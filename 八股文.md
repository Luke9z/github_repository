# 设计模式

## 创建型模式

### 抽象工厂模式

- 抽象工厂就是提供一个接口，用于创建相关或者依赖对象的家族，不需要指定具体的类。程序员在使用的时候直接使用对应的工厂来创建即可，不需要思考具体类是如何生成的。缺点就是当我们要去新增新的产品时，要去更改接口的行为
- ![抽象工厂模式.jpeg](https://images0.cnblogs.com/blog/381060/201310/08191340-e13eefcde4ee4e029ee5df41067866dd.png)
- 这里有：
  - **AbstractFactory**：抽象工厂。这个接口定义了所有生成产品的行为，对应的具体工厂需要实现这个接口
  - **ConcreteFactory**：具体工厂，用于生成不同产品族群。创建一个产品的时候，用户直接使用对应的工厂即可
  - **AbstractProduct**：抽象产品，这是产品家族，具体工厂可以产出产品家族下的一整组产品
  - **Product**：具体的产品
- 我们可以发现，当需要新增产品的时候，所有具体工厂以及抽象工厂都需要添加新的方法，比如新增产品C，就需要添加`createProductC()`这个方法。
- ![img](https://pic1.zhimg.com/80/v2-26c774778cddec1ae164116df8c1a86e_720w.webp?source=1def8aca)

### 工厂方法模式

- 工厂方法模式与抽象工厂不同的是，工厂方法模式由具体工厂来决定返回具体的产品，也就是说，用户可以通过每个具体的工厂来获得具体的产品。一个产品与一个工厂一一对应。
- ![工厂方法模式](https://images0.cnblogs.com/blog/381060/201310/08191345-b284145d01324a29a331abbe0285df33.png)
- 参与者：
  - **Product**：抽象产品。所有产品都要实现这个接口
  - **Factory**：抽象工厂，实现了生成产品的方法，但不实现，由具体的工厂类来实现。
- ![img](https://picx.zhimg.com/80/v2-d705bcb757fce334e251abb3c733bc1d_720w.webp?source=1def8aca)

### 建造者模式

- 建造者模式主要用来构建复杂的对象，它将对象内部进行分隔，分解到不同的方法中，用户可以精确的控制对象的创建过程。但是如果产品内部过于复杂，则系统会较为庞大，有很多方法对外暴漏出去。同时，建造者模式不适用于多个差异较大的产品，因为不同产品之间的相同部分可能不会特别多，这样子适用范围就有限，
- ![建造者模式](https://images0.cnblogs.com/blog/381060/201310/08191342-1fb6ec5ff4734e7baaa87bb950cd8385.jpg)
- 参与者：
  - **Builder**：抽象建造者，定义了创建Product对象各个部件的方法
  - **Director**：使用Builder接口对象，可以用来创建复杂对象，用户可以直接使用它来完成复杂对象的全部创建。

### 原型模式

- 当有时候我们创建对象的代价比较大时，又想重复的去创建它使用它时，可以采用原型模式。原型模式的本质是在使用某个对象的时候，直接使用其副本而不去新建它。这里的副本其实就是Java中的clone方法，进行一次拷贝。比如在一次高代价的数据库操作后创建了一个对象，其他人去使用的时候可以直接使用其副本而不去重新查询数据库。

### 单例模式

- 确保项目中只有单个对象被创建，这个类提供唯一方法来访问其的对象，外部不需要实例化对象，由内部实例化

- 饿汉式创建：

  - ```java
    class Singleton{
        private static Singleton instance = new Singleton();
        private Singleton(){}
        public static getInstance(){
            return instance;
        }
    }
    ```

- 懒汉式创建：

  - ```java
    //使用双重检查锁的形式来保证线程安全
    //使用volatile来解决指令重排序的问题。
    //在synchronized内部，如果instance没有volatile保证重排序的问题，那么有可能instance被赋值，但是对象还没创建好，此时外部线程过来会发现instance != null，就会把instance返回，但是这个instance只是有赋值，对象还没有真正创建出来。
    class Singleton{
        private volatile static Singleton instance;
        private Singleton(){}
        public static getInstance(){
            if(instance == null){
                synchronized(Singleton.class){
                    if(instance == null){
                        instance = new Singleton();
                    }
                }
            }
            return instance;
        }
    }
    ```

## 结构型模式

### 适配器模式

- 作为两个不兼容接口的桥梁，可以结合两个独立的接口。生活中，我有一个读卡器，读卡器就是一个适配器，它将内存卡和笔记本进行了适配。正常情况下，笔记本只能去读USB接口的设备，读不了内存卡，但是如果我们将内存卡插到读卡器以后，笔记本就可以通过读卡器的USB接口去读取内存卡的内容了。

- ![适配器模式的 UML 图](https://www.runoob.com/wp-content/uploads/2014/08/20210223-adapter.png)

- 以上这个UML例子展现了一个音频播放器的功能。MediaPlayer是接口，AudioPlayer实现这个接口，并且默认只能读MP3文件，然后我们再创建一个MediaAdapter适配器，这个适配器也实现了MediaPlayer接口，并且可以去读取MP4文件和Vlc文件。只要我们再AudioPlayer里面组合一个MediaAdapter，就可以利用MediaAdapter去读取MP4和Vlc了

- ```java
  public class MediaAdapter implements MediaPlayer {
   
     AdvancedMediaPlayer advancedMusicPlayer;
   
     public MediaAdapter(String audioType){
        if(audioType.equalsIgnoreCase("vlc") ){
           advancedMusicPlayer = new VlcPlayer();       
        } else if (audioType.equalsIgnoreCase("mp4")){
           advancedMusicPlayer = new Mp4Player();
        }  
     }
   
     @Override
     public void play(String audioType, String fileName) {
        if(audioType.equalsIgnoreCase("vlc")){
           advancedMusicPlayer.playVlc(fileName);
        }else if(audioType.equalsIgnoreCase("mp4")){
           advancedMusicPlayer.playMp4(fileName);
        }
     }
  }
  
  public class AudioPlayer implements MediaPlayer {
     MediaAdapter mediaAdapter; 
   
     @Override
     public void play(String audioType, String fileName) {    
   
        //播放 mp3 音乐文件的内置支持
        if(audioType.equalsIgnoreCase("mp3")){
           System.out.println("Playing mp3 file. Name: "+ fileName);         
        } 
        //mediaAdapter 提供了播放其他文件格式的支持
        else if(audioType.equalsIgnoreCase("vlc") 
           || audioType.equalsIgnoreCase("mp4")){
           mediaAdapter = new MediaAdapter(audioType);
           mediaAdapter.play(audioType, fileName);
        }
        else{
           System.out.println("Invalid media. "+
              audioType + " format not supported");
        }
     }   
  }
  ```

  





# AQS

## AQS结构

- 其实就四个属性

  - 头节点，当前持有锁得线程

  - 尾节点，阻塞队列得尾部

  - 锁得状态，0表示没有占用，大于0表示有线程占用，每次重用锁都会+1

  - 占有独占锁得线程，属性是为了判断当前线程是否已经获取锁了，如果获取了就直接state+1

  - ```java
    // 头结点，你直接把它当做 当前持有锁的线程 可能是最好理解的
    private transient volatile Node head;
    
    // 阻塞的尾节点，每个新的节点进来，都插入到最后，也就形成了一个链表
    private transient volatile Node tail;
    
    // 这个是最重要的，代表当前锁的状态，0代表没有被占用，大于 0 代表有线程持有当前锁
    // 这个值可以大于 1，是因为锁可以重入，每次重入都加上 1
    private volatile int state;
    
    // 代表当前持有独占锁的线程，举个最重要的使用例子，因为锁可以重入
    // reentrantLock.lock()可以嵌套调用多次，所以每次用这个来判断当前线程是否已经拥有了锁
    // if (currentThread == getExclusiveOwnerThread()) {state++}
    private transient Thread exclusiveOwnerThread; //继承自AbstractOwnableSynchronizer
    ```

- 注意，阻塞队列不包括头节点

  - ![aqs-0](https://assets.javadoop.com/blogimages/AbstractQueuedSynchronizer/aqs-0.png)

- 看一下node 的数据结构

  - ```java
    static final class Node {
        // 标识节点当前在共享模式下
        static final Node SHARED = new Node();
        // 标识节点当前在独占模式下
        static final Node EXCLUSIVE = null;
    
        // ======== 下面的几个int常量是给waitStatus用的 ===========
        /** waitStatus value to indicate thread has cancelled */
        // 代码此线程取消了争抢这个锁
        static final int CANCELLED =  1;
        /** waitStatus value to indicate successor's thread needs unparking */
        // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒
        static final int SIGNAL    = -1;
        /** waitStatus value to indicate thread is waiting on condition */
        // 本文不分析condition，所以略过吧，下一篇文章会介绍这个
        static final int CONDITION = -2;
        /**
         * waitStatus value to indicate the next acquireShared should
         * unconditionally propagate
         */
        // 同样的不分析，略过吧
        static final int PROPAGATE = -3;
        // =====================================================
    
        // 取值为上面的1、-1、-2、-3，或者0(以后会讲到)
        // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待，
        //    ps: 半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的。。。
        volatile int waitStatus;
        // 前驱节点的引用
        volatile Node prev;
        // 后继节点的引用
        volatile Node next;
        // 这个就是线程本尊
        volatile Thread thread;
    
    }
    ```

  - 其实也就4个属性， waitStatus， pre，next和thread，其他都是常量。 

## 公平锁如何实现线程抢锁

- 首先，线程调用`lock()`之后，会去获取锁`acquire(1)`，然后在获取锁方法里面进行`tryAcquire(1)`尝试去获取锁，如果现在锁没有被占用，那么直接获取成功，有人占用了已经，那么就把线程放入阻塞队列

  - ```java
     // 争锁
        final void lock() {
            acquire(1);
        }
          // 来自父类AQS，我直接贴过来这边，下面分析的时候同样会这样做，不会给读者带来阅读压力
        // 我们看到，这个方法，如果tryAcquire(arg) 返回true, 也就结束了。
        // 否则，acquireQueued方法会将线程压到队列中
        public final void acquire(int arg) { // 此时 arg == 1
            // 首先调用tryAcquire(1)一下，名字上就知道，这个只是试一试
            // 因为有可能直接就成功了呢，也就不需要进队列排队了，
            // 对于公平锁的语义就是：本来就没人持有锁，根本没必要进队列等待(又是挂起，又是等待被唤醒的)
            if (!tryAcquire(arg) &&
                // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。
                acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) {
                  selfInterrupt();
            }
        }
    ```

- 在`tryAcquire(int acuires)`中，先获取到现在锁的状态。

  - 如果为0的话，说明锁没有被占用，同时因为是公平锁的原因，要看看阻塞队列中有没有别人已经在等待获取锁了，如果没有的话，就是用CAS尝试一下获取锁`期待值为0，想要修改成(acuires)`，如果CAS成功的话，那么这个线程真正的获取到锁，同时标记`exclusiveOwnerThread`为当前线程，记录当前获得锁的线程，返回true

  - 如果没有返回true，说明当前锁被占用，那么就要看看现在这个线程是不是占用锁的线程，如果是的话，那么就是可重用，将state + 1，表示再次获取锁，返回true。

  - 如果走到这里，说明没有获取到锁，那么返回false。

  - ```java
    /**
         * Fair version of tryAcquire.  Don't grant access unless
         * recursive call or no waiters or is first.
         */
        // 尝试直接获取锁，返回值是boolean，代表是否获取到锁
        // 返回true：1.没有线程在等待锁；2.重入锁，线程本来就持有锁，也就可以理所当然可以直接获取
        protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            // state == 0 此时此刻没有线程持有锁
            if (c == 0) {
                // 虽然此时此刻锁是可以用的，但是这是公平锁，既然是公平，就得讲究先来后到，
                // 看看有没有别人在队列中等了半天了
                if (!hasQueuedPredecessors() &&
                    // 如果没有线程在等待，那就用CAS尝试一下，成功了就获取到锁了，
                    // 不成功的话，只能说明一个问题，就在刚刚几乎同一时刻有个线程抢先了 =_=
                    // 因为刚刚还没人的，我判断过了
                    compareAndSetState(0, acquires)) {
    
                    // 到这里就是获取到锁了，标记一下，告诉大家，现在是我占用了锁
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
              // 会进入这个else if分支，说明是重入了，需要操作：state=state+1
            // 这里不存在并发问题
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            // 如果到这里，说明前面的if和else if都没有返回true，说明没有获取到锁
            // 回到上面一个外层调用方法继续看:
            // if (!tryAcquire(arg) 
            //        && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) 
            //     selfInterrupt();
            return false;
        }
    ```

- 如果我们的`tryAcquire`返回false的话，那么就会走`acquireQueued(addWaiter(Node.EXCLUSIVE), arg)`这个代码，这个代码 首先会执行`addWaiter(Node.EXCLUSIVE)`，作用为把线程包装成node，同时放入队列。

  - 放入队列的代码比较直观，就是获取到队列尾节点，判断队列是否为空

    - 不为空，将尾节点设置为当前线程node的前驱，然后使用CAS把自己设置为队尾(因为是多线程环境，所以有可能在设置队尾时，另外一个线程已经把自己设置为队尾了，那么此时队尾就不对了，所以采用CAS方式)。
      - 如果设置成功，那么将前驱的后驱设置为自己，表示线程入队了
    - 如果为空或者CAS设置队尾失败，那么将采用自旋的方式入队。

  - ```java
    /**
         * Creates and enqueues node for current thread and given mode.
         *
         * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared
         * @return the new node
         */
        // 此方法的作用是把线程包装成node，同时进入到队列中
        // 参数mode此时是Node.EXCLUSIVE，代表独占模式
        private Node addWaiter(Node mode) {
            Node node = new Node(Thread.currentThread(), mode);
            // Try the fast path of enq; backup to full enq on failure
            // 以下几行代码想把当前node加到链表的最后面去，也就是进到阻塞队列的最后
            Node pred = tail;
    
            // tail!=null => 队列不为空(tail==head的时候，其实队列是空的，不过不管这个吧)
            if (pred != null) { 
                // 将当前的队尾节点，设置为自己的前驱 
                node.prev = pred; 
                // 用CAS把自己设置为队尾, 如果成功后，tail == node 了，这个节点成为阻塞队列新的尾巴
                if (compareAndSetTail(pred, node)) { 
                    // 进到这里说明设置成功，当前node==tail, 将自己与之前的队尾相连，
                    // 上面已经有 node.prev = pred，加上下面这句，也就实现了和之前的尾节点双向连接了
                    pred.next = node;
                    // 线程入队了，可以返回了
                    return node;
                }
            }
            // 仔细看看上面的代码，如果会到这里，
            // 说明 pred==null(队列是空的) 或者 CAS失败(有线程在竞争入队)
            // 读者一定要跟上思路，如果没有跟上，建议先不要往下读了，往回仔细看，否则会浪费时间的
            enq(node);
            return node;
        }
    ```

- 接下来就是自旋的方式添加node进入队列中，调用的时`enq(node)`

  - 在一个无限循环里，重复的尝试将node加入到队列中，注意，首先要获取tail，因为head和tail在初始话的时候时null，所以需要在enq这个方法中进行初始化

    - 如果tail是null的话，那么就初始化head，并且还是使用CAS的方式将队头初始化，然后将队尾指向对头，此时 head == tail，但是方法并没有返回，会走接下来的循环。
    - 此时tail不是null了，且代码体和`addWaiter`中放入队列一样，只是如果CAS放入队尾还是失败，那么就再次进入下一个循环来操作。

  - ```java
    private Node enq(final Node node) {
            for (;;) {
                Node t = tail;
                // 之前说过，队列为空也会进来这里
                if (t == null) { // Must initialize
                    // 初始化head节点
                    // 细心的读者会知道原来 head 和 tail 初始化的时候都是 null 的
                    // 还是一步CAS，你懂的，现在可能是很多线程同时进来呢
                    if (compareAndSetHead(new Node()))
                        // 给后面用：这个时候head节点的waitStatus==0,说明此时head节点没有占用锁，看new Node()构造方法就知道了
    
                        // 这个时候有了head，但是tail还是null，设置一下，
                        // 把tail指向head，放心，马上就有线程要来了，到时候tail就要被抢了
                        // 注意：这里只是设置了tail=head，这里可没return哦，没有return，没有return
                        // 所以，设置完了以后，继续for循环，下次就到下面的else分支了
                        tail = head;
                } else {
                    // 下面几行，和上一个方法 addWaiter 是一样的，
                    // 只是这个套在无限循环里，反正就是将当前线程排到队尾，有线程竞争的话排不上重复排
                    node.prev = t;
                    if (compareAndSetTail(t, node)) {
                        t.next = node;
                        return t;
                    }
                }
            }
        }
    ```

- 接下来会回到`acquireQueued`这个方法，如果这个方法返回true的话，那么就进入到`selfInterrupt()`，所以应该返回false。

  - 首先先获取当前线程节点的前驱节点，如果这个前驱结点时头节点的话，那么当前线程可以去尝试获取一下锁

    - 为什么说是尝试获取呢，首先如果前驱节点是头节点的话，那么说明当前节点是对头，可以去尝试抢锁，第二个原因是，从enq方法我得知，初始化对头的时候，`waitStatus`是0，没有设置任何线程，所有head不属于任何线程，可以去试一试。

  - 如果获取失败，或者前驱节点不是头节点的话，那么就调用`shouldParkAfterFailedAcquire(p, node)`这个方法。

  - ```java
    final boolean acquireQueued(final Node node, int arg) {
            boolean failed = true;
            try {
                boolean interrupted = false;
                for (;;) {
                    final Node p = node.predecessor();
                    // p == head 说明当前节点虽然进到了阻塞队列，但是是阻塞队列的第一个，因为它的前驱是head
                    // 注意，阻塞队列不包含head节点，head一般指的是占有锁的线程，head后面的才称为阻塞队列
                    // 所以当前节点可以去试抢一下锁
                    // 这里我们说一下，为什么可以去试试：
                    // 首先，它是队头，这个是第一个条件，其次，当前的head有可能是刚刚初始化的node，
                    // enq(node) 方法里面有提到，head是延时初始化的，而且new Node()的时候没有设置任何线程
                    // 也就是说，当前的head不属于任何一个线程，所以作为队头，可以去试一试，
                    // tryAcquire已经分析过了, 忘记了请往前看一下，就是简单用CAS试操作一下state
                    if (p == head && tryAcquire(arg)) {
                        setHead(node);
                        p.next = null; // help GC
                        failed = false;
                        return interrupted;
                    }
                    // 到这里，说明上面的if分支没有成功，要么当前node本来就不是队头，
                    // 要么就是tryAcquire(arg)没有抢赢别人，继续往下看
                    if (shouldParkAfterFailedAcquire(p, node) &&
                        parkAndCheckInterrupt())
                        interrupted = true;
                }
            } finally {
                // 什么时候 failed 会为 true???
                // tryAcquire() 方法抛异常的情况
                if (failed)
                    cancelAcquire(node);
            }
        }
    ```

- 现在就走到了`shouldParkAfterFailedAcquire(p, node)`方法，这个方法就是说:"当前线程没有抢到锁，是否需要挂起线程"

  - 首先先拿到前驱节点的`waitStatus`，如果 = -1的话，说明前驱节点的状态是正常的，直接返回true等待下一个方法挂起当前线程

  - 如果不是 -1 的话，那么要判断前驱节点的`waitStatus`是否 > 0，如果 > 0说明前驱节点取消排队了，那么我们就要将当前的节点的前驱节点往前再找，直到找到一个节点的`waitStatus`是 <= 0的

  - 如果都不是的话，那么说明现在前驱节点的`waitStatus`为0， -2， -3，用CAS将他们的 `waitStatus`设置为 -1，然后返回false，继续循环进入此方法，此时就会进入到第一个if返回true

  - ```java
    /**
         * Checks and updates status for a node that failed to acquire.
         * Returns true if thread should block. This is the main signal
         * control in all acquire loops.  Requires that pred == node.prev
         *
         * @param pred node's predecessor holding status
         * @param node the node
         * @return {@code true} if thread should block
         */
        // 刚刚说过，会到这里就是没有抢到锁呗，这个方法说的是："当前线程没有抢到锁，是否需要挂起当前线程？"
        // 第一个参数是前驱节点，第二个参数才是代表当前线程的节点
        private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
            int ws = pred.waitStatus;
            // 前驱节点的 waitStatus == -1 ，说明前驱节点状态正常，当前线程需要挂起，直接可以返回true
            if (ws == Node.SIGNAL)
                /*
                 * This node has already set status asking a release
                 * to signal it, so it can safely park.
                 */
                return true;
    
            // 前驱节点 waitStatus大于0 ，之前说过，大于0 说明前驱节点取消了排队。
            // 这里需要知道这点：进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。
            // 所以下面这块代码说的是将当前节点的prev指向waitStatus<=0的节点，
            // 简单说，就是为了找个好爹，因为你还得依赖它来唤醒呢，如果前驱节点取消了排队，
            // 找前驱节点的前驱节点做爹，往前遍历总能找到一个好爹的
            if (ws > 0) {
                /*
                 * Predecessor was cancelled. Skip over predecessors and
                 * indicate retry.
                 */
                do {
                    node.prev = pred = pred.prev;
                } while (pred.waitStatus > 0);
                pred.next = node;
            } else {
                /*
                 * waitStatus must be 0 or PROPAGATE.  Indicate that we
                 * need a signal, but don't park yet.  Caller will need to
                 * retry to make sure it cannot acquire before parking.
                 */
                // 仔细想想，如果进入到这个分支意味着什么
                // 前驱节点的waitStatus不等于-1和1，那也就是只可能是0，-2，-3
                // 在我们前面的源码中，都没有看到有设置waitStatus的，所以每个新的node入队时，waitStatu都是0
                // 正常情况下，前驱节点是之前的 tail，那么它的 waitStatus 应该是 0
                // 用CAS将前驱节点的waitStatus设置为Node.SIGNAL(也就是-1)
                compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
            }
            // 这个方法返回 false，那么会再走一次 for 循序，
            //     然后再次进来此方法，此时会从第一个分支返回 true
            return false;
        }
    ```

- 如果上面这个方法返回true的话，那么就直接挂起当前线程，调用`parkAndCheckInterrupt()`方法

  - ```java
    // private static boolean shouldParkAfterFailedAcquire(Node pred, Node node)
        // 这个方法结束根据返回值我们简单分析下：
        // 如果返回true, 说明前驱节点的waitStatus==-1，是正常情况，那么当前线程需要被挂起，等待以后被唤醒
        //        我们也说过，以后是被前驱节点唤醒，就等着前驱节点拿到锁，然后释放锁的时候叫你好了
        // 如果返回false, 说明当前不需要被挂起，为什么呢？往后看
    
        // 跳回到前面是这个方法
        // if (shouldParkAfterFailedAcquire(p, node) &&
        //                parkAndCheckInterrupt())
        //                interrupted = true;
    
        // 1. 如果shouldParkAfterFailedAcquire(p, node)返回true，
        // 那么需要执行parkAndCheckInterrupt():
    
        // 这个方法很简单，因为前面返回true，所以需要挂起线程，这个方法就是负责挂起线程的
        // 这里用了LockSupport.park(this)来挂起线程，然后就停在这里了，等待被唤醒=======
        private final boolean parkAndCheckInterrupt() {
            LockSupport.park(this);
            return Thread.interrupted();
        }
     // 2. 接下来说说如果shouldParkAfterFailedAcquire(p, node)返回false的情况
    
       // 仔细看shouldParkAfterFailedAcquire(p, node)，我们可以发现，其实第一次进来的时候，一般都不会返回true的，原因很简单，前驱节点的waitStatus=-1是依赖于后继节点设置的。也就是说，我都还没给前驱设置-1呢，怎么可能是true呢，但是要看到，这个方法是套在循环里的，所以第二次进来的时候状态就是-1了。
    
        // 解释下为什么shouldParkAfterFailedAcquire(p, node)返回false的时候不直接挂起线程：
        // => 是为了应对在经过这个方法后，node已经是head的直接后继节点了。剩下的读者自己想想吧。
    	//我觉得是因为如果node是head的后继节点，那么在循环体的第一个if中会去尝试获取锁，如果直接挂起的话，那么就不会去尝试获取锁了。
    ```

  - ![a](http://assets.processon.com/chart_image/602f37927d9c081db9a6d12c.png)

## 公平锁之线程解锁

- 线程解锁其实就很简单了

  - ```java
    // 唤醒的代码还是比较简单的，你如果上面加锁的都看懂了，下面都不需要看就知道怎么回事了
    public void unlock() {
        sync.release(1);
    }
    
    public final boolean release(int arg) {
        // 往后看吧
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null && h.waitStatus != 0)
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
    
    // 回到ReentrantLock看tryRelease方法
    protected final boolean tryRelease(int releases) {
        int c = getState() - releases;
        if (Thread.currentThread() != getExclusiveOwnerThread())
            throw new IllegalMonitorStateException();
        // 是否完全释放锁
        boolean free = false;
        // 其实就是重入的问题，如果c==0，也就是说没有嵌套锁了，可以释放了，否则还不能释放掉
        if (c == 0) {
            free = true;
            setExclusiveOwnerThread(null);
        }
        setState(c);
        return free;
    }
    
    /**
     * Wakes up node's successor, if one exists.
     *
     * @param node the node
     */
    // 唤醒后继节点
    // 从上面调用处知道，参数node是head头结点
    private void unparkSuccessor(Node node) {
        /*
         * If status is negative (i.e., possibly needing signal) try
         * to clear in anticipation of signalling.  It is OK if this
         * fails or if status is changed by waiting thread.
         */
        int ws = node.waitStatus;
        // 如果head节点当前waitStatus<0, 将其修改为0
        if (ws < 0)
            compareAndSetWaitStatus(node, ws, 0); //这里设置为0后，唤醒的那个线程会进入循环，将自己的前驱变为head
        /*
         * Thread to unpark is held in successor, which is normally
         * just the next node.  But if cancelled or apparently null,
         * traverse backwards from tail to find the actual
         * non-cancelled successor.
         */
        // 下面的代码就是唤醒后继节点，但是有可能后继节点取消了等待（waitStatus==1）
        // 从队尾往前找，找到waitStatus<=0的所有节点中排在最前面的
        Node s = node.next;
        if (s == null || s.waitStatus > 0) {
            s = null;
            // 从后往前找，仔细看代码，不必担心中间有节点取消(waitStatus==1)的情况
            for (Node t = tail; t != null && t != node; t = t.prev)
                if (t.waitStatus <= 0)
                    s = t;
        }
        if (s != null)
            // 唤醒线程
            LockSupport.unpark(s.thread);
    }
    ```


## 非公平锁lock

```java
static final class NonfairSync extends Sync {
    final void lock() {
        // 2. 和公平锁相比，这里会直接先进行一次CAS，成功就返回了
        if (compareAndSetState(0, 1))
            setExclusiveOwnerThread(Thread.currentThread());
        else
            acquire(1);
    }
    // AbstractQueuedSynchronizer.acquire(int arg)
    public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
    protected final boolean tryAcquire(int acquires) {
        return nonfairTryAcquire(acquires);
    }
}
/**
 * Performs non-fair tryLock.  tryAcquire is implemented in
 * subclasses, but both need nonfair try for trylock method.
 */
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        // 这里没有对阻塞队列进行判断
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

## Condition

![条件队列](https://assets.javadoop.com/blogimages/AbstractQueuedSynchronizer-2/aqs2-2.png)

1. 条件队列和阻塞队列的节点，都是 Node 的实例，因为条件队列的节点是需要转移到阻塞队列中去的；
2. 我们知道一个 ReentrantLock 实例可以通过多次调用 newCondition() 来产生多个 Condition 实例，这里对应 condition1 和 condition2。注意，ConditionObject 只有两个属性 firstWaiter 和 lastWaiter；
3. 每个 condition 有一个关联的**条件队列**，如线程 1 调用 `condition1.await()` 方法即可将当前线程 1 包装成 Node 后加入到条件队列中，然后阻塞在这里，不继续往下执行，条件队列是一个单向链表；
4. 调用`condition1.signal()` 触发一次唤醒，此时唤醒的是队头，会将condition1 对应的**条件队列**的 firstWaiter（队头） 移到**阻塞队列的队尾**，等待获取锁，获取锁后 await 方法才能返回，继续往下执行。

await()方法：

```java
// 首先，这个方法是可被中断的，不可被中断的是另一个方法 awaitUninterruptibly()
// 这个方法会阻塞，直到调用 signal 方法（指 signal() 和 signalAll()，下同），或被中断
public final void await() throws InterruptedException {
    // 老规矩，既然该方法要响应中断，那么在最开始就判断中断状态
    if (Thread.interrupted())
        throw new InterruptedException();

    // 添加到 condition 的条件队列中
    Node node = addConditionWaiter();

    // 释放锁，返回值是释放锁之前的 state 值
    // await() 之前，当前线程是必须持有锁的，这里肯定要释放掉
    // 因为要先lock()后，再去执行有关await()的逻辑。
    int savedState = fullyRelease(node);

    int interruptMode = 0;
    // 这里退出循环有两种情况，之后再仔细分析
    // 1. isOnSyncQueue(node) 返回 true，即当前 node 已经转移到阻塞队列了
    // 2. checkInterruptWhileWaiting(node) != 0 会到 break，然后退出循环，代表的是线程中断
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 被唤醒后，将进入阻塞队列，等待获取锁
    if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null) // clean up if cancelled
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}
```

### 1. 将节点加入到条件队列

addConditionWaiter() 是将当前节点加入到条件队列，看图我们知道，这种条件队列内的操作是线程安全的。

```java
// 将当前线程对应的节点入队，插入队尾
private Node addConditionWaiter() {
    Node t = lastWaiter;
    // 如果条件队列的最后一个节点取消了，将其清除出去
    // 为什么这里把 waitStatus 不等于 Node.CONDITION，就判定为该节点发生了取消排队？
    if (t != null && t.waitStatus != Node.CONDITION) {
        // 这个方法会遍历整个条件队列，然后会将已取消的所有节点清除出队列
        unlinkCancelledWaiters();
        t = lastWaiter;
    }
    // node 在初始化的时候，指定 waitStatus 为 Node.CONDITION
    Node node = new Node(Thread.currentThread(), Node.CONDITION);

    // t 此时是 lastWaiter，队尾
    // 如果队列为空
    if (t == null)
        firstWaiter = node;
    else
        t.nextWaiter = node;
    lastWaiter = node;
    return node;
}
```

上面的这块代码很简单，就是将当前线程进入到条件队列的队尾。

在addWaiter 方法中，有一个 unlinkCancelledWaiters() 方法，该方法用于清除队列中已经取消等待的节点。

当 await 的时候如果发生了取消操作（这点之后会说），或者是在节点入队的时候，发现最后一个节点是被取消的，会调用一次这个方法。

```java
// 等待队列是一个单向链表，遍历链表将已经取消等待的节点清除出去
// 纯属链表操作，很好理解，看不懂多看几遍就可以了
private void unlinkCancelledWaiters() {
    Node t = firstWaiter;
    Node trail = null;
    while (t != null) {
        Node next = t.nextWaiter;
        // 如果节点的状态不是 Node.CONDITION 的话，这个节点就是被取消的
        if (t.waitStatus != Node.CONDITION) {
            t.nextWaiter = null;
            if (trail == null)
                firstWaiter = next;
            else
                trail.nextWaiter = next;
            if (next == null)
                lastWaiter = trail;
        }
        else
            trail = t;
        t = next;
    }
}
```

### 2. 完全释放独占锁

回到 wait 方法，节点入队了以后，会调用 `int savedState = fullyRelease(node);` 方法释放锁，注意，这里是完全释放独占锁（fully release），因为 ReentrantLock 是可以重入的。

> 考虑一下这里的 savedState。如果在 condition1.await() 之前，假设线程先执行了 2 次 lock() 操作，那么 state 为 2，我们理解为该线程持有 2 把锁，这里 await() 方法必须将 state 设置为 0，然后再进入挂起状态，这样其他线程才能持有锁。当它被唤醒的时候，它需要重新持有 2 把锁，才能继续下去。

```java
// 首先，我们要先观察到返回值 savedState 代表 release 之前的 state 值
// 对于最简单的操作：先 lock.lock()，然后 condition1.await()。
//         那么 state 经过这个方法由 1 变为 0，锁释放，此方法返回 1
//         相应的，如果 lock 重入了 n 次，savedState == n
// 如果这个方法失败，会将节点设置为"取消"状态，并抛出异常 IllegalMonitorStateException
final int fullyRelease(Node node) {
    boolean failed = true;
    try {
        int savedState = getState();
        // 这里使用了当前的 state 作为 release 的参数，也就是完全释放掉锁，将 state 置为 0
        if (release(savedState)) {
            failed = false;
            return savedState;
        } else {
            throw new IllegalMonitorStateException();
        }
    } finally {
        if (failed)
            node.waitStatus = Node.CANCELLED;
    }
}
```

> 考虑一下，如果一个线程在不持有 lock 的基础上，就去调用 condition1.await() 方法，它能进入条件队列，但是在上面的这个方法中，由于它不持有锁，release(savedState) 这个方法肯定要返回 false，进入到异常分支，然后进入 finally 块设置 `node.waitStatus = Node.CANCELLED`，这个已经入队的节点之后会被后继的节点”请出去“。



### 3. 等待进入阻塞队列

释放掉锁以后，接下来是这段，这边会自旋，如果发现自己还没到阻塞队列，那么挂起，等待被转移到阻塞队列。

```java
int interruptMode = 0;
// 如果不在阻塞队列中，注意了，是阻塞队列
while (!isOnSyncQueue(node)) {
    // 线程挂起
    LockSupport.park(this);

    // 这里可以先不用看了，等看到它什么时候被 unpark 再说
    if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
        break;
}
```

isOnSyncQueue(Node node) 用于判断节点是否已经转移到阻塞队列了：

```java
// 在节点入条件队列的时候，初始化时设置了 waitStatus = Node.CONDITION
// 前面我提到，signal 的时候需要将节点从条件队列移到阻塞队列，
// 这个方法就是判断 node 是否已经移动到阻塞队列了
final boolean isOnSyncQueue(Node node) {

    // 移动过去的时候，node 的 waitStatus 会置为 0，这个之后在说 signal 方法的时候会说到
    // 如果 waitStatus 还是 Node.CONDITION，也就是 -2，那肯定就是还在条件队列中
    // 如果 node 的前驱 prev 指向还是 null，说明肯定没有在 阻塞队列(prev是阻塞队列链表中使用的)
    if (node.waitStatus == Node.CONDITION || node.prev == null)
        return false;
    // 如果 node 已经有后继节点 next 的时候，那肯定是在阻塞队列了
    if (node.next != null) 
        return true;

    // 下面这个方法从阻塞队列的队尾开始从后往前遍历找，如果找到相等的，说明在阻塞队列，否则就是不在阻塞队列

    // 可以通过判断 node.prev() != null 来推断出 node 在阻塞队列吗？答案是：不能。
    // 这个可以看上篇 AQS 的入队方法，首先设置的是 node.prev 指向 tail（这里已经设置前驱了，但是如果自己还没有设置为尾节点，那么还是没有被添加进去同步队列），
    // 然后是 CAS 操作将自己设置为新的 tail，可是这次的 CAS 是可能失败的。

    return findNodeFromTail(node);
}

// 从阻塞队列的队尾往前遍历，如果找到，返回 true
private boolean findNodeFromTail(Node node) {
    Node t = tail;
    for (;;) {
        if (t == node)
            return true;
        if (t == null)
            return false;
        t = t.prev;
    }
}
```

回到前面的循环，isOnSyncQueue(node) 返回 false 的话，那么进到 `LockSupport.park(this);` 这里线程挂起。



### 4. signal 唤醒线程，转移到阻塞队列

为了大家理解，这里我们先看唤醒操作，因为刚刚到 `LockSupport.park(this);` 把线程挂起了，等待唤醒。

唤醒操作通常由另一个线程来操作，就像生产者-消费者模式中，如果线程因为等待消费而挂起，那么当生产者生产了一个东西后，会调用 signal 唤醒正在等待的线程来消费。

```java
// 唤醒等待了最久的线程
// 其实就是，将这个线程对应的 node 从条件队列转移到阻塞队列
public final void signal() {
    // 调用 signal 方法的线程必须持有当前的独占锁
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node first = firstWaiter;
    if (first != null)
        doSignal(first);
}

// 从条件队列队头往后遍历，找出第一个需要转移的 node
// 因为前面我们说过，有些线程会取消排队，但是可能还在队列中
private void doSignal(Node first) {
    do {
          // 将 firstWaiter 指向 first 节点后面的第一个，因为 first 节点马上要离开了
        // 如果将 first 移除后，后面没有节点在等待了，那么需要将 lastWaiter 置为 null
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        // 因为 first 马上要被移到阻塞队列了，和条件队列的链接关系在这里断掉
        first.nextWaiter = null;
    } while (!transferForSignal(first) &&
             (first = firstWaiter) != null);
      // 这里 while 循环，如果 first 转移不成功，那么选择 first 后面的第一个节点进行转移，依此类推
}

// 将节点从条件队列转移到阻塞队列
// true 代表成功转移
// false 代表在 signal 之前，节点已经取消了
final boolean transferForSignal(Node node) {

    // CAS 如果失败，说明此 node 的 waitStatus 已不是 Node.CONDITION，说明节点已经取消，
    // 既然已经取消，也就不需要转移了，方法返回，转移后面一个节点
    // 否则，将 waitStatus 置为 0
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;

    // enq(node): 自旋进入阻塞队列的队尾
    // 注意，这里的返回值 p 是 node 在阻塞队列的前驱节点
    Node p = enq(node);
    int ws = p.waitStatus;
    // ws > 0 说明 node 在阻塞队列中的前驱节点取消了等待锁，直接唤醒 node 对应的线程。唤醒之后会怎么样，后面再解释
    // 如果 ws <= 0, 那么 compareAndSetWaitStatus 将会被调用，上篇介绍的时候说过，节点入队后，需要把前驱节点的状态设为 Node.SIGNAL(-1)
    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
        // 如果前驱节点取消或者 CAS 失败，会进到这里唤醒线程，之后的操作看下一节
        LockSupport.unpark(node.thread);
    return true;
}
```

正常情况下，`ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)` 这句中，ws <= 0，而且 `compareAndSetWaitStatus(p, ws, Node.SIGNAL)` 会返回 true，所以一般也不会进去 if 语句块中唤醒 node 对应的线程。然后这个方法返回 true，也就意味着 signal 方法结束了，节点进入了阻塞队列。

假设发生了阻塞队列中的前驱节点取消等待，或者 CAS 失败，只要唤醒线程，让其进到下一步即可。



### 5. 唤醒后检查中断状态

上一步 signal 之后，我们的线程由条件队列转移到了阻塞队列，之后就准备获取锁了。只要重新获取到锁了以后，继续往下执行。

等线程从挂起中恢复过来，继续往下看

```java
int interruptMode = 0;
while (!isOnSyncQueue(node)) {
    // 线程挂起
    LockSupport.park(this);

    if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
        break;
}
```

先解释下 interruptMode。interruptMode 可以取值为 REINTERRUPT（1），THROW_IE（-1），0

- REINTERRUPT： 代表 await 返回的时候，需要重新设置中断状态
- THROW_IE： 代表 await 返回的时候，需要抛出 InterruptedException 异常
- 0 ：说明在 await 期间，没有发生中断

有以下三种情况会让 LockSupport.park(this); 这句返回继续往下执行：

1. 常规路径。signal -> 转移节点到阻塞队列 -> 获取了锁（unpark）
2. 线程中断。在 park 的时候，另外一个线程对这个线程进行了中断
3. signal 的时候我们说过，转移以后的前驱节点取消了，或者对前驱节点的CAS操作失败了
4. 假唤醒。这个也是存在的，和 Object.wait() 类似，都有这个问题

线程唤醒后第一步是调用 checkInterruptWhileWaiting(node) 这个方法，此方法用于判断是否在线程挂起期间发生了中断，如果发生了中断，是 signal 调用之前中断的，还是 signal 之后发生的中断。

```java
// 1. 如果在 signal 之前已经中断，返回 THROW_IE
// 2. 如果是 signal 之后中断，返回 REINTERRUPT
// 3. 没有发生中断，返回 0
private int checkInterruptWhileWaiting(Node node) {
    return Thread.interrupted() ?
        (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :
        0;
}
```

> Thread.interrupted()：如果当前线程已经处于中断状态，那么该方法返回 true，同时将中断状态重置为 false，所以，才有后续的 `重新中断（REINTERRUPT）` 的使用。

看看怎么判断是 signal 之前还是之后发生的中断：

```java
// 只有线程处于中断状态，才会调用此方法
// 如果需要的话，将这个已经取消等待的节点转移到阻塞队列
// 返回 true：如果此线程在 signal 之前被取消，
final boolean transferAfterCancelledWait(Node node) {
    // 用 CAS 将节点状态设置为 0 
    // 如果这步 CAS 成功，说明是 signal 方法之前发生的中断，因为如果 signal 先发生的话，signal 中会将 waitStatus 设置为 0
    if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {
        // 将节点放入阻塞队列
        // 这里我们看到，即使中断了，依然会转移到阻塞队列
        enq(node);
        return true;
    }

    // 到这里是因为 CAS 失败，肯定是因为 signal 方法已经将 waitStatus 设置为了 0
    // signal 方法会将节点转移到阻塞队列，但是可能还没完成，这边自旋等待其完成
    // 当然，这种事情还是比较少的吧：signal 调用之后，没完成转移之前，发生了中断
    while (!isOnSyncQueue(node))
        Thread.yield();
    return false;
}
```

> 这里再说一遍，即使发生了中断，节点依然会转移到阻塞队列。

到这里，大家应该都知道这个 while 循环怎么退出了吧。要么中断，要么转移成功。

这里描绘了一个场景，本来有个线程，它是排在条件队列的后面的，但是因为它被中断了，那么它会被唤醒，然后它发现自己不是被 signal 的那个，但是它会自己主动去进入到阻塞队列。



### 6. 获取独占锁

while 循环出来以后，下面是这段代码：

```java
if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
    interruptMode = REINTERRUPT;
```

由于 while 出来后，我们确定节点已经进入了阻塞队列，准备获取锁。

这里的 acquireQueued(node, savedState) 的第一个参数 node 之前已经经过 enq(node) 进入了队列，参数 savedState 是之前释放锁前的 state，这个方法返回的时候，代表当前线程获取了锁，而且 state == savedState了。

注意，前面我们说过，不管有没有发生中断，都会进入到阻塞队列，而 acquireQueued(node, savedState) 的返回值就是代表线程是否被中断。如果返回 true，说明被中断了，而且 interruptMode != THROW_IE，说明在 signal 之前就发生中断了，这里将 interruptMode 设置为 REINTERRUPT，用于待会重新中断。

继续往下：

```java
if (node.nextWaiter != null) // clean up if cancelled
    unlinkCancelledWaiters();
if (interruptMode != 0)
    reportInterruptAfterWait(interruptMode);
```

本着一丝不苟的精神，这边说说 `node.nextWaiter != null` 怎么满足。我前面也说了 signal 的时候会将节点转移到阻塞队列，有一步是 node.nextWaiter = null，将断开节点和条件队列的联系。

可是，`在判断发生中断的情况下，是 signal 之前还是之后发生的？` 这部分的时候，我也介绍了，如果 signal 之前就中断了，也需要将节点进行转移到阻塞队列，这部分转移的时候，是没有设置 node.nextWaiter = null 的。

之前我们说过，如果有节点取消，也会调用 unlinkCancelledWaiters 这个方法，就是这里了。



### 7. 处理中断状态

到这里，我们终于可以好好说下这个 interruptMode 干嘛用了。

- 0：什么都不做，没有被中断过；
- THROW_IE：await 方法抛出 InterruptedException 异常，因为它代表在 await() 期间发生了中断；
- REINTERRUPT：重新中断当前线程，因为它代表 await() 期间没有被中断，而是 signal() 以后发生的中断

```java
private void reportInterruptAfterWait(int interruptMode)
    throws InterruptedException {
    if (interruptMode == THROW_IE)
        throw new InterruptedException();
    else if (interruptMode == REINTERRUPT)
        selfInterrupt();
}
```

> 这个中断状态这部分内容，大家应该都理解了吧，不理解的话，多看几遍就是了。

# TreadLocal

`ThreadLocal` 是 Java 中一个非常有用的工具，它允许我们在每个线程中存储线程特定的数据。在多线程环境中，每个线程都可以有自己的 `ThreadLocal` 变量的副本，而不会与其他线程的 `ThreadLocal` 变量冲突。

下面是 `ThreadLocal` 的底层实现的简要概述：

1. **内部存储**:
   - `ThreadLocal` 并不直接存储数据。相反，它在每个线程中都有一个关联的 `ThreadLocalMap`。这个 `ThreadLocalMap` 是一个定制的哈希映射，用于存储每个 `ThreadLocal` 变量和它的值。
   - ![TreadLocal数据结构](C:\Users\62488\Downloads\TreadLocal数据结构.png)

2. **键为弱引用**:
   - `ThreadLocalMap` 中的键是对 `ThreadLocal` 对象的弱引用。这意味着，如果 `ThreadLocal` 对象没有其他强引用，并且被垃圾收集器回收，那么它的条目会从 `ThreadLocalMap` 中被清除。

3. **获取和设置值**:
   - 当你调用 `ThreadLocal` 的 `get()` 方法时，它会获取当前线程的 `ThreadLocalMap`，然后使用 `ThreadLocal` 对象作为键来查找值。
   - 当你调用 `set(T value)` 方法时，它会在当前线程的 `ThreadLocalMap` 中为 `ThreadLocal` 对象设置一个值。
   - 

4. **初始化**:
   - `ThreadLocal` 提供了一个 `initialValue()` 方法，它返回此线程局部变量的初始值。默认情况下，此方法返回 `null`。但你可以通过子类化 `ThreadLocal` 并重写 `initialValue()` 方法来更改初始值。

5. **内存泄漏的问题**:
   - 尽管 `ThreadLocal` 使用弱引用作为键，但如果线程持续存在并且不被终止，那么它的 `ThreadLocalMap` 也会持续存在。这可能会导致内存泄漏，尤其是在使用线程池的情况下。为了避免这种情况，建议在不再需要 `ThreadLocal` 值时调用 `ThreadLocal` 的 `remove()` 方法。

6. **用途**:

   - `ThreadLocal` 常用于实现线程安全的单例模式、数据库连接、会话管理等场景，其中每个线程需要有自己的实例副本。


# Java中的多线程 

![image-20240113174024248](C:\Users\62488\AppData\Roaming\Typora\typora-user-images\image-20240113174024248.png)

## 重量级锁

- 当synchronized关键字锁定一个对象的时候，一个线程执行到这个代码块时，会首先将这个对象与Monitor进行关联，将对象头的中Mark Word修改为指向Monitor的地址，以及将锁状态改为10，也就是重量级锁状态。
- 随后，线程将可以看到这个Monitor中的Owner 和 EntryList。如果Owner为Null，也就是说此时并没有线程拿到锁，那么这个线程就会去将Owner修改为自己，并且继续指向代码块中的内容。
- 当其他线程此时过来，看到这个对象，也从这个对象找到了对应的Monitor对象，看到Owner已经有线程了，那么这个新线程就会被放入到EntryList，将自己的状态修改为Block阻塞，等待被唤醒
- 第一个线程结束代码块中的内容之后，会将锁释放，也就是将Owner修改为Null，并且去唤醒Entry List中的阻塞的线程
- 当Entry List中没有线程阻塞的时候，那么Mark Word就会被还原回去

## 轻量级锁

- 轻量级锁是重量级锁的优化，当synchronized锁定一个对象的时候，此时线程过来执行这个代码块，首先会创建一个Lock Record在自己的栈内存中，并且尝试将Lock Record中的Mark Word与锁对象的Mark Word进行交换，使用CAS。如果发现锁对象的Mark Word为01，也就是无锁状态，那么就会成功交换，将Mark Word修改为了指向这个Lock Record的地址，以及00。并且，Lock Record中也有一个记录指向了这个锁对象
- 当其他线程过来之后，也会尝试去CAS交换Lock Record的Mark Word与锁对象的Mark Word。此时，锁对象的Mark Word是00，也就是轻量级锁状态，那么他们就会去进行锁膨胀的过程，也就是将轻量级锁升级为重量级锁。具体和上面一致，找到一个Monitor，将锁对象的Mark Word修改为重量级锁的形式，并且将线程自己放入到Entry List当中，将Owner修改为持有线程的对象。
- 第一个线程可能会多次去拿这个锁，称为锁重入。当锁重入发生的时候，线程进行CAS也会失败，但是发现这个Lock Record是指向自己的Lock Record，那么这个新的Lock Record的Mark Word就是null。当后面进行释放锁的时候，就会将这些null的Lock Record直接删除。当释放到最后一个Lock Record的时候，就会还原锁对象的Mark Word。

## 偏向锁

- 锁对象的对象头会变为 Thread ... 01 01

- 偏向锁会将一个锁对象偏向给一个线程，当线程第一次去获取这个锁对象时，就会将对象头的Thread字段存取线程id。

- 那如果此时发生了并发，也就是另一个线程尝试获取锁的时候，他会将锁对象变回轻量级锁的形式，对象头还原会原来的对象头，001结尾

- 但是，如果这种变化发生了20次，那么JVM会觉得是不是偏向错了线程，就会将锁对象的对象头保持偏向锁格式，将Thread字段的原线程ID修改为新的线程ID

- 此时，如果第三个线程又来了，它首先还是将偏向锁转换成轻量级锁，然后再次进行修改ThreadID，如果这种修改累计发生了40次，那么JVM就觉得确实是有问题，就不应该偏向任何人，所以这个锁对象的类，以后再次创建的新的对象，都会是轻量级锁的模式，而不再是偏向锁的模式了。


## sun.misc.Contended注解

- 这个注解是防止CPU缓存行的伪共享。
  - CPU中有一级缓存，二级缓存，和三级缓存。每个核心有自己的一级缓存和二级缓存，还有一个与其他核心共享的三级缓存
  - CPU会从内存中预先读取数据，加入到各自的缓存当中
  - 缓存以缓存行为单位，每个缓存行存取64个字节数据
  - 当然，同一份数据可能在不同核心的缓存中存在，此时，如果核心1修改它缓存中与其他核心共享的数据，那么核心2就需要抛弃整个缓存行，从主存中重新获取，保证数据统一
- LongAdder中为什么快，是因为当发现多线程并发累加的时候，会将共享变量分到不同的Cell中，这些Cell会组成一个Cell数组。
- 那这里会出现一个问题，也就是CPU缓存行的伪共享
  - 我们知道，Java中对象的大小是24个字节，16个头和8个value，64位机器中
  - 那么，Cell[]数组是地址连续的，所以，这个数组的两个Cell很大几率会放到核心的同一个缓存行中(64的缓存行足够容纳两个对象 + 数组)
  - 假设，核心1对Cell数组的 0 下标进行修改，而这个数组被同时存在核心1和核心2的缓存行中，那么，这次修改会导致核心2将它的缓存行抛弃，从内存中重新获取一次
  - 反之，如果核心2对数组下标1进行修改，那么也会导致核心1去抛弃整个缓存行
  - 所以，为了解决这个问题，我们最好的是将两个Cell放入到不同的缓存行中，也就是说，下标为Cell[0]这个Cell放入核心1的一个缓存行，下标Cell[1]的这个Cell放入核心2一个缓存行。
  - 这样子，两个核心的缓存行中有不共享的数据，可以放心的自己修改
  - 如何去实现呢？sun.misc.Contented注解就可以将对象的前后加入128字节大小的padding空白，这样子缓存行就无法同时存入两个Cell，保证它们被分开存取。

## Park Unpark

- 每一个线程都有一个Parker对象，由`_counter`,`_cond`和`_mutex`组成
  - 当前线程调用`Unsafe.park()`方法时，会去检查`_counter`，如果是0的话，获得`_mutex`互斥锁，线程进入`_cond`条件变量阻塞，然后把`_counter`设置为0
  - 如果检查`_counter`是1的话，设置为`0`但是不阻塞线程
  - 其他线程调用`Unsafe.unpark(thread)`时，设置`_counter`为1，唤醒`_cond`条件变量中的Thread恢复运行，Thread恢复以后会去把`_counter`改为0。
  - 那如果线程还在运行的时候，其他线程调用了unpark，就会把`_counter`设置为1，此时线程自己去park的时候，就不会阻塞，但是把`_counter`设置为0

# 类加载

- 类加载有三个步骤：
  - 加载：
    - 这里Java中的ClassLoader就会开始工作，Java定义好的有三个ClassLoader
      - BootstrapClassLoader
        - 这是底层由C实现，所以JDK内部其实没有这个的实例化对象，主要加载`lib`目录下的核心类库，``rt.jar``, `resources.jar`
      - ExtensionClassLoader
        - 负责加载`lib/ext`下的jar包
      - AppClassLoader
        - 面向用户的加载器，加载ClassPath下的所有jar包
    - 同时还有一个重要的机制：双亲委派机制
      - 类加载器执行的时候，首先会尝试由父类加载器开始加载，如果父类加载器找不到，再由子类去加载。
      - 父类执行loadClass方法尝试找到类，如果找不到，则才会执行findClass去加载。
      - 一般来说，如果不想打破双亲委派机制的话，就不要重写loadClass方法，重新findClass方法即可
      - 双亲委派机制主要保证了JDK核心代码的加载，避免了重复加载。因为JDK对类的区分不仅仅根据类名，不同类加载器加载的类是不同的类
      - 如果不使用双亲委派机制，然后去写了一个和JDK核心代码完全相同的包名和类名的类，那么就会导致重复加载。
  - 连接
    - 这里分为三个步骤：
      - 验证
        - 文件格式验证：是否符合Class文件规范，包括魔术，主次版本号是否能够被当前虚拟机所处理
        - 元数据验证：查看这个类是否由父类，是否继承了final修饰的类等等
        - 字节码验证：语义是否合法，参数类型是否正确，有没有语法问题
        - 符号引用验证：比如使用其他类、方法、字段时，是否有正确的权限。
      - 准备
        - 这个阶段正式的给类变量进行内存分配，以及设置类变量的初始值（也就是static修饰的变量）。JDK7使用的永久代，类中的内存都划分到方法区中，包括字符串常量池，静态变量等等，JDK8后的元空间则是将字符串常量池、静态变量等放到了堆内存中。
        - 初始值指的是默认的值，如果static变量有值了，则会直接赋值，如果有final修饰，也是直接这里赋值。成员变量则会等待实例创建的时候再赋值。
      - 解析
        - 这个阶段时虚拟机将常量池内的符号引用替换成直接引用。针对接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符。
  - 初始化
    - 这一步JVM才开始执行类中定义的Java程序代码，只有以下6中类必须进行初始化：
      - 遇到`new`,`getstatic`,`putstatic`,`invokestatic`，4条指令，也就是`new`一个类，读一个静态变量，调用一个静态方法
      - 使用反射机制
      - 初始化一个类，如果父类还没有初始化，则先初始化父类
      - 虚拟机启动的时候，`main`方法所在的类
      - default方法，如果接口实现类发生了初始化，那么这个接口也需要初始化。
- 类卸载：
  - 三个要求：
    - 该类所有实例对象都GC
    - 没有任何地方引用这个类
    - 该类的类加载器实例已被GC

# Spring

## Spring IOC

### IoC

- IoC(Inversion of Control)，控制反转是一种思想，将对象的创建权交给IoC容器管理，这样子程序员就可以专注于业务的开发，不用关心对象到底是怎么创建出来的。
- Spring时代我们通过`XML`文件来配置`Bean`，将`Bean`的类路径，属性需不要赋值都配置好，到时候Spring直接从`XML`文件中读取相关的配置，就可以帮我们创建好`Bean`，我们只需要在特定的地方引入即可

### Spring Bean

- ```xml
  <!-- Constructor-arg with 'value' attribute -->
  <bean id="..." class="...">
     <constructor-arg value="..."/>
  </bean>
  ```

- 可以使用许多注解声明一个Bean

  - `@Component`
  - `@Service`
  - `@Repository`
  - `@Controller`

- `@Bean`注解的话用来注解一个方法，这个方法的返回值可以作为一个Bean被Spring管理。

### 依赖注入的方式

- 我们可以使用`@AutoWired`和`@Resource`两种注解来对依赖进行注入

- `AutoWired`

  - `@AutoWired`是Spring内置的注解，它默认是根据类进行匹配`byType`。当一个接口有多个实现类时，就会出现一个问题，Spring找不到你真正想要注入的实现类了，所以它的注入方式会变成`byName`，此时我们的变量名就得和实现类的名字一样

  - ```java
    // 报错，byName 和 byType 都无法匹配到 bean
    @Autowired
    private SmsService smsService;
    // 正确注入 SmsServiceImpl1 对象对应的 bean
    @Autowired
    private SmsService smsServiceImpl1;
    // 正确注入  SmsServiceImpl1 对象对应的 bean
    // smsServiceImpl1 就是我们上面所说的名称
    @Autowired
    @Qualifier(value = "smsServiceImpl1") //最好使用@Qualifier显式指定名称
    private SmsService smsService;
    ```

- `@Resource`

  - 这个注解式JDK提供的注解，默认为`byName`，如果名称匹配不到，就改为`byType`'

  - 这个注解有两个属性：`name`、`type`

    - ```java
      public @interface Resource {
          String name() default "";
          Class<?> type() default Object.class;
      }
      ```

  - 如果只指定了`name`，就`byName`，如果只指定了`type`，就`byType`，如果都指定了，就一起

  - ```java
    // 报错，byName 和 byType 都无法匹配到 bean
    @Resource
    private SmsService smsService;
    // 正确注入 SmsServiceImpl1 对象对应的 bean
    @Resource
    private SmsService smsServiceImpl1;
    // 正确注入 SmsServiceImpl1 对象对应的 bean（比较推荐这种方式）
    @Resource(name = "smsServiceImpl1")
    private SmsService smsService;
    ```

### Bean的作用域

- Spring中Bean的作用域有好几种，但是我们一般使用单例的

  - `Singleton`：单例，IoC容器中只有一个bean实例
  - `Prototype`：每一次获取都会创建一个Bean实例
  - `Request`
  - `Session`
  - `Application/Global-Session`
  - `WebSocket`

- 后面四种都是web应用使用的。

- 通过注解`@Scope`可以去声明一个Bean的作用域

  - ```java
    @Bean
    @Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE)
    public Person personPrototype() {
        return new Person();
    }
    ```

### Bean的生命周期

- Bean首先由Spring发现其路径，然后通过反射机制构造出来，接着如果Bean实现了一些***Aware接口，就调用这些接口相关的一些方法，如果有`BeanPostProcessor`对象的话，那么就会调用这个对象的`postProcessBeforeInitialization()`方法，如果Bean实现了一个`InitializingBean`接口的话，就调用其中的`afterPropertiesSet()`方法，接着调用Bean后处理器方法`postProcessAfterInitialization()`。
- 当容器关闭的时候，如果Bean实现了`DisposableBean`接口，就调用`destroy()`方法。
- ![Spring Bean 生命周期](https://images.xiaozhuanlan.com/photo/2019/b5d264565657a5395c2781081a7483e1.jpg)

## Spring AOP

### Spring AOP和AspectJ的区别

- Spring AOP基于的是动态代理，而AspectJ基于的是字节码操作。
- Spring AOP属于运行时增强，通过动态代理为我们的方法加上增加，而AspectJ属于编译时增强。

### AspectJ定义的通知类型

- **Before**（前置通知）：方法调用之前触发
- **After**（后置通知）：方法调用之后触发
- **AfterReturning**（返回通知）：目标方法调用完成，返回结果值时触发
- **AfterThrowing**（异常通知）：抛出/触发异常的时候触发
- **Around**（环绕通知）：可以拿到目标对象的方法调用，所以我们就可以在方法的前后随意添加想要的代码。
- 使用`@Order`去定义切面的顺序。

## SpringMVC

### SpringMVC的核心组件

- SpringMVC的核心组件其实就是我们在请求过来的时候，SpringMVC帮我们做了什么
  - `DispatcherServlet`：这是核心的中央处理器，帮我们接收，分发请求，响应给客户端
  - `HandlerMapping`：处理器映射器，通过URL去找到能处理这个请求的`Handler`，将请求涉及到的拦截器和`Handler`一起封装
  - `HandlerAdapter`：处理器适配器，根据`HandlerMapping`找到的`Handler`，适配的执行`Handler`
  - `Handler`：请求处理器，处理真正的请求的处理器
  - `ViewResolver`：视图处理器，根据`Handler`返回的逻辑视图，解析真正的视图，传递给`DispatcherServlet`响应客户端。
- 请求过来的时候，先到`DispatcherServlet`中调用`HanlderMapping`，去根据`URL`找到能够处理的`Handler`，然后`DispatcherServlet`通过调用`HandlerAdapter`去执行`Handler`。这里是一个适配器模式的使用，`DispatcherServlet`不需要面对`Handler`的细节，直接调用`HandlerAdapter`就可以调用到真正的`Handler`了。`Handler`执行结束以后，返回一个`ModelAndView`给`DispatcherServlet`，`ModelAndView`包含了数据以及一个逻辑视图，`ViewResolver`会去解析这个逻辑视图，找到真正的`View`，然后把`Model`数据传递给这个`View`，最终返回给浏览器`View`
- ![img](https://oss.javaguide.cn/github/javaguide/system-design/framework/spring/de6d2b213f112297298f3e223bf08f28.png)

### SpringMVC的全局异常处理

- `@ControllerAdvice`可以注解一个全局异常处理类，这个类中的方法使用`@ExceptionHandler`去指定处理具体什么异常

  - ```java
    @ControllerAdvice
    @ResponseBody
    public class GlobalExceptionHandler {
    
        @ExceptionHandler(BaseException.class)
        public ResponseEntity<?> handleAppException(BaseException ex, HttpServletRequest request) {
          //......
        }
        @ExceptionHandler(value = ResourceNotFoundException.class)
        public ResponseEntity<ErrorReponse> handleResourceNotFoundException(ResourceNotFoundException ex, HttpServletRequest request) {
          //......
        }
    }
    ```

  - 当有异常的时候，`DispatcherServelt`会与`ExceptionHandlerExceptionResolver`交互来处理异常，后者可以去查找`@ExceptionHandler`注解的方法，然后把异常映射到这些方法上面。

  - `ExceptionHandlerExceptionResolver`的`getMappedMethod`就会去找对应的处理异常的方法，然后按照匹配度最高的那一个返回。

  - 这个匹配度：

    - 如果有方法注解了详细对应的异常`@ExceptionHandler`，那么直接使用这一个方法
    - 如果没有详细对应的话，那么去查找有没有使用`@ExceptionHandler`去声明这个异常的父类，比如`Exception`或`RuntimeException`
    - 那如果有多个父类呢？就会去选择最接近的父类
    - 比如我们有一个`NullPointerExcepion`想要去处理，如果刚好有一个方法注解了`@ExceptionHandler(value = NullPointerException.class)`，那就直接选择。如果没有的话，看看有没有注解了`@ExceptionHandler(value = Exception.class) 或者 @ExceptionHandler(value = RuntimeException.class)`。如果这两个注解都有，则会去选择`RuntimeException`的处理器，因为`RuntimeException`离`NullPointerException`的继承链更近。

## Spring中的事务

### 编程式事务

- 通过`TranscationTemplate`或者`TranscationManager`手动控制管理事务。

- `TransactionTemplate`管理：

  - ```java
    @Autowired
    private TransactionTemplate transactionTemplate;
    public void testTransaction() {
            transactionTemplate.execute(new TransactionCallbackWithoutResult() {
                @Override
                protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) {
    
                    try {
    
                        // ....  业务代码
                    } catch (Exception e){
                        //回滚
                        transactionStatus.setRollbackOnly();
                    }
    
                }
            });
    }
    ```

- `TransactionManager`管理：

  - ```java
    @Autowired
    private PlatformTransactionManager transactionManager;
    
    public void testTransaction() {
    
      TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition());
              try {
                   // ....  业务代码
                  transactionManager.commit(status);
              } catch (Exception e) {
                  transactionManager.rollback(status);
              }
    }
    
    ```

- `TranscationTemplate`提供了模板化的方法来管理事务，使用起来没有那么复杂，如果是简单的事务操作，直接使用它即可，我们专注于业务逻辑即可，我们可以看到代码中甚至没有提交的操作，它封装好了

- `TranscationManager`则提供了更灵活的选择，我们可以显示的控制事务的提交，回滚，不过使用起来就更加复杂。

### Spring事务管理接口

- 主要三个重要的接口：

  - `PlatformTransactionManager`：平台事务管理器，Spring事务管理的核心
  - `TranscationDefinition`：事务定义信息（隔离级别，传播行为，超时，只读，回滚规则）
  - `TranscationStatus`：事务运行状态

- `PlatformTransactionManager`:

  - 这个接口由各个的数据库服务来实现，它负责获取事务，根据`TranscationDefinition`中的信息来管理事务

  - ```java
    package org.springframework.transaction;
    
    import org.springframework.lang.Nullable;
    
    public interface PlatformTransactionManager {
        //获得事务
        TransactionStatus getTransaction(@Nullable TransactionDefinition var1) throws TransactionException;
        //提交事务
        void commit(TransactionStatus var1) throws TransactionException;
        //回滚事务
        void rollback(TransactionStatus var1) throws TransactionException;
    }
    ```

- `TranscationDefinition`:

  - 定义了五种事务属性：
    - 隔离级别
    - 传播行为
    - 回滚规则
    - 是否只读
    - 事务超时

- `TransactionStatus`:

  - 记录了事务的状态，获取或判断事务的相应状态信息

  - ```java
    public interface TransactionStatus{
        boolean isNewTransaction(); // 是否是新的事务
        boolean hasSavepoint(); // 是否有恢复点
        void setRollbackOnly();  // 设置为只回滚
        boolean isRollbackOnly(); // 是否为只回滚
        boolean isCompleted; // 是否已完成
    }
    ```

### 事务属性

#### 重点关注事务传播行为

- 事务传播行为是当事务方法被另一个事务方法调用的时候，我们得指定事务的传播行为，是继续现有的事务，还是开启一个新事务。一个事务方法回滚，调用它的事务方法是否回滚。

- `TranscationDefinition.PROPAGATION_REQUIRED`

  - 默认的一个事务传播行为：

    - 如果外部方法没有开启事务，那么被`PROPAGATION_REQUIRED`修饰的方法内部开启一个新事务

    - 如果外部方法也是`PROPAGATION_REQUIRED`修饰，则两个方法属于一个事务，一个方法回滚，整个事务都会回滚

    - ```java
      //一个方法回滚，整个事务回滚
      @Service
      Class A {
          @Autowired
          B b;
          @Transactional(propagation = Propagation.REQUIRED)
          public void aMethod {
              //do something
              b.bMethod();
          }
      }
      @Service
      Class B {
          @Transactional(propagation = Propagation.REQUIRED)
          public void bMethod {
             //do something
          }
      }
      ```

- `TranscationDefinition.PROPAGATION_REQUIRED_NEW`

  - 会创建一个新事务，与外部事务。不管外部有没有创建事务，被`PROPAGATION_REQUIRED_NEW`修饰的方法都会开启一个新的事务，相互独立，互不干扰。 

  - ```java
    //a方法的事务实际上是挂起了，直到b方法的事务提交或者发生异常
    //这里如果a方式异常，b的事务不会回滚
    //b发生异常回滚，但是没有捕获异常，抛出了，那么如果这个异常满足了a的回滚规则，a也会去回滚
    @Service
    Class A {
        @Autowired
        B b;
        @Transactional(propagation = Propagation.REQUIRED)
        public void aMethod {
            //do something
            b.bMethod();
        }
    }
    @Service
    Class B {
        @Transactional(propagation = Propagation.REQUIRES_NEW)
        public void bMethod {
           //do something
        }
    }
    ```

- `TranscationDefinition.PROPAGATION_NESTED`：

  - 这是嵌套事务，如果当前没有事务的话，内部方法执行与`PROPAGATION_REQUIRED`一样的逻辑，但是如果外部有事务，则内部方法嵌套执行

  - 因为是嵌套的事务，这个事务并不是一个全新的事务，它拥有独立的提交和回滚，当嵌套事务进行回滚的时候，只会回滚到它的开始位置，不会影响到外部的事务。

  - 此时，如果外部事物回滚的话，这个嵌套事务也会回滚。

  - ```java
    //如果b发生了回滚，a不会回滚，除非有符合a回滚的异常抛出
    //a发生了回滚，b也会回滚，因为实际上它们共用一个物理事务
    @Service
    Class A {
        @Autowired
        B b;
        @Transactional(propagation = Propagation.REQUIRED)
        public void aMethod {
            //do something
            b.bMethod();
        }
    }
    @Service
    Class B {
        @Transactional(propagation = Propagation.REQUIRES_NEW)
        public void bMethod {
           //do something
        }
    }
    ```

#### 事务隔离机制

- 枚举类`Isolation`中有五个隔离机制，其实和MySQL的隔离机制一致，只不过多了一个DEFAULT，默认InnoDB的可重复读Repeatable Read

#### 事务超时属性

- 一个事务允许执行的最长时间。如果超过该事件限制但是事务还未完成，就自动回滚事务。`TranscationDifition`中以int值表示时间，单位为秒，默认值-1，表示事务没有超时时间或者取决于底层事务系统

#### 事务只读

- 这个主要是为了保证多条查询语句的原子性，所以开启事务支持
- 因为MySQL默认是`autocommit`，执行一条语句就直接提交。但是如果开启了事务，指明了只读，MySQL就会去优化它的执行，不会出现我多条SQL语句，第一个查询和第二个查询之间数据被修改的情况。
- 又复习一个MVCC的事务：
  - 默认是`autocommit`，所以每次查询都会创建一个新事务然后提交，`READ VIEW`记录的`m_low_trx_id`肯定是最新值，可以读到最新的数据
  - 如果开启事务，那根据不同的隔离机制，默认可重复读，则可以保证数据统计的正确性，因为我们读的都是开启事务那一刻的快照读，读的都是历史版本。

#### 事务回滚规则

- 指定了哪些异常会导致事务回滚。默认的话只有遇到运行时异常(`RuntimeException`)才会回滚，`Error`也会回滚，而受检时异常(`Exception`)不会回滚。

### Spring AOP的自调用问题(宁德时代面试)

- 因为SpringAOP是一个运行时增强，它去创建一个动态代理对象，并在方法的前后调用，这个调用如果是其他类来调用代理对象的话，才会拦截，但是如果是在方法内部调用的话，就无法拦截了。

## 什么是自动装配

- `SpringBoot`定义了一个接口规范：在SpringBoot启动的时候会去扫描外部引用`jar`包中的`META-INF/spring.factories`文件，然后将文件中配置的类型信息加载到Spring容器。
- 自动装配可以简单理解为：**通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能。**

### 怎么实现的自动装配

- 通过核心注解`@SpringBootApplication`

  - `@SpringBootApplication`可以看作三个注解的合集：`ComponentScane`,`EnableAutoConfiguration`和`@Configuration`

    - `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制

    - `@Configuration`：允许在上下文中注册额外的 bean 或导入其他配置类

    - `@ComponentScan`：扫描被`@Component` (`@Service`,`@Controller`)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。如下图所示，容器中将排除`TypeExcludeFilter`和`AutoConfigurationExcludeFilter`。

  - ```java
    @Target({ElementType.TYPE})
    @Retention(RetentionPolicy.RUNTIME)
    @Documented
    @Inherited
    <1.>@SpringBootConfiguration
    <2.>@ComponentScan
    <3.>@EnableAutoConfiguration
    public @interface SpringBootApplication {
    }
    @Target({ElementType.TYPE})
    @Retention(RetentionPolicy.RUNTIME)
    @Documented
    @Configuration //实际上它也是一个配置类
    public @interface SpringBootConfiguration {
    }
    
    ```

- 这个`@EnableAutoConfiguration`就是自动配置的重要注解

  - ```java
    @Target({ElementType.TYPE})
    @Retention(RetentionPolicy.RUNTIME)
    @Documented
    @Inherited
    @AutoConfigurationPackage //作用：将main包下的所有组件注册到容器中
    @Import({AutoConfigurationImportSelector.class}) //加载自动装配类 xxxAutoconfiguration
    public @interface EnableAutoConfiguration {
        String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration";
    
        Class<?>[] exclude() default {};
    
        String[] excludeName() default {};
    }
    ```

  - `@Import`注解可以导入配置类，将配置类中的定义的`bean`注册到Spring中，这里的话导入了一个选择器`AutoConfigurationImportSelector`，可以动态的决定导入哪些`bean`或配置类

- `AutoConfigurationImportSelector`做了什么？

  - 继承结构如下：

  - ```java
    public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered {
    
    }
    public interface DeferredImportSelector extends ImportSelector {
    
    }
    public interface ImportSelector {
        String[] selectImports(AnnotationMetadata var1);
    }
    ```

  - 我们看到，它实际上实现了`ImportSelector`，这个接口有一个方法`selectImports`，可以获取所有符合条件的类的全限定名，这些类就可以用于加载到IOC容器中

  - ```java
    //AutoConfigurationImportSelector中的selectImports方法
    private static final String[] NO_IMPORTS = new String[0];
    
    public String[] selectImports(AnnotationMetadata annotationMetadata) {
            // <1>.判断自动装配开关是否打开
            if (!this.isEnabled(annotationMetadata)) {
                return NO_IMPORTS;
            } else {
              //<2>.获取所有需要装配的bean
                AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader);
                AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); //重点关注
                return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());
            }
        }
    ```

  - 看到，这里调用了一个`getAutoConfigurationEntry`方法，这个方法负责加载自动配置类，调用链为：

    - ![img](https://oss.javaguide.cn/github/javaguide/system-design/framework/spring/3c1200712655443ca4b38500d615bb70~tplv-k3u1fbpfcp-watermark.png)

    - 源码：

    - ```java
      private static final AutoConfigurationEntry EMPTY_ENTRY = new AutoConfigurationEntry();
      
      AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) {
              //<1>.判断一下自动装配开关是否开启，默认spring.boot.enableautoconfiguration=true
              if (!this.isEnabled(annotationMetadata)) {
                  return EMPTY_ENTRY;
              } else {
                  //<2>. 用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName。
                  AnnotationAttributes attributes = this.getAttributes(annotationMetadata);
                  //<3>. 获取需要自动装配的所有配置类，读取META-INF/spring.factories
                  List<String> configurations = this.getCandidateConfigurations(annotationMetadata, attributes); 
                  //<4>.
                  configurations = this.removeDuplicates(configurations);
                  Set<String> exclusions = this.getExclusions(annotationMetadata, attributes);
                  this.checkExcludedClasses(configurations, exclusions);
                  configurations.removeAll(exclusions);
                  //不是所有都会加载，配置类中的@ConditionalOnXXX会开始筛选，有些不满足条件的就不会加载
                  configurations = this.filter(configurations, autoConfigurationMetadata);
                  this.fireAutoConfigurationImportEvents(configurations, exclusions);
                  return new AutoConfigurationImportSelector.AutoConfigurationEntry(configurations, exclusions);
              }
          }
      
      ```

### 依赖注入的方式

# MySql

## MySql索引

### B树与B+树

- B树的节点既存放Key也存放数据(指针信息)，而B+树只有叶子节点存放
- B+树的叶子节点通过一条引用链连接到相邻的叶子节点，B树的叶子节点是独立的。
- 因为B树存了指针，所以查询的时候可能到一半就停止了，而B+树效率就稳定，直到叶子叶子节点
- B树在范围查找的时候，得先找到下界，然后通过中序遍历找到上界。而B树直接遍历叶子节点即可。
- 比如查找1 - 12，B树查找到1以后，还得中序遍历找到12，而B+树直接遍历叶子节点从1找到12即可。
- ![img](https://img-blog.csdnimg.cn/20190905145443436.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjYxMTMw,size_16,color_FFFFFF,t_70)
- MyISAM与InnoDB都是使用B+树，但是实现方式不一样
  - MyISAM，B+树叶子节点的data域存放的是数据记录的地址，找到这个地址以后，再通过地址去读取真正的数据，这个就是非聚簇索引
  - InnoDB，B+树的叶子节点直接保存完整的数据记录，找到索引以后直接就获取到值了。注意，这里只有主键作为索引的时候才是这样。也叫做聚簇索引。而其余的索引都是辅助索引，data域存放的是主键id。走主索引的时，直接拿取数据，走辅助索引时，拿到主键以后再走一次主索引。

### 索引类型

- 按底层存储方式

  - 聚簇索引：
    - `InnoDB`中的主键索引便是聚簇索引，索引结构与数据存放在一起。
    - `.ibd`文件包含了表的索引和数据。
    - 优点：
      - 查询速度非常快，聚簇索引还可以少一次IO操作
      - 对排序或者范围查找非常快，因为叶子节点本身就是有序的了。
    - 缺点：
      - 依赖有序的数据
      - 更新代价较大，如果修改索引列，索引也得修改(得重新排序)，而且聚簇索引的叶子中还存放着数据，重新排序代价就很大，所以主键索引来说，作为索引的主键一般是不可以修改的。


  - 非聚簇索引：
    - `InnoDB`中的二级索引，也就是辅助索引，就是非聚簇索引，索引结构与主键的ID值放在一起，与真正的数据分开存放。MyISAM中不管是主键索引还是辅助索引都是非聚簇索引
    - 叶子节点也不一定存放ID，MyISAM存放的就是指针
    - 优点：
      - 更新代价比较少，因为存放的是指针，所以不需要移动整个数据
    - 缺点：
      - 一样需要依赖有序数据
      - 二次回表，辅助索引中，因为叶子节点放的是主键ID值，所以如果不是覆盖索引的话，那么需要去主键再去查找一次。


- 按应用维度：

  - 主键索引：加速查询 + 列值唯一（不可以有 NULL）+ 表中只有一个。
  - 普通索引：仅加速查询。
  - 唯一索引：加速查询 + 列值唯一（可以有 NULL）。
  - 覆盖索引：一个索引包含（或者说覆盖）所有需要查询的字段的值。
  - 联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。
  - 全文索引：对文本的内容进行分词，进行搜索。目前只有 `CHAR`、`VARCHAR` ，`TEXT` 列上可以创建全文索引。一般不会使用，效率较低，通常使用搜索引擎如 ElasticSearch 代替。

### 主键索引

- 主键列使用的就是主键索引。当没有指明主键的时候，InnoDB会去看看有没有非空唯一索引，如果有就使它成为主键，如果没有的话就创建一个6Byte的自增主键。

### 联合索引（最左匹配原则）

- 只要记住，联合索引的有序是从左往右的，左边内部右边才是有序的。比如(a,b)，a是全局有序的，而b是在a等于某个值的时候才有序。

- `Q1: select * from t_table where a > 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？`
  - 只用到了a，因为a > 1的范围里b是无序的
- `Q2: select * from t_table where a >= 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？`
  - 用到了ab，因为在 a = 1的时候，b是有序的，可以减少搜索范围。
- `Q3: SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？`
  - `BETWEEN ... AND`在MySQL实现是左闭右闭的，所以当 a = 2 和 a = 8时，b都是有序的，可以缩小范围
- `Q4: SELECT * FROM t_user WHERE name like 'j%' and age = 22，联合索引（name, age）哪一个字段用到了联合索引的 B+Tree？`
  - 同理，name和age都使用到了，当name = j时，age是有序的。



## MySql日志

### redo Log（重做日志）

- `Innodb`独有的，`MySql`有了崩溃恢复的能力，当`MySql`挂了或者宕机了，可以从`redo Log`中恢复数据
- `MySql`查询时，会将一页的数据放入`Buffer Pool`中，下次如果击中缓存了，则直接从缓存取。修改数据时也是先更新缓存，然后将更新的具体内容放入`redo log buffer`中，再去刷盘到`redolog`文件中
- 刷盘时机：
  - 事务提交：
    - `innodb_flush_log_at_trx_commit`参数可以控制刷盘时机
    - 0：表示事物提交不刷盘，由守护线程1s执行一次刷盘。可能会丢失1s的数据
    - 1：表示每次事务提交的时候都刷盘，这种最安全
    - 2：每次事务提交到系统的`page cache`中，再由守护线程刷盘。这种情况`MySql`挂机了没有关系，但是如果整个电脑宕机了就可能丢失1s的数据
  - `log buffer`空间不足：`log buffer`中缓存的 `redo log`占了容量的一半，就要将日志刷新到磁盘中
  - 事物日志缓冲区满
  - CheckPoint：`InnoDB`定期检查内存中的数据，如果有脏数据，就刷盘到磁盘中。同时将响应的`redo log`刷入到磁盘
  - 后台刷新线程：上面提到了，将脏页刷入到磁盘
  - 正常关闭服务器

### bin log

- `bin log`用来同步数据，`MySql`在数据备份，主备，主主，主从都需要保证数据的一致性。使用`bin log`就可以保证数据的一致性。什么存储引擎，只要是发生了表数据更新，都有bin log的产生。
- 记录格式，由`binlog_format`参数指定：
  - `statement`
    - 记录`SQL`语句的原文，同步数据的时候会执行`SQL`语句，但是这里有个问题，就是如果使用一些可能会造成数据不一致的语句。比如 `now()`
  - `row`
    - 通过`mysqlbinlog`工具解析`row`格式下记录的内容。可以将`SQL`语句以及具体操作的数据记录下来。但是这就会造成更大的空间损耗，`IO`就会更耗资源
  - `mixed`
    - `MySql`会判断这条语句是否会引起数据不一致，如果会就使用`row`，否则就使用`statement`
- 写入时机
  - 和`redo log`类似，在事务执行的时候，先写入到`binlog cache`中，事务提交的时候，再将`binlog cache`写入到`binlog`中。
  - 因为事务需要保证一致性，所以整个事务的语句都需要写到`binlog cache`中，不可以分开写。每个线程都有一块内存空间作为`binlog cache`
  - 每次事务提交以后，会首先`write`到 `page cache`中，然后再`fsync`到磁盘中
  - 可以通过`sync_binlog`参数控制`write`和`fsync`的时机
    - 0:表示提交事务只`write`，由系统判断什么时候`fsync`，如果还没有`fsync`但是宕机了，就会丢失`binlog cache`中的数据
    - 1:表示提交事务都会执行`fsync`，就和`redo log`设置为1一样
    - 当然还可以设置`N`，表示累积到N个事务才会`fsync`
- 两阶段提交：
  - 有一个问题，当我们的`redo log`和`bin log`数据不统一时，怎么解决？
  - 我们知道`redo log`是每次数据发生更新的时候就会写，而`bin log`只有在事务提交的时候才会写。
  - 假设此时，我们在执行某条更新语句的时候，成功写入了`redo log`，但是`bin log`发生了异常，那么`redo log`和`bin log`中的逻辑就不一致了。原库进行数据恢复的时候可以成功恢复，但是从库进行备份或者使用`bin log`复制的时候，就没有这条更新
  - `InnoDB`采用了两阶段提交：
    - `redo log`在执行更新语句的时候，设置为 `prepare`阶段
    - 当`bin log`成功写入的时候，将`redo log`设置为`commit`
    - 这样子，如果`bin log`发生异常，在数据恢复的时候，会发现`redo log`处在`prepare`阶段，而且没有对应的`bin log`，那么事务就会回滚
    - 但是，如果`redo log`在设置`commit`阶段发生了异常，此时`bin log`是正常执行的，可以通过事务`id`找到对应的`bin log`日志，所以就不会回滚。

### undo log（回滚日志）

- 我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行**回滚**，在 MySQL 中，恢复机制是通过 **回滚日志（undo log）** 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 **回滚日志** 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。

### 总结

MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。

`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。

## 事务隔离级别

- 四种事务隔离级别：
  - 读未提交
    - 会发生脏读，不可重复读和幻读
    - 事务1在事务为结束的时候，可以读取到事务2还没提交的数据。如果事务2回滚了，那么事务1读取的就是脏数据![img](https://oss.javaguide.cn/github/javaguide/2019-31-1%E8%84%8F%E8%AF%BB(%E8%AF%BB%E6%9C%AA%E6%8F%90%E4%BA%A4)%E5%AE%9E%E4%BE%8B.jpg)
  - 读已提交
    - 会发生不可重复读和幻读
    - 不可重复读就是，事务1在事务未结束的时候，事务2提交了某个数据，事务1再次读取这个数据的时候就会第一次读取的不一样。
    - ![img](https://oss.javaguide.cn/github/javaguide/2019-32-1%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E5%AE%9E%E4%BE%8B.jpg)
  - 可重复读
    - 会出现幻读
    - ![img](https://oss.javaguide.cn/github/javaguide/2019-33-2%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.jpg)
    - 幻读就是，当事务1未结束的时候，事务2插入了一条新数据，此时事务1就可以查看到这个新数据
    - ![img](https://oss.javaguide.cn/github/javaguide/phantom_read.png)
    - SQL 脚本 1 在第一次查询工资为 500 的记录时只有一条，SQL 脚本 2 插入了一条工资为 500 的记录，提交之后；SQL 脚本 1 在同一个事务中再次使用当前读查询发现出现了两条工资为 500 的记录这种就是幻读。
  - 可串行化
    - 所有事物依次执行，这样事物之间就不会出现脏读，不可重复读和幻读了
  - 要解决幻读，也可以在可重复读的基础上
    - 给表上锁
    - 给表加入间隙锁

## MySQL锁

### 表级锁和行级锁

- MyISAM仅支持表级锁，上锁就上一张表，并发性能很差
- InnoDB支持行级锁，默认也为行级锁，粒度更小，性能更好。
- 行级锁需要注意的是：
  - 在使用update和delete语句时，如果where后面没有命中唯一索引，那就会走全表扫描，也就是全表上锁。

### InnoDB中有几类行级锁

- 记录锁：单个行记录上的锁

- 间隙锁：锁定一个范围，不包含记录本身

- 临键锁：Record Lock + Gap Lock，锁定一个范围包含记录本身，主要解决幻读问题的产生。

- RR下，默认是Next-key Lock，但是如果索引是唯一的或者是主键，并且`WHERE`条件后只有一个等值查询且命中了，那么就会退化为Record Lock，如果是等值查询但是没有这个数据，就会退化为间隙锁：

  - 数据存在![img](https://segmentfault.com/img/remote/1460000040129115)

    - ```
      mysql> begin; select * from t where id = 10 for update;
      ```

    - 添加的是行锁

  - 数据不存在

    - ```
      mysql> select * from t where id = 11 for update;
      ```

    - 添加的是间隙锁，区间为(10,15)，左开右开，添加12会拒绝，15不会

  - 范围查询：

    - ```
      mysql> begin; select * from t where id >= 10 and id < 11 for update;
      ```

    - 添加间隙锁，以及id为10的行锁，以及id = 15之前的间隙锁，范围为[10, 15)

    - ```
      mysql> begin; select * from t where id > 10 and id <= 15 for update;
      ```

    - Next-key-lock为(10, 15]，但是这里有一个bug，在较早版本的时候，会把第一个不满足条件的范围也锁上，这个例子第一个不满足 <=15的范围为20，所以id=20也会锁上。


### 共享锁和排他锁

- 无论是表级锁还是行级锁，都存在共享锁S和排他锁X这两类
  - 共享锁：事务读取记录时获取共享锁`SELECT * FROM t FOR SHARE`，也叫读锁，读锁可以兼容
  - 排他锁：写锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取，如果有一个记录加上了写锁，其他事务都不可以加任何类型的锁了
    - 那我就是要读怎么办？使用快照读

### 意向锁是什么？

- 如果使用表锁时，为了判断一个表中记录有没有上锁，就要使用意向锁来快速判断
  - 意向共享锁(IS锁)：事务有意向往表中的某些记录加S锁，加S锁前必须获取IS锁
  - 意向排他锁(IX锁)：事务有意向往某些记录加排他锁X锁，加X锁必须先获取IX锁
- 意向锁之间互相兼容：因为意向锁主要是给表锁判断的，行锁之间由行锁自己判断。
- 意向锁除了IS锁与表锁S锁不互斥，其余都互斥(注意，这里都是指意向锁与表锁之间的互斥关系，意向锁与行锁之间并不互斥，你拿行锁之间肯定得先获取意向锁)

## MVCC(Multi-Version Concurrency Control)

- 为了保证并发时多个事务的一致性和隔离性，通过给数据加上版本号的形式，创建数据快照，使得各个事务之间不会相互影响
  - 读操作：
    - 事务会读取不晚于当前时间的最新版本，其他事务对此数据如果后续进行了更改，也不会影响此次读取，因为是数据快照
  - 写操作
    - 事务写的时候，会创建一个新的数据版本，然后才写入数据库，这个新数据会带有事务的版本号，可以让其他事务进行查看版本号加一区分。原始的数据也依然存在，因为可能其他事务在更改数据之前就在读了。
  - 事务提交和回滚：
    - 事务提交时，他做的修改变成数据库最新版本，其他事务可见
    - 回滚时：所作的修改进行撤销，其他事务不可见
  - 版本回收：
    - 因为版本不可以无线增长，所以MVCC会定期进行版本回收。

### 一致性非锁定读和锁定读

- 一致性非锁定读
  - 给数据加上版本号，修改的时候版本号加一，读取的时候对比可见版本号与记录的版本号。如果可见版本号大于记录的版本号，说明记录可见。
  - `InnoDB`的MVVC实现就是非锁定读。如果读取一个正在修改的数据，那么不会等待锁释放，而是去读取历史数据，这叫做快照读。
  - 所以可以实现可重复读。因为就算数据确实的被一个事务提交修改了，那么对于当前事务来说，他的版本号还没有进行更新，所以看不到最新的更改，使得同一个事务中实现了可重复读。
- 锁定读：
  - 如果执行的不是普通的`select`的语句，而是：
    - `select ... lock in share mode`
    - `select ... for update`
    - `insert`、`update`、`delete` 操作
    - 就是锁定读
  - 锁定读的话会去读到最新版本的数据，也叫做当前读。读到的数据会加锁。
    - `select ... lock in share mode`，会加入读锁 S锁，其他事务也可以加 S锁，但是不可以加写锁 X 锁。
    - `select ... for update, insert、 update、delete`操作的话，会加X锁，其他事务不可以加任何锁了。
  - 上面提到，如果使用一致性非锁定读的话，就算该数据有X锁，也可以读到，只不过是老的版本，快照读。此时可以防止一部分幻读的产生。但是如果使用当前读，因为是读取最新版本，所以有可能会突然多一条数据，这就发生了幻读。那么`InnoDB`为了解决`可重复读下`使用当前读出现的幻读，就给记录加上`间隙锁 Next-key Lock`，防止事务在间隙间插入数据。

### InnoDB对MVCC的实现

- 主要通过三个重要的东西实现：`隐藏字段`,`Read view`, `undo log`

  - `隐藏字段`:

    - `InnoDB`引擎为每个数据添加了额外的隐藏字段
    - `DB_TRX_ID`：最后一次插入或更新改行的事务id
    - `DB_ROLL_PTR`:回滚指针，如果当前事务对这个数据不可见的话，或者这个数据正在被上锁，为了实现非锁定读，那么就会通过这个指针找到`undo log`，从中选取一个过去的版本
    - `DB_ROW_ID`：如果没有设置主键且该表没有唯一非空索引，那么`InnoDB`通过该id来生成聚簇索引。

  - `Read VIEW`：

    - 是一个文件，创建时机有隔离级别决定

    - 主要存储了

      - ```c++
        class ReadView {
          /* ... */
        private:
          trx_id_t m_low_limit_id;      /* 大于等于这个 ID 的事务均不可见 */
        
          trx_id_t m_up_limit_id;       /* 小于这个 ID 的事务均可见 */
        
          trx_id_t m_creator_trx_id;    /* 创建该 Read View 的事务ID */
        
          trx_id_t m_low_limit_no;      /* 事务 Number, 小于该 Number 的 Undo Logs 均可以被 Purge */
        
          ids_t m_ids;                  /* 创建 Read View 时的活跃事务列表 */
        
          m_closed;                     /* 标记 Read View 是否 close */
        }
        ```

      - `m_low_limit_id`：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见

      - `m_up_limit_id`：活跃事务列表 `m_ids` 中最小的事务 ID，如果 `m_ids` 为空，则 `m_up_limit_id` 为 `m_low_limit_id`。小于这个 ID 的数据版本均可见

      - `m_ids`：`Read View` 创建时其他未提交的活跃事务 ID 列表。创建 `Read View`时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。`m_ids` 不包括当前事务自己和已提交的事务（正在内存中）

      - `m_creator_trx_id`：创建该 `Read View` 的事务 ID

    - 怎么理解？

      - 使用版本控制，那么当事务创建`Read View`的时候，如果有一些数据被其他事务后续修改了，那么我们肯定是不希望再当前事务执行的时候看见的，所以有一个最大的事务ID，也就是当前事务ID后的事务ID
      - 也有一种情况，就是我启动事务的时候，其他事务还有没有提交的，那这些事务后续提交以后的修改我也不希望看见，所以会记录一个还在获取的事务id们，就算这个id比我们此时的id小，那如果它后续修改了但是我们还没结束，那他的修改我也不想看见，所以将最小的id记录一下，当作我的分界。只有那些数据中的事务id比这个临界小，我才可以看的见
      - 如果没有活跃的事务，那我们可以放心的将分界设置为下一个当前事务ID后的事务ID

  - `undo log`

    - 主要有两个作用：
      - 事务回滚时可以恢复到修改之前的样子。
      - MVVC，我们上面提过，如果数据正在上锁，或者是对当前事务不可见的话，那么就通过`undo log`获取到历史版本进行操作。
    - 主要分为两种
      - `insert undo log`
        - 指的是`insert`操作产生的`undo log`，因为`insert`操作产生的新值，版本号肯定是最新的，其他事务肯定是看不到的，除非使用当前读。所以这个`undo log`在事务提交以后就可以删除了。
      - `update undo log`
        - `update`或`delete`语句产生的`undo log`。因为修改或者删除的是表中拥有的数据，这个数据可能正在被其他事务使用，所以我们要将修改之前的值记录下来，不能直接删除。`undo log`会放入一个链表，等待`purge线程`的最后删除。
        - 第一次修改：![img](https://javaguide.cn/assets/c52ff79f-10e6-46cb-b5d4-3c9cbcc1934a-UG37aFoQ.png)
        - 第二次修改：![img](https://javaguide.cn/assets/6a276e7a-b0da-4c7b-bdf7-c0c7b7b3b31c-J-draIaP.png)


### 可见化算法

- 首先看数据的`DB_TRX_ID`和`m_up_limit_id`比较，如果小于这个值，那么可见。
- 如果大于，看看是不是大过了`m_low_limit_id`，如果大过了，那么不可见。
- 如果没有大过，且`m_ids`为空，说明创建快照的时候没有活跃事务，也说明这个数据是创建快照前修改的，可见。
- 但是如果有活跃事务，那我们要检查一下这个`DB_TRX_ID`在不在活跃事务当中，如果在的话，说明数据被这个事务修改过，有两个可能：
  - 创建快照之前就被修改了，但是还没有提交。
  - 创建快照之后修改了。
  - 这两种情况都说明数据不可见。
- 如果找不到对应的活跃事务`id`的话，说明这个数据早就被改过了，而且已经正常提交了，那么说明数据可见。
- 所有数据不可见的判断之后，都会使用`DB_ROLL_PTR`指针去找到对应的`undo log`获取历史版本，也就是快照记录。拿到这个快照记录以后重新执行一下可见化算法。直到满足快照版本。

### RC和RR隔离级别下的MVCC差异

- RC为读已提交，这种级别下我们知道是可以读到别的事物已经提交的数据，那就说明每次执行`select`查询之前都会生成一个`Read View`，这样子才能做到可以读取到已提交的数据。
  - 具体来说，就是我生成新的`Read View`，那么就会有新的活跃事物列表，此时，这个列表中肯定没有刚刚已经提交完的事务（因为已经提交了），所以在可见化算法的时候，就会在`m_ids`找不到对应的事务ID，那么这个记录也就可见了。
  - 或者也有可能，第一个事务开启以后，第二个新事务过来修改数据，同样，此时第一个事务读取第二个事务已经提交的数据时，会发现新的`m_low_limit_id`大于`DB_TRX_ID`，所以可以正常读。
- RR隔离级别的话是可重复读，也就是别的事务就算提交了，我读取同一个数据还是同一个快照，只要我只生成一个`Read View`即可，生成一个以后，别的事物提交，要不就是大于`m_low_limit_id`，要不然就是在`m_ids`里面，两种情况数据都是不可见的，所以 就会使用同一个快照版本。

## SQL语句的执行过程

### 基本架构

- MySql的基本架构为:
  - **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。
  - **查询缓存：** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
  - **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
  - **优化器：** 按照 MySQL 认为最优的方案去执行。
  - **执行器：** 执行语句，然后从存储引擎返回数据
- 主要分为两个模块
  - Server层：MySql带的，里面有一个通用日志模块`bin log`
  - 存储引擎：多种存储引擎实现，`InnoDB`中的日志`redo log`

### 各个层级

- 连接器：
  - 负责用户登录数据库的身份认证以及权限。这个权限在登录以后就一直使用直到连接断开。所以连接断开前，就算管理员修改了权限，用户也不会受到影响
- 查询缓存
  - SQL语句作为KEY，结果集作为Value
  - 执行前也会判断用户权限
  - MySql 8.0后删除了这个模块，因为如果更新一个数据的时候，会将整个表的缓存清空
- 分析器
  - 会分析SQL语句干嘛，分为两步
    - 词法分析：提取关键字，什么查询，什么表，什么字段，什么条件
    - 语法分析：看看语法对不对
- 优化器：
  - MySQL会选取一个最优的方案进行执行（虽然有时候并不是最优的）
- 执行器：
  - MySQL准备执行，也会先看看用户有没有权限。有的话就去调用引擎的接口，返回接口的执行结果

### 语句分析

- 查询语句：

  - ```sql
    select * from tb_student  A where A.age='18' and A.name=' 张三 ';
    ```

  - 先看看有没有权限

  - 提取出关键元素，`select`,`tb_student`,`age`,`name`

  - 优化，比如这个可以先查`age`，也可以先查`name`

  - 执行！！

- 更新语句：

  - ```sql
    update tb_student A set A.age='19' where A.name=' 张三 ';
    ```

  - 这里就会提到两个日志了`bin log`, `redo log`

  - 更新以后，会将更新结果记录`redo log`之中，也会将数据保存到内存中，上面提到的`Buffer Pool`, `redo log`此时为`prepare`状态

  - 然后会通知执行器记录`bin log`，然后再将`redo log`修改为`commit`

  - 更新完成

- 两阶段提交原理上面提过了，主要是为了防止`bin log`与`redo log`之间的数据不统一。‘


## 自增主键一定连续？

### 自增主键保存在哪里？

- 我们表结构实际上存储在一个`.frm`文件中，但是对于`InnoDB`来说自增主键一开始存储在内存中，并没有到文件中，所以在我们添加一个数据以后立马重启`MySQL`，会发现AUTO_INCREMENT进行了回退，但是8.0版本之后，AUTO_INCREMENT记录在了`redo log`	中，就不会出现这个情况了。

### 自增值不连续

#### 自增值不连续1

- 如果我们插入的自增值列设为0或者null，那么就会根据AUTO_INCREMENT当前的值进行赋值，但是如果我们设置了，那么如果设置的值比当前自增值大，就要将当前自增值改为新的自增值
- 但是这个修改不是直接修改到大于1即可，而是从`auto_increment_offset`开始，以`auto_increment_increment`为步长累加上去，所以可能出现不连续的情况

#### 自增值不连续2

- 如果重复插入一个数据，这个数据的唯一列值相同，那么AUTO_INCREMENT也会增加，虽然数据没有真正的插入，但是AUTO_INCREMENT实际上已经增加了。
- 因为得先通过AUTO_INCREMENT给我们的列赋值，然后再去查看有没有插入相同的唯一数据。

#### 自增值不连续3

- 事务回滚后，自增值不会跟着回滚
- 比如此时自增值为1，然后插入一条数据，自增值变为2，然后开启事务，插入一条数据，但是回滚，那么自增值变为3了。
- 假设事务回滚，自增值也回滚的话，就会造成两个事务插入数据时有可能会出现ID重复的错误
- 为了防止这个错误，就得使用其他手段来检查表中是不是有相同ID，比如直接判断有没有ID，比如上锁
- 这两种都存在性能问题，所以还不如直接设置为不回滚，这样每个事务申请到的ID肯定都是不重复的

#### 自增值不连续4

- 批量插入数据
  - 在我们使用普通的`insert`语句时，因为是知道有几个数据插入的，所以直接申请对应的自增值数目即可
  - 但是批量插入数据时，MySQL并不知道有多少个数据即将插入，一个个申请太慢了，所以会使用2次方的形式来申请
    - 第一次申请，分配1个
    - 第二次申请，分配2个
    - 第三次申请，分配4个
    - 。。。
  - 所以，比如我们批量插入五条数据
    - 第一次，分配1个
    - 第二次，分配2个
    - 第三次，分配4个
    - 一共分配了7个
  - 所以此时AUTO_INCREMENT的值为8，而不是6.

# Redis

## Redis基础

### Redis为什么快

- Redis是基于内存的数据库，所以内存操作比在磁盘上操作要快很多
- Redis使用多路复用的形式，使得一个线程可以监听大量的请求
- Redis底层的数据结构实现，性能很高

### Redis线程模型

#### Redis单线程模型

- 使用Reactor实现多路复用，一个线程就可以监听大量请求，和Netty的实现差不多。
- **Redis的单线程指的是 接收客户端请求 -> 解析请求 -> 进行数据读写操作等 -> 发送数据给客户端 这个过程是单线程的（主线程）完成**
- **Redis程序并不是单线程的**，Redis启动的时候会启动后台线程（BIO）：
  - **Redis在2.6版本**：会启动2个后台线程，分别处理关闭文件、AOF刷盘两个任务
  - **Redis在4.0版本之后**：新增一个新的后台线程，用来异步释放Redis内存，也就是`lazyfree`线程。例如执行 unlink key / flushdb async / flushall async等命令，会把这些删除操作交给后台线程来执行。好处是不会阻塞主线程的。所以，当我们要去删除一个大key时，不要使用del命令删除，del是在主线程处理的，这样会造成主线的卡断，使用unlink来异步删除大key

- 后台线程相当于一个消费者，生成者把耗时的任务丢到任务队列中，消费者（BIO）不断轮询这个队列，拿到任务就去执行相应的方法
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.jpg)
- 关闭文件、AOF刷盘、释放内存这三个操作都比较耗时，所以不希望在主线程执行，Redis为它们这些任务单独创建线程处理。它们有自己的任务队列
  - `BIO_CLOSE_FILE`:关闭任务队列。当队列有任务时，后台线程调用 `close(fd)`，将文件关闭
  - `BIO_AOF_FSYNC`：AOF刷盘任务队列。当AOF日志设置为 `everysec`，主线程会把AOF写日志操作封装成一个任务，放到队列中，由后台线程发现任务并调用 `fsync(fd)`，将AOF文件刷盘
  - `BIO_LAZY_FREE`：lazy free任务队列，当队列有任务时，后台线程会 free(obj)释放对象 / free(dict)删除数据库所有对象 / free(skiplist) 释放跳表对象

- 为什么6.0之前不使用多线程
  - 4.0之后其实增加了多线程，但是这些线程主要是针对大键值对的删除命令，使用这些命令可以异步处理。
  - Redis的性能瓶颈并不是在CPU，因为它是基于内存的，6.0之后的多线程主要是针对网络的请求。
  - 单线程更容易维护
  - 多线程会造成额外的问题，比如上下文切换，死锁问题。
- Redis6.0的多线程主要提高网络IO读写性能，执行命令依然是单线程顺序执行。而且Redis6.0的多线程默认是禁用的。

#### Redis 单线程模式是怎么样的

- Redis6.0之前的单线程模式是：
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.drawio.png)
- 蓝色的部分是一个事件循环，由主线程负责，可以发现网络I/O和命令处理都是单线程的。Redis初始化的时候，会做以下事情：
  - 首先，调用 `epoll_create()`创建一个epoll对象和调用socket()创建一个服务端socket
  - 然后，调用 `bind()`绑定端口和调用 `listen()`监听该socket
  - 然后，将调用 `epoll_ctl()`将 listen socket加入到epoll，同时注册 连接事件 处理函数
- 以上其实就是建立了一个服务端监听socket开始监听请求，利用多路复用
- 然后，主线程就进入到一个 **事件循环函数**：
  - 首先，调用 **处理发送队列函数**，看发送队列中是否有任务，如果有任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮发不完，就注册一个写事件，等待epoll_wait 发现可写以后再处理
  - 接着调用 epoll_wait 函数等待事件到来
    - 如果是 **连接事件**，则会调用 **连接事件处理函数**，该函数会调用`accpet`获取已连接的socket，接着调用`epoll_ctl`将已连接的socket加入到`epoll`，最后注册 读事件 处理函数
    - 如果是 **读事件**，则会调用 **读事件处理函数**，该函数会调用 read获取客户端发送的数据，然后解析命令，处理命令，将客户端对象添加到发送队列（**这里主要是依靠处理发送队列函数来进行发送数据**），最后将执行结果写到发送缓冲区等待发送
    - 如果是 **写事件**，则会调用 **写事件处理函数**，该函数会通过 write函数将客户端发送缓冲区里的数据发送出去，如果这一轮数据没有发送完，就继续注册写事件处理函数，等待 `epoll_wait`发现可写后再处理。

#### 为什么Redis是单线程还那么快

- 主要有以下原因：
  - Redis大部分操作都是在 **内存中完成的**，而且底层采用了高效的数据结构，因此Redis瓶颈可能是机器的内存或者网络带宽，而并非CPU，既然CPU不是瓶颈，自然采用单线程的模式
  - Redis采用单线程模型可以避免 **多线程之间的进程**，省去了多线程带来的上下文切换消耗，并且也不会出现死锁的问题
  - Redis采用了 **I/O多路复用机制**处理大量客户端请求。

#### 为啥Redis6.0之前使用单线程

- 首先和上面一样，**CPU并不是制约Redis性能表现的瓶颈所在**，更多情况下是内存大小和网络I/O的限制
- 使用单线程的可维护性高，使用多线程会带来并发读写等一系列问题，**增加了系统复杂度、同时会有线程切换消耗，甚至是死锁的产生**

#### 那为啥Redis6.0引入了多线程

- **Redis6.0版本后引入多线程主要是处理网络请求，因为网络硬件的性能提升，Redis的性能瓶颈会出现在网络I/O处理上**

- 为了提高网络I/O的并行度，Redis6.0对于网络I/O采用多线程来处理。**但是对于命令的执行，Redis仍然采用单线程的模式来处理**

- Redis6.0版本支持的I/O多线程特性，默认情况下I/O多线程只针对发送响应数据（write client socket），并不会使用多线程的方式来处理读请求（read client socket）。想要开启多线程处理客户端读请求，需要把Redis.conf 配置文件的 io-threads-do-reads设置为yes

- 同时，Redis.conf配置文件提供了IO多线程个数的配置项

  - ```
    io-threads 4
    ```

- 关于线程数，官方建议如果CPU是4核，使用2到3个线程，如果8核CPU，则使用6个线程数

- 所以，在Redis6.0之后，Redis在启动的时候，默认会创建6个线程（不包括主线程）

  - Redis-server：Redis主线程
  - bio_close_file, bio_aof_fsync, bio_lazy_free：三个后台线程，分别处理 关闭文件、aof刷盘 与 释放内存
  - io_thd_1、io_thd_2、io_thd_3：三个I/O线程，io-threads默认是4，所以会启动3个I/O多线程，分担Redis的I/O压力

### Redis集群（高可用）

#### Redis如何实现服务高可用

- 要设计一个高可用的Redis服务，要从Redis的多服务节点来考虑，比如Redis的主从复制、哨兵模式、切片集群

##### 主从复制

- 主从复制是Redis高可用服务的最基础的保证，实现方案就是将从前的一台Redis服务器，同步数据到多台从Redis服务器上，即一主多从的模式，且主从服务器采用的是 读写分离 的方式
- 主服务器可以进行读写操作，当发生写操作时将写操作同步给从服务器，而从服务器一般是只读，并接收主服务器同步过来的写操作，然后执行这条命令
- ![img](https://cdn.xiaolincoding.com//mysql/other/2b7231b6aabb9a9a2e2390ab3a280b2d.png)
- 也就是说，所有的数据修改都只在主服务器上进行，然后将最新的数据同步给从服务器，这样就可以使得主从的数据一致
- 主从服务器之间的命令复制是 **异步执行的**
- 具体来说，在主从服务器命令传播阶段，主服务器接收到新的写命令后，会发送给从服务器。但是主服务器不会等到从服务器实际执行完成再把结果返回给客户端，而是主服务器自己在本地执行完后，就向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器的数据就不一致了
- 所以没有办法实现强一致性，数据不一致是不可避免地

###### 第一次同步

多台服务器要通过什么方式确定谁是主谁是从呢？

可以使用 `replicaof`（Redis5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系

比如现在有A服务器和B服务器，在服务器B上执行

- ```shell
  #服务器B执行这条命令
  replicaof <服务器A的IP地址> <服务器A的Redis端口号>
  ```

接着服务器B就会变成服务器A的从服务器，然后进行与主服务器的第一次同步

主从服务器的第一次同步有三个阶段

- 第一阶段：建立连接、协商同步
- 第二阶段：主服务器同步数据给从服务器
- 第三阶段：主服务器发送新写操作命令给从服务器

![图片](https://cdn.xiaolincoding.com//mysql/other/ea4f7e86baf2435af3999e5cd38b6a26.png)

第一阶段：建立连接、协商同步

- 执行了 `replicaof`之后，从服务器就会给主服务器发送 `psync`命令，表示要进行数据同步
- `psync`有两个参数，分别是 **主服务器的runID**和 **复制进度 offset**
  - runID：每个Redis服务器启动的时候会自动产生一个随机的ID来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的runID，所以设置为 "?"
  - offset：表示复制的进度，一开始同步设置为 -1
- 当主服务器收到 `psync`命令后，会用 `FULLRESYNC`作为响应命令返回对方
- 这个命令会带上两个参数：主服务器的runID和主服务器目前的复制进度offset。从服务器收到响应后，会记录这两个值
- FULLRESYNC响应命令的意图是采用 **全量复制**的方式，也就是主服务器会把数据全部同步给从服务器
- 所以，第一阶段的工作是为了全量复制做准备

第二阶段：主服务同步数据给从服务器

- 接着，主服务器会执行 bgsave命令来生成RDB文件，把这个文件发送给从服务器
- 从服务器收到RDB文件后，会首先清空当前的数据，然后载入RDB文件
- 但是，因为 bgsave命令是一个异步生成RDB的命令，如果这个期间里有新的写操作过来之后，那并没有记录到刚刚的RDB文件，这是主从服务器间的数据就不一致了
- 那么为了保证主从服务器的数据一致性，**主服务器在其中三个时间间隙中如果收到写操作，会写入到replication buffer缓冲区中**
  - 主服务器生成RDB文件期间
  - 主服务器发送RDB文件给从服务器期间
  - 从服务器加载RDB文件期间

第三阶段：主服务器发送新写操作命令给从服务器

- 在主服务器生成的RDB文件发送完，从服务器收到RDB文件后，会丢弃所有旧数据，然后将RDB数据载入内存。完成RDB载入后，会回复一个确认消息给主服务器
- 接着，主服务器将 `replication buffer`缓冲区记录的写操作命令发送给从服务器，从服务器执行来自主服务器 `replication buffer`缓冲区里的命令，这样子就主从数据一致了

###### 命令传播

主从服务器完成第一次同步后，双方之间会维护一个TCP连接

后续主服务器可以通过这个连接继续将写操作命令同步到从服务器上，然后从服务器直接执行即可。

这个连接是长连接，避免了频繁TCP连接和断开带来的性能消耗

这个过程也称为 **基于长连接的命令传播**，通过这种方式来保证第一次同步之后主从数据一致

###### 分摊主服务器的压力

前面的分析可以看到，主从的第一次同步需要主服务器使用 bgsave 来创建RDB文件，然后通过网络传输，这两个操作都比较耗时

- 由于是通过`bgsave`命令来生成RDB文件，如果内存数据特别大， 那么fork()函数因为会去复制页表，是会阻塞主线程的，从而Redis可能无法响应正常请求
- 传输RDB文件会占用主服务器的网络带宽，对主服务器响应命令请求产生影响

如果我们的从服务器有很多个，难道都由主服务器一个个去生成RDB文件来完成主从同步吗？

其实并不是，Redis中的从服务器可以用自己的从服务器，那这个从服务器不仅可以接收主服务器的同步数据，自己也可以当成主服务器的形式去将数据同步给从服务器

![图片](https://cdn.xiaolincoding.com//mysql/other/4d850bfe8d712d3d67ff13e59b919452.png)

通过这种方式，**主服务生成的RDB和传输RDB的压力就可以分摊到这些充当经理角色的从服务器**

命令的话其实很简单，和我们选主服务器的命令是一样的

```
replicaof <目标服务器IP> 6379
```

如果目标服务器也是一个 从服务器，那么该目标服务器就会称为经理的角色，不但可以接收主服务器同步的数据，也可以把数据同步到自己旗下的从服务器，分摊主服务器的压力

###### 增量复制

主从服务器第一次同步之后，就会基于TCP长连接进行命令传播

但是，如果网络断开了怎么办？那命令就没办法传播到从节点了，客户端就有可能从 从服务器读到旧数据

那网络恢复了，又怎么继续去保持主从一致性呢？

在Redis2.8 之前，如果主从服务器在命令同步时出现了网络断开又恢复的情况，从服务器就会和主服务器进行一次全量复制，显然开销太大

Redis2.8之后，网路断开又恢复的情况，主从服务器会使用 **增量复制**的方式继续同步，只会把网络断开期间主服务器接收到的写操作命令同步给从服务器

![图片](https://cdn.xiaolincoding.com//mysql/other/e081b470870daeb763062bb873a4477e.png)

主要三个步骤

- 从服务器从网络恢复以后，会发送 `psync`命令给主服务，此时 `psync`中的offset参数不是-1
- 主服务器收到该命令后，会使用CONTINUE响应命令告诉从服务器，接下来将采用增量复制的方式同步数据
- 然后主服务器将主从服务器断开期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令

那就要考虑一个点，**主服务怎么知道要将哪些增量数据发送给从服务器呢**

有两个东西去解决：

- `repl_backlog_buffer`: 这是一个 **环形** 缓冲区，用于主从服务器断连之后，从中找到差异的数据
- `replication offset`：标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 `master_repl_offset`来记录自己 **写** 到的位置，从服务器使用 `slave_repl_offset` 来记录自己的 **读** 的位置。

那repl_backlog_buffer缓冲区什么时候写入呢？

在主服务器进行命令传播时，不仅会将写的命令发送给从服务器，还会将命令写入到 `repl_backlog_buffer`中，因此，这个缓冲区包含了最近传播的写命令

网络断开重连后，从服务器通过 `psync`命令将自己的复制偏移量 `slave_repl_offset`发送给主服务器，主服务器根据自己的 `master_repl_offset`和 `slave_repl_offset`之间的差距，然后决定服务器执行哪种同步操作

- 如果判断出从服务器要读取的数据还在 `repl_backlog_buffer`中，那么主服务器采用 **增量同步的方式**
- 如果判断出从服务器要读取的数据已经不在 `repl_backlog_buffer`了，那么就要采用 **全量同步的方式**

当主服务器在 `repl_backlog_buffer`中找到了主从服务器的增量数据以后，就会将增量数据写入到 replication buffer中

![图片](https://cdn.xiaolincoding.com//mysql/other/2db4831516b9a8b79f833cf0593c1f12.png)

`repl_backlog_buffer`缓冲区默认大小是 1MB，并且由于它是一个环形缓冲区，当数据写满缓冲区后，就会去覆盖之前的数据。因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。

那么网络恢复时，如果从服务器想读取的数据被覆盖了，主服务器就会采用全量复制，这个方式比增量同步的性能损耗要大很多

**为了避免在网络恢复时，主服务器频繁采用全量同步，那么我们要调整一下 repl_backlog_buffer的缓冲区大小，尽可能大一些**，减少出现从服务器想要读取的数据被覆盖的概率。

那具体怎么计算出这个大小呢？

![图片](https://cdn.xiaolincoding.com//mysql/other/5e9e65a4a59b3688fa37cadbd87bb5ac.png)

- second：为从服务器断线后重新连接上主服务器所需的平均时间（秒为单位）
- write_size_per_second：主服务器平均每秒产生的写命令数据量大小

如果主服务器每秒产生1MB的写命令，而从服务器断开后需要5秒才能重连，那么 `repl_backlog_buffer`大小就不能低于5MB，否则新写的命令就会覆盖旧数据了

###### 怎么判断Redis某个节点是否正常工作？

通过互相的心跳检测，如果有一半以上的节点去ping一个节点的时候没有pong回应，那么集群就会认为这个节点挂掉了，断开这个节点的连接

Redis主从节点的心跳间隔发送是不一样的，而且作用也有区别：

- Redis主节点默认10s对从节点发送ping命令，判断从节点的存活性和连接状态，可通过参数 `repl-ping-slave-period`去调整发送频率
- Redis从节点每个1s发送 `replconf ack{offset}`命令，目的是给主节点报上自己当前的复制偏移量：
  - 实时监控主从节点的网络状态
  - 上报自身偏移量，检查是否有复制数据丢失，如果从节点数据丢失，再从主节点的复制缓冲区拉取丢失的数据

###### 主从模式下，过期Key如何处理

主节点处理一个Key或者通过淘汰算法淘汰了一个Key，这个时间主节点就会去模拟一个del命令发送给从节点，从节点就可以通过执行该命令删除key

###### 主从复制中两个Buffer（Replication Buffer, repl backlog buffer）的区别

- 出现的时机不一样
  - repl backlog buffer是在增量更新阶段出现的，**一个主节点只配一个repl backlog buffer**
  - replication buffer是在全量更新和增量更新都会出现的，**主节点为每个新连接的从节点分配一个replication buffer**
- 两个Buffer都有大小限制，当缓冲区满了，会有不同的策略
  - 当 repl backlog buffer满了之后，因为是环形结构，直接 **覆盖起始位置的数据**
  - 当 replication buffer满了之后，会导致连接断开，删除缓存，从节点重新连接，**重新开始全量复制**

###### 如何应对主从数据不一致的情况

- 因为Redis的主从命令传播是异步进行的，所以没有办法保证数据强一致性，但是我们可以尽量减少这个影响
  - 首先，为了防止网络耗时过久，就要保证主从节点之间的网络良好，最好就部署在同一个机房
  - 其次，可以开发一个外部程序监控主从节点的复制进度：
    - Redis提供了一个命令 `INFO replication`，可以去查看主节点接收写命令的进度信息（master_repl_offset）和从节点的复制写命令进度信息（slave_repl_offset），所以，我们可以开发一个监控程序，使用INFO replication命令查看到主从的进度，然后用 master_repl_offset - slave_repl_offset得到主从复制进度的差值
    - 我们为这个差值设置一个阈值，如果超过这个阈值，说明主从节点的进度差距太大，数据不一致性情况比较多，可以让客户端不要再和这个从节点进行数据读取，进而减少读到不一致数据的情况。这个阈值还得调大一点，以免所有从节点都不能连接了

##### Redis哨兵机制

###### 为什么要有哨兵机制

我们原来的主从模型中，主节点负责写操作和读操作，然后将写操作同步到各个从节点，那假设主节点此时挂了，那么就没有主节点来服务客户端的写操作，也无法将数据与从节点进行同步

如果要恢复服务，以前的做法就只能进行人工干预，选一个从节点切换为主节点，然后让其他节点指向新的主节点，还得通知上游的客户端现在换主节点了，让他们去更新为 新主节点的ip地址

不过这样子也太麻烦了，所以在Redis2.8之后提供了 **哨兵机制**，实现了主从节点的故障转移，它会去检测主节点是否存活，如果挂了，就会去选举一个从节点切换为主节点，并且将新主节点的相关信息通知到各个从节点和客户端

###### 哨兵机制如何去工作的

既然它可以去检测主节点，那它必然是一个独立于主从节点的一个进程，所以它其实是运行在一个特殊模式下的Redis进程，也是一个节点，它相当于是一个 观察者节点，观察的对象就是主节点

哨兵主要负责三件事情：**监控、选主、通知**

###### 如何判断主节点真的故障了？

哨兵会去每隔1秒给所有主从节点发送PING命令，当主从节点收到PING命令后，会发送响应命令给哨兵，这样就可以判断是否在正常运行

如果主节点或者从节点在规定时间内没有响应哨兵的PING命令，哨兵就会把他们标记为 **主观下线**，这个 规定的时间 可以在配置项 `down-after-milliseconds`参数去设定，单位是毫秒

那什么是 **客观下线**？客观下线只在主节点有

之所以分了两个状态出来，是因为主节点可能没有故障，只是因为主节点的系统压力大，或网络拥塞，导致没有在规定时间内返回PING命令

为了减少这个误判的情况，哨兵在部署的时候不会只部署一个节点，而是使用多个节点部署成 **哨兵集群（最少需要三台机器），通过多个哨兵节点一起来判断，就可以避免单个哨兵因为自身网络状态不好而导致的误判**。

具体怎么判定主节点为 客观下线呢？

当一个哨兵判断主节点为 主观下线，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络情况，做出赞成投票或拒绝投票的响应

当赞同票达到哨兵配置文件中的 `quorum`配置项设定的值后，主节点就会标记为 客观下线

比如现在有三个哨兵，quorum配置为2，那么当两个哨兵标记主节点为主观下线以后，就可以标记主节点是客观下线了

- 一般设置 quorum的值为哨兵个数的 1/2 + 1，也就是比一半多1票

判断完主节点客观下线以后，就要从多个从节点中选举一个出来做主节点

###### 由哪个哨兵进行主从故障转移

上面判断完主节点已经是客观下线，那选哪一个哨兵对节点进行主从故障转移呢？这里就得从哨兵集群选举一个Leader出来

首先，选举Leader那必然会有候选者，哪个哨兵判断主节点是主观下线的，那那个哨兵就是一个候选者

还是上面的例子，现在哨兵B先判断主节点是主观下线，会去发送 is-master-down-by-addr命令，其他哨兵就会根据自己和主节点的网络情况进行投票

![img](https://cdn.xiaolincoding.com//picgo/d0bed80d28a543fd8dcd299d4b06cf04.png)

当B收到赞成票达到配置文件中的 quorum，就会将主节点标记为客观下线，此时B就是一个Leader候选者

成为候选者后，就会去给其他哨兵发送命令。表示希望成为Leader来进行主从切换，让其他哨兵给它投票

每个哨兵只有一次投票机会，投完就不能参与了，可以投给自己或其他人，不过只有候选者可以投给自己

投票过程中，任何一个候选者要满足两个条件

- 拿到半数以上的赞成票
- 拿到的票数还得大于等于 quorum的值

在上面这情况，quorum设置为2，那么任何一个想成为Leader的哨兵只要拿到2票，就可以选举成功。如果没有满足条件，则重新进行选举

假设此时，两个哨兵同时发现主节点客观下线，它们俩都是候选者，那如何去选Leader呢？

剩余的投票者会先收到某个候选者的投票请求，那么就会把票投给它，剩余那个候选者的请求到达时，因为已经没有票数了，所以最终会给第一个投票请求的候选者成为Leader

哨兵的数量最好设置为奇数，且quorum设置为 1/2 * 数量 + 1

###### 主从故障转移的过程

选举出哨兵Leader以后，就可以进行主从故障转移了

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB.png)

故障转移主要包含四个步骤

- 在已下线主节点（旧主节点）属下的所有 从节点 里面，挑选一个从节点，将其转换为主节点
- 让旧主节点下的所有 从节点 修改复制目标，修改为复制 新主节点
- 让新主节点的IP地址和信息，通过 发布者/订阅者机制 通知给客户端
- 继续监视旧主节点，当它恢复上线的时候，把它设置为新主节点的从节点

那我们逐步分析

第一步：选出新主节点

- 故障转移第一步肯定是挑选出一个新的主节点，我们从 从节点挑选出一个状态良好、数据完成的，然后向这个 从节点 发送 SLAVEOF no one （`SLAVEOF <ip><port>`命令在Redis5.0之前就是选择主节点的命令，5.0后说 `REPLICAOF <ip><port>`）命令，将这个 从节点 转换为 主节点
- 如何去挑选呢？最简单就是随机去挑，那如果挑到一个网络状态不好的不就可能又要做主从故障迁移了吗
- 所以，我们首先得把网络状态不好的从节点给他过滤掉。把已经下线的从节点过滤掉，然后把以往网络连接状态不好的从节点也过滤掉
- 怎么去判断从节点之前网络连接好不好呢
  - Redis有一个叫 `down-after-milliseconds * 10`的配置项，其 `down-after-milliseconds`是主从节点断连的最大连接超时时间。如果在 `donw-after-milliseconds`毫秒内，主从节点都没有通过网络联系上，那么就认为主从节点断连了，如果这种断连的次数发生了超过10次（或者说总断连时间超过了 down-after-milliseconds * 10 毫秒数），就认为这个节点的网络状态不好，不适合作为新的主节点
- 这样子，就可以去过滤网络状态不好的从节点，接下来还要对所有从节点进行三轮考察：**优先级**、**复制进度**、**ID号**。在每一级考察的时候，哪个从节点优先胜出，就成为新的主节点
  - **优先级考察**：根据从节点的优先级进行排序，优先级越高排名越靠前
    - Redis有个叫 `slave-priority`配置项，可以给从节点设置优先级
    - 每个从节点的服务器配置不一定相同，可以根据服务器性能去设置从节点的优先级
    - 比如 A从节点的物理内存是所有从节点中最大的，那么可以设置 A从节点 的优先级为最高，当哨兵第一轮考察的时候，优先级最高的 A从节点就会胜出，成为新的主节点
  - **复制进度考察**：如果优先级相同，则查看复制的下标，哪个从 主节点 接收的复制数据越多，哪个越靠前
    - 那如果第一轮考察相同，就会来到第二轮考察，去比较两个从节点哪个复制进度最多
    - 主要是看我们前面提过的 `repl_backlog_buffer`中，主节点的 `master_repl_offset`和从节点的 `slave_repl_offset`，哪个从节点的offset最接近主节点，它就为新的主节点
  - **ID号**：如果优先级和下标都相同，那就选择 从节点ID较小的那个
    - 最后，如果复制进度也一样，那么就查看节点之间的ID号，ID号小的从节点胜出
    - 每个Redis实例都有一个ID号

选出新主节点以后，哨兵Leader会向被选中的节点发送 `SLAVEOF no one`命令，让这个从节点解除从节点的身份，变为新主节点

发送完 `SLAVEOF no one`命令之后，哨兵leader会以每秒一次的频率去向被升级的从节点发送 `INFO`命令（没进行故障转移前， `INFO`命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级的角色信息从原来的slave变为master时，哨兵Leader就知道选中的从节点已经顺利升级为主节点了

第二步：将从节点指向新主节点

- 当新主节点出现之后，哨兵leader下一步要做的就是，让已下线主节点旗下的所有 从节点 指向 新主节点，这一动作可以通过向 从节点 发送 `SLAVEOF`命令实现
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E4%BB%8E%E8%8A%82%E7%82%B9%E6%8C%87%E5%90%91%E6%96%B0%E4%B8%BB%E8%8A%82%E7%82%B9.png)
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BD%AC%E6%8D%A2%E6%88%90%E5%8A%9F.png)

第三步：通知客户的主节点已更换

- 前面的一系列操作已经完成了选主，将从晋升为主，将其余从修改主为新主，那么新主的信息怎么通知给客户端呢？
- 这里通过 **Redis的发布者/订阅者机制来实现**。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息
- 哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的关键事件
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E5%93%A8%E5%85%B5%E9%A2%91%E9%81%93.webp)
- 客户端和哨兵建立连接之后，客户端会去订阅哨兵提供的频道，**主从切换完成以后，哨兵就会向 `+switch-master`频道发布新主节点的IP地址和端口的信息，这个时候客户端就可以收到这个信息，然后用这里面新主节点的IP地址和端口进行通信了**
- 通过发布者/订阅者机制，客户端可以监控到主从节点切换过程中的各个重要事件，那客户端就可以了解主从切换到哪一步了

第四步：将旧主节点变为从节点

- 最后要做的就是，当旧主节点重新上线以后，哨兵集群会向他发送 `SLAVEOF`命令，设置它变为新主节点的从节点，所以旧主节点断开的时候哨兵还是要对他进行监控。

###### 哨兵集群如何组成的

刚刚提到了Redis的发布者/订阅者机制，那就要提一下哨兵集群的组成方式，因为它也用了这个机制

配置哨兵的信息，只有很少的一些参数：主节点名称，主节点的IP和端口，以及quorum值

```sh
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

不需要填写其他哨兵节点的信息，那它们怎么感知到对方呢？其实就是通过 **Redis的发布者/订阅者模型来互相发现的**

在主从集群中，主节点上有一个 `_sentinel_:hello`频道，不同哨兵就是通过它实现互相发现，互相通信的

![img](https://cdn.xiaolincoding.com//picgo/a6286053c6884cf58bf397d01674fe80.png)

如上图，哨兵A把自己的IP地址和端口信息发布到 `_sentinel_:hello`频道上，哨兵B和C订阅了该频道。那么此时，哨兵B和C就可以从这个频道上直接获取哨兵A的IP地址和端口号。然后哨兵B、C可以和哨兵A建立网络连接了

那同样的方式，哨兵B也可以与C建立连接，至此，哨兵集群就形成了

我们前面提到了，哨兵还得去监控从节点，那怎么拿到从节点的信息呢？

主节点是知道所有从节点的信息的，所以哨兵每10秒一次的频率向主节点发送INFO命令，来获取所有从节点的信息，获取到以后，就可以和从节点进行一一连接建立了。每个哨兵都是如此与从节点建立连接的

##### 切片集群模式

当Redis缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis切片集群（Redis Cluster）**，它将数据分布到不同的服务器上，以此来降低系统对单主节点的以来，从而提供Redis的读写性能

Redis Cluster方案采用哈希槽（Hash Slot），处理数据和节点之间的映射关系。在Redis Cluster方案中，**一个切片集群共有16384个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的key，映射到一个哈希槽中，具体分为两大步：

- 根据键值对的Key，按照CRC16算法，计算一个16bit的值
- 再用16bit值对16384取模，得到 0 - 16383范围内的模数，每个模数代表一个相应编号的哈希槽

那如何将哈希槽映射到具体的Redis节点呢？也有两种方案

- **平均分配**：在使用cluster create命令创建Redis集群时，Redis会自动把所有哈希槽平均分配到集群节点，比如集群中有9个节点，那么每个节点上槽个数为 16384/9个
- **手动分配**：可以使用 `cluster meet`命令手动建立节点间的连接，组成集群，再使用 cluster addslots命令，指定每个节点上的哈希槽个数

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/redis%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%E6%98%A0%E5%B0%84%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB.jpg)

需要注意的是，使用手动分配哈希槽时，要把16384个槽都分完，否则Redis集群无法正常工作

#### 集群脑裂导致数据丢失

##### 什么是脑裂？

脑裂的现象产生就好比人有两个大脑了，由哪个大脑控制呢？

Redis的脑裂就是出现了多个主节点的情况，这是因为当网络波动的时候，主节点与其他从节点都失联了，但是主节点其实没有挂机，和客户端还是正常连接的，客户端照常向主节点写数据，此时这些数据保存在缓冲区，无法同步给从节点

此时，哨兵也发现主节点失联了，它也认为主节点挂了，所以去选举一个新的主节点，此时集群中就出现了两个主节点（**脑裂产生**）

然后网络现在好了，因为哨兵选举出了一个新主节点，所以旧主节点降级为从节点A，然后从节点A会去向新主节点进行数据同步，**因为第一次同步是全量同步的方式，所以从节点A会去清除本地数据，然后同步，那么之前客户端写入的数据就会丢失了，也就是集群产生脑裂导致了数据丢失**

一句话就是：由于脑裂问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生了两个主服务。等网络恢复，旧主节点将为从节点，再与新主节点进行同步复制的时候，会全量同步，清空本地缓冲区，导致先前客户端写入的数据丢失

##### 如何避免脑裂导致数据丢失

可以设置一个阈值，当主节点发现从节点下线或者通信超时的总数量小于一个阈值时，那么禁止主节点进行写操作，直接返回错误给客户端

在Redis的配置文件中有两个参数可以设置：

- `min-slaves-to-write x`：主节点必须要有至少x个从节点连接，如果小于这个数，主节点就会禁止写数据
- `min-slaves-max-lag x`：主从数据复制和同步的延迟不能超过x秒，如果超过了，主节点禁止写数据

可以把这两个配置项搭配来使用，比如分别设置一个阈值，N和T。翻译过来就是，主节点连接的从节点至少要有N个，和主节点进行数据复制的ACK消息延迟不能超过T秒，否则主节点就不再接收客户端的写请求

假设原主节点现在假故障，它无法和其他从节点进行同步，所以也就无法进行ACK确认，这样子N和T都无法满足，也就不会去接收客户端的写请求

后续恢复以后，新主库负责写的操作，而旧主库因为没有接收客户端请求，也就不会有新数据丢失

### Redis的内存管理

#### Redis的过期时间

- 内存是有限的，我们的数据不能一直保存在内存中，所以要给数据设置过期时间

- Redis使用`expire`给key设置过期时间，字符串类型的话还可以使用`setex`

  - ```sh
    127.0.0.1:6379> expire key 60 # 数据在 60s 后过期
    (integer) 1
    127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
    OK
    127.0.0.1:6379> ttl key # 查看数据还有多久过期
    (integer) 56
    
    ```

- 处理缓解内存的消耗，设置过期时间也可以用于业务上的处理，比如验证码1min有效，Token一天有效

#### Redis如何判断数据是否过期

- 使用一个叫做过期字典的东西，这个保存着数据过期的时间。过期字典的Key指向Redis 的Key，Value是long long类型的整数，毫秒精确度。
  - ![redis过期字典](https://oss.javaguide.cn/github/javaguide/database/redis/redis-expired-dictionary.png)
  - 这里expires就是过期字典
- 那有什么策略删除这些过期的键呢？
  - 惰性删除：只有取出key的时候才对数据进行过期检查。这样子CPU很友好，但是可能很多过期的Key都删除不到
  - 定期删除：定期抽出一批Key来检查一下过期时间，底层会限制删除的时长和频率，减少CPU的消耗
- Redis采用定期删除 + 惰性删除的手段

  - 如何实现惰性删除？

    - ```c
      int expireIfNeeded(redisDb *db, robj *key) {
          // 判断 key 是否过期
          if (!keyIsExpired(db,key)) return 0;
          ....
          /* 删除过期键 */
          ....
          // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除；
          return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :
                                               dbSyncDelete(db,key);
      }
      ```

      - Redis在访问或者修改Key之前都会调用 `expireIfNeeded`对其进行检查，是否key过期
        - 如果过期，则删除该key，至于选择异步删除还是同步删除，根据`lazyfree_lazy_expire`参数，然后返回null给客户端
        - 如果没有过期，不做任何处理，返回正常的键值对给客户端

  - 如何实现定期删除？

    - 定期删除是 **每个一段时间抽出一定数量的key，并删除其中的key**，这里有两个点需要关注：
    - 间隔时间多久呢？
      - Redis默认每秒进行10次过期检查数据库，这个配置可以通过Redis的配置文件 redis.conf进行配置，配置键为hz，默认值是hz 10
      - 每次检查并不是遍历过期字典中的所有key，而是抽取一定数量进行过期检查

    - 抽查的数量是多少？
      - 写死在代码中的，是20，也就是说，Redis进行每轮检查时，会随机选择20个Key判断过期时间

    - 所以定期删除的流程为：
      - 首先去过期字典中抽取20个key
      - 检查这个20个key是否过期，并且删除已过期的key
      - 如果本轮检查的已过期key的数量，超过5个（20/4），也就是 已过期key的数量 占比 随机抽取key的数量 大于25%，则重复步骤1; 如果已过期key比例小于25%，则停止继续删除过期key，等待下一轮检查

    - 可以看到定期删除是一个循环的过程，Redis为了保证不要循环过度，导致线程卡死，为此增加了定期删除循环流程的时间上限，默认不会超过25ms

- 可惜的是，这样子远远不够，所以Redis有内存淘汰机制

#### Redis的内存淘汰机制

##### 如何设置Redis最大运行内存

在配置文件 redis.conf 中，可以通过参数 `maxmemory <bytes>`来设定最大运行内存，只有在Redis的运行内存达到了我们设置的最大允许内存，才会触发内存淘汰策略。不同位数的操作系统，maxmemory的默认值是不一样的：

- 64位系统中，maxmomery默认值为0，表示没有内存大小限制，那么不管用户存放什么数据到Redis中，Redis都不会对可用内存进行检查，直到Redis实例因内存不足而崩溃也无作为。
- 32位操作系统中，maxmemory的默认是3G，因为32位的机器最大只支持4GB的内存，而系统本身需要一定的内存资源支持运行，所以32位操作系统限制最大3GB的可用内存是很合理的，这样可以避免因为内存导致Redis实例崩溃

##### Redis的内存淘汰机制有什么

- **volatile-lru（least recently used）**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最近最少使用的数据淘汰。

- **volatile-ttl**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选将要过期的数据淘汰。

- **volatile-random**：从已设置过期时间的数据集（`server.db[i].expires`）中任意选择数据淘汰。

- **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
- **allkeys-random**：从数据集（`server.db[i].dict`）中任意选择数据淘汰。
- **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！
- **4.0后新增了lfu机制**
- **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最不经常使用的数据淘汰。
- **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。

##### 如何查看 | 修改Redis的内存淘汰策略

可以使用 `config get maxmemory-policy`命令去查看

那如何修改呢？有两种方式

- 通过 `config set maxmemory-policy <策略>`命令设置，优点是立即生效，不需要重启Redis服务，缺点是重启Redis，设置会失效
- 通过修改Redis配置文件修改，设置 `maxmemory-policy <策略>`，优点是重启 Redis服务后配置不会丢失，缺点是必须重启Redis服务，配置才能生效。

##### LRU算法和LFU算法的区别

LFU内存淘汰算法是Redis4.0后新增的内存淘汰策略，为什么要新增一个算法呢？肯定是为了解决LRU算法的问题

###### 什么是LRU算法

LRU是Least Recently Used，**最近最少使用**，会淘汰最近最少使用的数据

传统的LRU算法是基于链表结构实现的，这边直接写一个

```java
class LRUCache {
    Node head;
    Node tail;
    Map<Integer, Node> cache;
    int capacity;
    int size;
    public LRUCache(int capacity) {
        this.capacity = capacity;
        head = new Node(-1, -1);
        tail = new Node(-1, -1);
        head.next = tail;
        tail.pre = head;
        cache = new HashMap<>();
    }
    
    public int get(int key) {
        Node node = cache.get(key);
        if(node != null){
            //将node移动到头部
            moveToHead(node);
            return node.value;
        }
        return -1;
    }
    
    public void put(int key, int value) {
        Node node = cache.get(key);
        if(node != null){
            node.value = value;
            moveToHead(node);
        }else{
            Node newNode = new Node(key, value);
            cache.put(key, newNode);
            addHead(newNode); //将新节点添加到头部
            size++;
            if(size > capacity){
                //如果size大于capacity，需要移除末尾节点
                Node waitToRemove = cache.get(tail.pre.key);
                cache.remove(waitToRemove.key);
                remove(waitToRemove);
            }
        }
    }

    public void remove(Node node){
        node.pre.next = node.next;
        node.next.pre = node.pre;
        node.next = null;
        node.pre = null;
    }

    public void addHead(Node node){
        node.next = head.next;
        node.pre = head;
        head.next.pre = node;
        head.next = node;
    }
    public void moveToHead(Node node){
        remove(node);
        addHead(node);
    }
}

class Node{
    Node next;
    Node pre;
    int key;
    int value;
    public Node(int key, int value){
        this.key = key;
        this.value = value;
    }
}

```

Redis并没有使用我这种传统的方式来实现LRU，因为存在一些问题：

- 需要用链表管理所有的缓存数据，会带来额外的空间消耗
- 当数据被访问时，需要把链表上的数据移动到头部，如果有大量数据被访问，会带来很多链表移动，耗时，降低Redis的缓存性能

###### Redis如何实现LRU算法呢？

Redis实现的是一种 **近似LRU算法**，目的是为了更好的节省内存，**它的实现方式是在Redis的对象结构体中添加一个额外字段，记录这个数据最后一次的访问时间**

当进行内存淘汰的时候，会采用 **随机采样的方式来淘汰数据**，随机取5个值（可配置），然后 **淘汰最久没有使用的那个**

Redis实现的LRU算法有两个优点：

- 并不需要为所有数据维护一个大链表，节省了空间占用
- 不用在每次数据访问时都移动链表项，提升了缓存性能

但LRU算法有一个问题，**无法解决缓存污染问题**，比如一次应用读取了大量的数据，而这些数据可能就只会使用一次，那么这些数据就会留存在Redis缓存中很长一段时间，污染了缓存

所以Redis4.0后使用了LFU算法来解决这个问题

###### 什么是LFU算法

LFU全称是 Least Frequently Used，**最近不常用**，LFU算法是根据数据访问次数来淘汰数据的，它的核心思想是 `如果数据过去被访问多次，那么将来被访问的频率也更高`

所以，LFU算法会去记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数

## Redis生产问题

### 缓存穿透

- 大量的key不合理，既不存在Redis中，也不存在数据库中，这样子就会放大量请求过Redis来到DB，可能会宕机
  - 举个例子：某个黑客故意制造一些非法的 key 发起大量请求，导致大量请求落到数据库，结果数据库上也没有查到对应的数据。也就是说这些请求最终都落到了数据库上，对数据库造成了巨大的压力。
- 解决方案：
  - 缓存无效key：
    - 如果数据库没有的话，将这个key直接缓存到Redis，但这个只是适合请求key变化不频繁的情况，如果频繁变化，会造成太多无效的Key在缓存中，如果非要使用，添加较短过期时间。
  - 布隆过滤器(Bloof Filter)：
    - 布隆过滤器的原理很简单，他是一个数组，这个数组的每个元素只占1bit，值只能为0或1
    - 存入数据的时候，将数据进行多个哈希函数，将多个哈希函数的结果当成下标，将布隆过滤器的对应下标改为1
    - 当第二个数据过来以后，计算各个哈希函数，如果发现所有下标都为1，表示存在，只要有一个不是1，表示不存在。
    - 不同数据哈希出来的值可能相同，所以可能会误判。但是如果布隆过滤器说没有，那就肯定是没有。
    - 使用的时候，将所有可能存在的请求值都放入布隆过滤器当中，用户请求过来的时候，先判断是否存在布隆过滤器，如果不存在，直接返回错误给客户端。

### 缓存击穿

- 热点Key突然过期了，导致大量请求直接来到数据库，宕机
  - 举个例子：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力。
- 解决方案：
  - 将热点数据设置为永不过期或者过期时间很长
  - 将热点数据提前预热，放入到缓存中，设置合理的过期时间
  - 请求数据库写数据到缓存前获取互斥锁，保证只有一个请求落到数据库
- 缓存穿透是因为缓存和数据库都没有数据
- 而缓存击穿是数据库有数据，缓存过期了，所以击穿了

### 缓存雪崩

- 缓存雪崩是由于大量缓存同一时间过期，或者失效，导致大量请求来到了数据库，宕机
  - 举个例子：数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。这就导致大量的请求直接落到数据库上，对数据库造成了巨大的压力
- 解决方案：
  - Redis服务不可用情况
    - 建立Redis集群，防止单机情况下Redis不可用
    - 限流，避免同时处理大量请求
    - 多级缓存：本地缓存 + Redis缓存组合，当Redis缓存出现问题，还可以从本地缓存中取
- 缓存击穿和缓存雪崩
  - 击穿是由于热点数据过期
  - 雪崩是由于大量缓存过期或者失效

### Cache Aside Pattern(旁路缓存模式)

- 写操作：
  - 先更新DB，然后删除Cache
- 读操作：
  - 先读取Cache，读到了直接返回
  - 如果读不到，就去DB读，然后将数据存入Cache
- 为什么要先更新DB后删除Cache
  - 如果先删除Cache，再更新DB会有一个问题，导致后续的请求拿到的都是错误的数据
  - 比如一个请求A来更新数据，他先去删除Cache，此时请求B来拿数据，拿到了DB还没修改的数据，并且放入了Cache，请求A再去修改DB，这样就导致了数据不一致的问题。
- 那先删除Cache再更新DB就一定没问题吗？
  - 也有可能有问题，但是概率很小，因为写入缓存的速度比写入数据库要快很多。
  - 比如A过来读，此时缓存没数据，它去数据库取，然后B此时修改数据库的数据了，最后A将它自己的数据放入了缓存。
  - 但是这个概率很小，因为写入缓存的速度很快，所以A大概率会在B修改完之前就把数据放入缓存了，所以B修改完之后再次删除缓存即可。
- 缺陷1：首次访问缓存中肯定没数据
  - 提前将数据放入Cache
- 缺陷2：写操作频繁的场景，Cache数据会被频繁删除
  - 如果要强数据一致，那我们可以更新的时候把Cache也更新了，但是要上锁，保障更新的原子性

### Read/Write Through Pattern（读写穿透）

- 读写穿透策略下，是将Cache作为主要的数据存储，Cache负责将数据读取和写入到DB，减轻应用程序的职责
- 写：
  - 先查Cache，如果Cache不存在则直接更新DB
  - Cache如果存在，则更新Cache，由Cache取更新DB（这里是同步更新）
- 读：
  - 先读Cache，如果Cache不存在则直接读取DB，然后将结果放入Cache
  - 如果存在，则读Cache

### 异步缓存写入

- 都是由Cache负责Cache和DB的读写
- 但是这里并不是同步修改，而是异步批量的来更新DB。我们原来提过的MySQL中InnoDB的BufferPool就是这种形式，先修改BufferPool中的内容，然后由MySQL自己去查看内存和数据库中是不是有不一致的情况，有的话再去更新

## Redis中5中基本数据类型

- | String | List                         | Hash          | Set          | Zset              |
  | :----- | :--------------------------- | :------------ | :----------- | :---------------- |
  | SDS    | LinkedList/ZipList/QuickList | Dict、ZipList | Dict、Intset | ZipList、SkipList |

- 每个命令都会跟着一个KEY，表示要操作的KEY，这个KEY可以想象成一个对象引用，通过引用拿到真正的对象，再操作。

### String

- Redis中的字符串格式是自己构建的，SDS(Simple Dynamic String)，比起C语言中的字符串，SDS获取长度的时间复杂度为O(1)。

  |              命令               |               介绍               |
  | :-----------------------------: | :------------------------------: |
  |          SET key value          |        设置指定 key 的值         |
  |         SETNX key value         | 只有在 key 不存在时设置 key 的值 |
  |             GET key             |        获取指定 key 的值         |
  | MSET key1 value1 key2 value2 …… |   设置一个或多个指定 key 的值    |
  |       MGET key1 key2 ...        |   获取一个或多个指定 key 的值    |
  |           STRLEN key            | 返回 key 所储存的字符串值的长度  |
  |            INCR key             |    将 key 中储存的数字值增一     |
  |            DECR key             |    将 key 中储存的数字值减一     |
  |           EXISTS key            |      判断指定 key 是否存在       |
  |         DEL key（通用）         |          删除指定的 key          |
  |   EXPIRE key seconds（通用）    |     给指定 key 设置过期时间      |

- 应用场景：

  - 存储常规数据
    - 缓存Session，Token，序列化的对象
    - 命令:`GET`,`SET`
  - 需要计数的场景
    - 用户单位时间的请求数目，页面的访问数
    - 命令：`SET`,`GET`,`INCR`,`DECR`
  - 分布式锁

#### 实现

- String类型的底层数据结构主要是int 和 SDS（简单动态字符串）
- SDS比原生的C字符串好在：
  - **SDS不仅可以保存文本数据，还可以保存二进制数据**。因为 `SDS`使用 `len`属性的值而不是空字符来判断字符串是否结束，并且SDS的所有API都会以处理二进制的方式处理SDS存放在 `buf[]`数组里的数据。所以SDS不光可以存储文本数据，也可以存储图片、视频、音频、压缩文件的二进制数据
  - **SDS获取字符串长度的时间复杂度为O(1)**。因为C语言的字符串并不记录自身长度，获取长度的复杂度为 O(n)，而SDS结构里用 `len`去记录了一下字符串的长度，所以复杂度为 O(1)
  - **Redis的SDS API是安全的，拼接字符串不会造成缓冲区溢出。**因为SDS在拼接字符串前会先检查SDS空间是否满足要求，如果空间不足会先去扩容
- 字符串对象的内部编码有3种：int、raw和embstr
- 如果一个字符串对象保存的是整数型，并且这个整数型可以用 `long`表示，那么字符串对象会将整数值保存在字符串对象结构里的 `ptr`属性种，并且将字符串对象的编码设置为 `int`
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/int.png)
- 如果字符串对象保存的是一个字符串，而且这个字符串长度小于32字节（redis 2.+版本），那么字符串对象会使用一个简单动态字符串（SDS）来保存这个字符串，将编码设置为 `embstr`，`embstr`编码是专门用于保存短字符串的一种优化编码方式![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/embstr.png)
- 如果字符串对象保存的是一个字符串，且长度大于32字节（redis2.+ 版本），那么字符串对象使用一个SDS来保存字符串，将编码方式设置为 `raw`![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/raw.png)
- 可以看到 `embstr`和 `raw`编码都会使用来保存 `SDS`，但是 `embstr`会通过一次内存分配函数分配一块连续的内存空间来保存 `redisObject`和 `SDS`, 而 `raw`编码会通过调用两次内存分配函数来分别分配两块空间保存 `redisObject` 和 `SDS`，这样做的好处有
  - `embstr`编码将创建字符串对象所需的内存分配次数从 `raw`编码的两次降为一次
  - 释放 `embstr`编码的字符串对象同样只需要调用一次内存释放函数
  - 因为 `embstr`编码的字符串对象所有数据都保存在一个连续的内存里面，可以更好利用CPU缓存提升性能。
- 但是，`embstr`也有缺点的：
  - 由于`embstr`和`redisObject`是连续的内存，当字符串的长度需要增加时，可能要重新分配内存，此时整个 `redisObject`和 `sds`都需要重新分配空间，所有 `embstr`编码的字符串实际上是不允许修改的，是只读的。当我们要对 `embstr`编码的字符串执行任何修改命令时（例如append），程序会将对象的编码从 `embstr`转换为 `raw`，然后再执行修改命令

### List

- Redis实现了自己的双向链表。
- 命令：

|            命令             |                    介绍                    |
| :-------------------------: | :----------------------------------------: |
| RPUSH key value1 value2 ... | 在指定列表的尾部（右边）添加一个或多个元素 |
| LPUSH key value1 value2 ... | 在指定列表的头部（左边）添加一个或多个元素 |
|    LSET key index value     | 将指定列表索引 index 位置的值设置为 value  |
|          LPOP key           |   移除并获取指定列表的第一个元素(最左边)   |
|          RPOP key           |  移除并获取指定列表的最后一个元素(最右边)  |
|          LLEN key           |              获取列表元素数量              |
|    LRANGE key start end     |     获取列表 start 和 end 之间 的元素      |

- 应用场景：
  - 信息流展示
    - 最新文章，最新动态
  - 消息队列
    - 功能简单且很多缺陷

#### 实现

- 列表的最大长度为`2^32 - 1`，支持`40亿`个元素
- 底层是由 **双向链表或者压缩列表实现**
  - 如果列表的元素个数小于 `512`个（默认值，可以由 `list-max-ziplist-entries`配置），列表每个元素的值都小于 `64`字节（默认值，可以有 `list-max-ziplist-value`配置），Redis就会使用 **压缩列表**作为List类型的底层数据结构
  - 如果列表不满足上面的条件，Redis就会使用 **双向链表**作为底层的数据结构

##### 链表

- 链表的结构和Java底层类似，包含头节点和尾节点，每个节点有两个指针，指向 `pre`和 `next`，优点的话就是获取头和尾和链表大小时间复杂度在 O(1)，插入头 尾也只需要 O(1)
- 链表的缺点：
  - 链表每个节点之间的内存是不连续的，所以没办法很好用到 **CPU缓存**。能很好利用 **CPU缓存是数组**，因为数组的内存是连续的，可以充分利用 **CPU缓存来加速访问**
  - 还有，每个链表节点，除了维护自身的数据，还要维护前序和后序的指针，**开销较大**
- 因此，Redis 3.0 的List对象在数据量较少的时候，实际上会去使用 **压缩列表**作为底层数据结构来实现，优势就是节省空间，并且是内存紧凑型的数据结构
- 但是压缩列表也有性能问题，所以Redis 3.2后续使用 `quicklist`作为底层数据结构来实现
- Redis 5.0后续使用了新的数据结构 `listpack`，沿用了列表紧凑型的内存布局，最终在最新的Redis版本，将Hash对象和Zset对象的底层数据结构之一的压缩列表，替换成了 `listpack`

##### 压缩列表

- 压缩列表最大的特点，就是是一种内存紧凑型的数据结构，占有一块连续的内存空间，不仅可以利用CPU缓存，而且会针对不同长度的数据，进行相应的编码，有效节省内存开销
- 但是缺点也有：
  - 不能存储过多的元素，否则查询效率会低
  - 新增或修改某个元素的时候，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题
- 因此，Redis对象（List对象，Hash对象，Zset对象）包含的元素较少的时候，或者元素值不大的时候，会使用压缩列表作为底层数据结构。

###### 压缩列表的结构

- ![img](https://cdn.xiaolincoding.com//mysql/other/ab0b44f557f8b5bc7acb3a53d43ebfcb.png)
  - **zlbytes**：记录整个压缩列表占用的内存字节数
  - **zltail**：记录压缩列表 尾部 节点距离起始地址多少字节，也就是列表尾部偏移量
  - **zllen**：记录压缩列表的节点数量
  - **zlend**：标记压缩列表的结束点，固定值0xFF（255 十进制）
- 在压缩列表中，如果要查找第一个元素或者最后一个元素，直接通过表头的三个字段包含的值就可以定位到了。但是查找其他的元素，就需要逐个查找，此时复杂度为O(N)，所以压缩列表不适合保存过多的元素
- 每个entry的结构为：![img](https://cdn.xiaolincoding.com//mysql/other/a3b1f6235cf0587115b21312fe60289c.png)
  - **prelen**：前一个节点的长度，目的是为了实现从后往前遍历
  - **encoding**：包含了当前节点实际数据的 类型和长度，类型主要有两种：字符串和整型
  - **data**：当前节点的实际数据，类型和长度都 `encoding` 决定。
- 当往压缩列表插入数据时，压缩列表会根据数据类型（整型还是字符串），以及数据大小，使用不同空间大小的 `prelen`和 `encoding`两个元素里保存的信息，**这种根据数据大小和类型进行不同的空间大小分配思想，就是Redis为了节省内存而采用的**
- prelen和encoding如何根据数据类型和大小进行不同的空间大小分配呢？
- 对于prelen，因为prelen属性的空间大小和前一个节点长度值相关：
  - 如果 **前一个节点大小长度小于254字节**，那么 `prelen` 属性就需要用 **1字节的空间**来保存这个长度值
  - 如果 **前一个节点的长度大于等于254字节**，那么 `prelen`属性就需要5个字节的空间来保存这个长度值
- `encoding`属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关，如：![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%E7%BC%96%E7%A0%81.png)
  - 如果 **当前节点的数据是整数**，则encoding会使用 **1字节的空间进行编码**，也就是 encoding的长度为一个字节。通过encoding确认了整数类型，就可以确认整数数据的实际大小了
  - 如果 **当前节点的数据是字符串，根据字符串的长度大小**，encoding会使用1 / 2 / 5字节的空间进行编码，encoding前两位的bit表示数据的类型，后续其他bit表示字符串数据的实际长度

###### 连锁更新

- 压缩列表除了查找复杂度较高的问题以外，还有一个问题
- **压缩列表新增或修改某个元素时，如果空间不够，压缩列表占用的空间就需要重新分配。当新添加的元素较大时，会造成后续元素的prevlen占用空间都发生变化，从而引起 连锁更新 问题，导致每个元素的空间都需要重新分配，造成访问压缩列表性能下降**
- 前面提到了prelen的分配是与前序节点的长度相关
- 假设现在压缩列表由多个连续的，长度在250 - 253之间的节点：![img](https://cdn.xiaolincoding.com//mysql/other/462c6a65531667f2bcf420953b0aded9.png)
- 因为这些节点的长度值小于254，所以prelen属性用一个字节的空间保存
- 此时，如果一个长度大于等于254的新节点加入到压缩列表头部，成为了e1的前置节点：![img](https://cdn.xiaolincoding.com//mysql/other/d1a6deff4672580609c99a5b06bf3429.png)
- 那么e1的prelen属性本身只有一个字节，无法保存这个长度，所以得对压缩列表的空间重新分配，将e1节点的prelen属性从1个字节扩展到5个字节，那么，e1此时的长度就会超过254，e2也会去扩充，多米诺牌效应就会出现：![img](https://cdn.xiaolincoding.com//mysql/other/1f0e5ae7ab749078cadda5ba0ed98eac.png)
- **这样的在特殊情况下产生的连续多次空间扩展的操作就是** **连锁更新**
- 所以，压缩列表只适用于元素数量不多的情况下，因为元素数量不多，所以连锁更新也不会太耗时

### Hash

- 和JDK1.8之前的`HashMap`类似，使用数组与链表

  |                   命令                    |                           介绍                           |
  | :---------------------------------------: | :------------------------------------------------------: |
  |           HSET key field value            |               设置指定哈希表中指定字段的值               |
  |          HSETNX key field value           |           只有指定字段不存在时设置指定字段的值           |
  | HMSET key field1 value1 field2 value2 ... | 同时将一个或多个 field-value (域-值)对设置到指定哈希表中 |
  |              HGET key field               |               获取指定哈希表中指定字段的值               |
  |        HMGET key field1 field2 ...        |         获取指定哈希表中一个或者多个指定字段的值         |
  |                HGETALL key                |               获取指定哈希表中所有的键值对               |
  |             HEXISTS key field             |            查看指定哈希表中指定的字段是否存在            |
  |        HDEL key field1 field2 ...         |                 删除一个或多个哈希表字段                 |
  |                 HLEN key                  |                获取指定哈希表中字段的数量                |
  |        HINCRBY key field increment        |  对指定哈希中的指定字段做运算操作（正数为加，负数为减）  |

- 应用场景：
  - 对于对象的存储场景
    - 用户信息，商品信息，文章信息，购物车信息
    - 相关命令：`HSET` （设置单个字段的值）、`HMSET`（设置多个字段的值）、`HGET`（获取单个字段的值）、`HMGET`（获取多个字段的值）。

#### 实现：

- 如果哈希类型元素个数小于 `512`个，所有值小于 `64`字节，则使用 `ziplist`作为Hash类型的底层数据结构，否则使用哈希表作为底层数据结构
- Redis 7.0中，压缩列表废弃，使用 `listpack`。

- Redis中的哈希表使用 **链式哈希**来解决哈希冲突，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链条
- ![img](https://cdn.xiaolincoding.com//mysql/other/dc495ffeaa3c3d8cb2e12129b3423118.png)

##### Rehash

- 由于Redis使用了链式哈希的方式去解决哈希冲突，那么随着链表长度的增大，查询这一个位置上的耗时就会增加，因为链表的查询时O(N)
- 为了解决这个问题，就要进行rehash，也就是对哈希表进行扩容
- Redis在实际上会去创建两个哈希表，结构如下：![img](https://cdn.xiaolincoding.com//mysql/other/2fedbc9cd4cb7236c302d695686dd478.png)
- 正常的情况下，插入的数据都会写入 哈希表1，此时 哈希表2 并没有分配空间
- 随着数据增多，触发了rehash的操作，这一步分为三步：
  - 给 哈希表2 分配空间，一般是 哈希表1 的两倍
  - 将 哈希表1 的数据迁移到 哈希表2
  - 迁移完毕后，哈希表1 的空间会被释放，把 哈希表2 设置为 哈希表1，然后新建一个空白的 哈希表2，为下一次rehash做准备
- 但是，**如果哈希表1 的数据非常多，那第二步数据迁移的时候会非常耗时，可能就直接阻塞Redis了，无法服务其他请求**

##### 渐进式rehash

- Redis采取了渐进式 rehash的方式来进行数据迁移，也就是数据不是一次性迁移完成，而是分了多次
- 渐进性rehash的流程：
  - 给 哈希表2 分配空间
  - 在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis除了会执行对应的操作之外，还顺序将 哈希表1 中索引位置上的所有 key-value迁移到 哈希表2
  - 随着处理客户端发起的哈希表请求数量越多，最终某个时间点会把 哈希表1 的所有key-value 迁移到 哈希表2，从而完成了rehash
- 这样就巧妙了将迁移工作分了多次进行完成
- 在渐进性rehash的过程中，会有两个哈希表同时操作，比如查找一个值的时候，会先去 哈希表1查找，如果找到就把数据从哈希表1对应的索引位置上的key-value全部迁移到哈希表2，如果找不到就去哈希表2找
- 同时，在新增key-value时，是直接保存到哈希表2，这样子就保证了哈希表1的元素只会减少，最终全部迁移到哈希表2

##### rehash的触发条件

- rehash 的触发条件跟 **负载因子（load factor）**有关系
- 负载因子可以这么计算：
- ![img](https://cdn.xiaolincoding.com//mysql/other/85f597f7851b90d6c78bb0d8e39690fc.png)
- 触发rehash操作的条件主要有两个：
  - **当负载因子大于等于1，并且Redis没有执行bgsave命令或者bgrewriteaof命令，也就是没有执行RDB快照或进行AOF重写的时候，就进行rehash操作**
  - **当负载因子大于等于5时，说明哈希冲突已经很严重了，不管有没有在执行 bgsave 或 bgrewriteaof 都要强制执行rehash操作**

### Set

- `Set`类似于Java中的`Set`，不过Redis提供的`Set`的功能更强大，可以很轻松的求两个Set的并集，差集和交集

  | 命令                                  | 介绍                                                 |
  | ------------------------------------- | ---------------------------------------------------- |
  | SADD key member1 member2 ...          | 向指定集合添加一个或多个元素                         |
  | SMEMBERS key                          | 获取指定集合中的所有元素                             |
  | SCARD key                             | 获取指定集合的元素数量                               |
  | SISMEMBER key member                  | 判断指定元素是否在指定集合中                         |
  | SINTER key1 key2 ...                  | 获取给定所有集合的交集                               |
  | SINTERSTORE destination key1 key2 ... | 将给定所有集合的交集存储在 destination 中            |
  | SUNION key1 key2 ...                  | 获取给定所有集合的并集                               |
  | SUNIONSTORE destination key1 key2 ... | 将给定所有集合的并集存储在 destination 中            |
  | SDIFF key1 key2 ...                   | 获取给定所有集合的差集，所有属于key1但是不属于后续的 |
  | SDIFFSTORE destination key1 key2 ...  | 将给定所有集合的差集存储在 destination 中            |
  | SPOP key count                        | 随机移除并获取指定集合中一个或多个元素               |
  | SRANDMEMBER key count                 | 随机获取指定集合中指定数量的元素                     |

- 使用场景：

  - 需要存放数据不能重复的场景
    - 点赞
    - 命令: `SCARD`
  - 需要求差集，并集，交集的场景
    - 共同好友，共同关注，好友推荐等
    - `SINTER`, `SINTERSOTRE`, `SUNION`,`SUNIONSTORE`,`SDIFF`,`SDIFFSTORE`
  - 获取随机数据的场景
    - 抽奖系统，随机点名
    - `SPOP`,`SRANDMEMBER`

#### 实现

- Set类型底层数据结构由 **哈希表或整数集合实现**
  - 如果集合中的元素都是整数小于 `512`（默认值，set-maxintset-entries配置）个，Redis会使用整数集合作为Set类型的底层数据结构
  - 如果不满足以上条件，Redis使用 **哈希表**作为Set类型的底层数据结构

##### 整数集合

整数集合本质上是一块连续内存空间，结构体如下：

```c
typedef struct intset {
    //编码方式
    uint32_t encoding;
    //集合包含的元素数量
    uint32_t length;
    //保存元素的数组
    int8_t contents[];
} intset;
```

保存元素的集合是一个contents数组，虽然这里声明为 int8_t类型，但是实际上并不保存任何 int8_t类型的数据，实际类型由encoding的属性值决定

- encoding为 `INTSET_ENC_INT16`，那么contents就是一个int16_t数组
- encoding为 `INTSET_ENC_INT32`，那么contents就是一个int32_t数组
- encoding为 `INTSET_ENC_INT64`，那么contents就是一个int64_t数组

不同类型的contents数组，意味着数组的大小也会不同

##### 整数集合的升级操作

- 整数集合会有一个升级规则，当加入的元素类型（int32_t）比整数集合当前所有的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展contents数组的空间大小，然后才能将新元素加入到整数集合里，升级的过程中也要维持整数集合有序性
- 整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后将每个元素按间隔类型大小分隔，如果encoding属性值为INTSET_ENC_INT16，则每个元素间隔就是16位。
- 举例子，现在整数集合中有3个类型为 int16_t的元素：
- ![img](https://cdn.xiaolincoding.com//mysql/other/5dbdfa7cfbdd1d12a4d9458c6c90d472.png)
- 现在要加入一个新的元素 65535，这个新元素需要使用 int32_t类型来保存，所以整数集合需要进行升级，首先对contents数组进行扩容，在原本的空间上再扩容80位(4 * 32 - 3 * 16 = 80)，**这样就可以存4个类型位 int32_t的元素**
- ![img](https://cdn.xiaolincoding.com//mysql/other/e2e3e19fc934e70563fbdfde2af39a2b.png)
- 然后就把前三个元素转换为 int32_t类型，然后把转换后的元素放到正确的位置上
- ![img](https://cdn.xiaolincoding.com//mysql/other/e84b052381e240eeb8cc97d6b729968b.png)

###### 整数集合升级有什么好处呢？

- 如果要一个数组同时保存 int16_t、int32_t、int64_t类型的元素，最简单的做法就是直接使用int_64t类型的数组，但是这样子，当元素都是int_16t类型的时候，就会造成内存浪费的情况。
- 整数集合升级就能避免这个情况，如果一直向整数集合添加int16_t类型的元素，那么整数集合的底层实现就一直是int16_t类型的数组，只有在我们要将int32_t类型或int64_t类型的元素添加到集合时，才会对数组进行升级操作
- 所以，整数集合升级的好处是 **节省内存资源**

##### 整数集合支持降级操作吗？

- 不支持降级，如果升级了，就会一直保持升级后的状态，比如前面的例子，如果删除了 65535，整数集合的数组还是 int_32t类型的，不会降为 int16_t

### ZSET（有序集合）

| 命令                                          | 介绍                                                         |
| --------------------------------------------- | ------------------------------------------------------------ |
| ZADD key score1 member1 score2 member2 ...    | 向指定有序集合添加一个或多个元素                             |
| ZCARD KEY                                     | 获取指定有序集合的元素数量                                   |
| ZSCORE key member                             | 获取指定有序集合中指定元素的 score 值                        |
| ZINTERSTORE destination numkeys key1 key2 ... | 将给定所有有序集合的交集存储在 destination 中，对相同元素对应的 score 值进行 SUM 聚合操作，numkeys 为集合数量 |
| ZUNIONSTORE destination numkeys key1 key2 ... | 求并集，其它和 ZINTERSTORE 类似                              |
| ZDIFFSTORE destination numkeys key1 key2 ...  | 求差集，其它和 ZINTERSTORE 类似                              |
| ZRANGE key start end                          | 获取指定有序集合 start 和 end 之间的元素（score 从低到高）   |
| ZREVRANGE key start end                       | 获取指定有序集合 start 和 end 之间的元素（score 从高到底）   |
| ZREVRANK key member                           | 获取指定有序集合中指定元素的排名(score 从大到小排序          |

- 应用场景：
  - 需要随机获取数据源中的元素根据某个权重进行排序
    - 各种排行榜
    - `ZRANGE`，从小到大排，`ZREVRANGE`从大到小排，`ZREVRANK`指定元素排名
  - 优先级队列

#### 实现

- Zset底层使用跳表和哈希表联合进行查询，好处就是既能高效的范围查询，也可以进行高效的单点查询

- 不过，在数据量较小的时候，`512`个以下及数据小于 `64`字节，使用压缩列表

- ```c
  typedef struct zset {
      dict *dict;
      zskiplist *zsl;
  } zset;
  ```

- Zset对象在执行数据插入或者数据更新时，会依次在跳表中和哈希表中插入或更新相关数据，从而保证跳表和哈希表中记录的信息保持一致

- Zset对象能支持范围查询（ZRANGEBYSCORE操作），就是因为它的数据结构采用了跳表，而又能以常数时间复杂度查询元素权重（ZSCORE），就是因为同时采用了哈希表进行索引

##### 跳表

- 链表在查询元素的时候，因为需要逐一查找，所以效率非常低，时间复杂度为 O(N)，于是就出现了跳表，**在链表的基础改进过来，实现了一种 多层 的有序链表**，这样的好处就是可以快读定位数据

- ![img](https://cdn.xiaolincoding.com//mysql/other/2ae0ed790c7e7403f215acb2bd82e884.png)

- 头节点有 L0 ~ L2三个指针，分别指向了不同层级的节点，每个层级的节点通过指针连接起来

  - L0层共有5个节点，分别是节点1、2、3、4、5
  - L1层共有3个节点，分别是节点2、3、5
  - L2层只有1个节点，就是节点3

- 如果在链表中查找元素4，只能从头开始查找，需要4次，而使用跳表，只需要从L2层级直接跳到节点3，然后在往后一步就可以找到节点3，查找了两次

- 查找过程就是在各个层级跳来跳去，最后定位到元素。时间复杂度为O(logN)

- 如何实现的多层级呢？跳表节点的数据结构为：

- ```c
  typedef struct zskiplistNode {
      //Zset 对象的元素值
      sds ele;
      //元素权重值
      double score;
      //后向指针
      struct zskiplistNode *backward;
    
      //节点的level数组，保存每层上的前向指针和跨度
      struct zskiplistLevel {
          struct zskiplistNode *forward;
          unsigned long span;
      } level[];
  } zskiplistNode;
  ```

- Zset对象要同时保存 元素 和 元素的权重，对应节点中的 ele 和 score。每个节点有一个向后指针，指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，倒序查找方便

- 跳表是一个带有层级关系的链表，每个层级可以包含多个节点，每个节点通过指针连接起来，主要就是靠 zskiplistLevel结构体的level数组

- level数组每一个元素代表跳表的一层，比如level[0]表示第一层，level[1]表示第二层。zskiplistLevel结构体里定义了 指向下一个跳表节点指针 和 跨度，跨度是用来记录两个节点之间的距离。

- 比如这张图展现了各个节点跨度：

- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.png)

- 跨度并不是用来遍历操作的，因为数组内记录了下一个节点的指针

- **跨度是用来计算节点在跳表中的排位**，从头节点到该节点的查询路径上，直接将所有层的跨度累加就是这个目标节点的跨度了

- 比如查找4的排位，首先头节点到节点3，此时跨度为3，然后从节点3到节点4，跨度为1，此时累加跨度为4，所以节点4的排位是4

- 当然，头节点其实也是跳表节点zskiplistNode，不过头节点的后向指针，权重和元素值都没有用到

- 既然有节点，我们肯定还有一个数据结构存储了节点

- ```c
  typedef struct zskiplist {
      struct zskiplistNode *header, *tail;
      unsigned long length;
      int level;
  } zskiplist;
  ```

- 跳表的结构包含了：

  - 跳表的头尾节点，便于在 O(1)时间复杂度内访问到跳表的头节点和尾节点
  - 跳表的长度，便于在O(1)的时间复杂度获取跳表的节点数量
  - 跳表的最大层数，便于在O(1)时间复杂度获取条表中层高最大的那个节点层数量

###### 跳表节点查询过程

- 查询一个节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层，在遍历某一层的跳表节点时，会用跳表节点中SDS类型的元素和元素权重进行判断，一共两个条件
  - 如果当前节点权重 < 要查找的权重，跳表会访问该层上的下一个节点
  - 如果当前节点权重 == 要查找的权重，并且当前节点的SDS类型数据 < 要查找的数据时，就会访问该层的下一个节点
- 如果上面两个条件不满足，或者下一个节点为空，跳表就会使用目前遍历的节点的level数组里的下一层支持，沿着下一层指针继续查找
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.drawio.png)
- 如果要查找 元素：abcd，权重：4的节点，过程为：
  - 先从头节点最高层开始，L2指向了 元素：abc，权重：3，这个节点的权重 < 要查找的节点，所以继续往后查找
  - 发现下一个节点为空，所以就跳到 元素：abc，权重：3 节点的下一层去找，也就是level[1]
  - 然后看下一个元素 元素：abcde，权重：4，虽然权重和我们要查找的元素相同，但是元素SDS类型大于要查找大元素，所以继续调大level[0]
  - 发现level[0]的下一个指针就是我们要找的节点，查询结束

###### 跳表节点层数设置

- 跳表相邻两层的节点数量比例会影响跳表的查询性能

- 比如：

- ![img](https://cdn.xiaolincoding.com//mysql/other/2802786ab4f52c1e248904e5cef33a74.png)

- 这个跳表去查询节点6，其实和链表中时一样的，复杂度为O(N)去了，所以为了降低查询复杂度，就要维持相邻层的节点数关系

- **跳表的相邻两层的节点数量最理想比例为2:1，查找复杂度可以降低到 O(logN)**

- 比如：

- ![img](https://cdn.xiaolincoding.com//mysql/other/cdc14698f629c74bf5a239cc8a611aeb.png)

- 那如何维护这个比例 2:1 呢？

  - 如果采用新增节点或删除节点时，调整跳表节点以维护比例的话，那会带来额外的开销

  - Redis采用了一个很巧妙的方法，**跳表在创建节点的时候，随机生成每个节点的层数**，并没有严格维护相邻两层节点数量比例为  2 : 1

  - 做法为：**跳表创建节点的时候，会生成范围 [0 - 1]的一个随机数，如果这个随机数小于0.25(相当于概率25%)，那么就会层数增加1，然后继续生成下一个随机数，直到随机数的结果大于0.25结束，最终确定该节点的层数**

  - 这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制为64

  - 虽然前面的例子头节点都是3层高，但是如果 **层高限制为64，则创建跳表 头节点的时候，会直接创建64层高的头节点**

  - ```c
    /* Create a new skiplist. */
    zskiplist *zslCreate(void) {
        int j;
        zskiplist *zsl;
    
        zsl = zmalloc(sizeof(*zsl));
        zsl->level = 1;
        zsl->length = 0;
        zsl->header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);
        //这个ZSKIPLIST_MAXLEVEL就是最高层数，Redis7.0定义为32，Redis5.0定义为64，Redis3.0定义为32
        for (j = 0; j < ZSKIPLIST_MAXLEVEL; j++) {
            zsl->header->level[j].forward = NULL; //初始下一个节点为null
            zsl->header->level[j].span = 0; //初始跨度为0
        }
        zsl->header->backward = NULL;
        zsl->tail = NULL;
        return zsl;
    }
    ```

###### 为什么使用跳表，不使用平衡树

- **跳表做范围查找的时候，比平衡树简单**：平衡树上，我们找到一个最小值以后，还要通过中序遍历的方式找到不超过最大值的其他节点，而跳表中找到最小值以后，直接对第一层链表进行遍历即可
- **跳表比平衡树在代码上易于实现很多**：平衡树在插入和删除时可能会引起子树的调整，逻辑复杂，而跳表中插入和删除节点只需要修改相邻节点的指针即可，简单快速。

### BitMap（位图）

#### 位图是什么

- 位图是一串连续的二进制数组（0和1），可以通过偏移量定位元素。BitMap通过最小单位bit来进行 `0|1`的实则hi，表示某个元素的值或状态，复杂度为O(1)
- 特别节省空间，特别时候一些大数据量且使用 **二值统计的场景**

#### 内部实现

- BitMap本身使用String类型作为底层数据结构实现的一种统计二值的数据类型
- String类型是会保存为二进制的字节数组，所以，Redis就把字节数组的每个bit利用起来，用来表示一个元素的二值状态

#### 常用命令

- 基本操作：

- ```
  #设置值，value只能是0 和 1
  SETBIT key offset value
  #获取值
  GETBIT key offset
  #获取指定范围内值为 1 的个数
  # start 和 end以字节为单位
  BITCOUNT key start end
  ```

#### 常用场景

##### 签到统计

- 在签到打卡的场景中，我们只记录签到(1) 或 未签到(0)，所以是一个典型的二值状态

- 每个用户一天签到用1个bit位就可以表示，一个月的签到情况就是31个bit位，而一年签到也就365个bit位

- 比如，统计ID100 的用户在2022年6月份的签到情况

  - 第一步，记录该用户6月3号签到

    - ```
      #offset 为 2，0为1号
      SETBIT uid:sign:100:202206 2 1
      ```

  - 第二步，检查该用户6月3是否签到

    - ```
      GETBIT uid:sign:100:202206 2
      ```

  - 第三步，统计该用户在6月份的签到次数

    - ```
      BITCOUNT uid:sign:100:202206
      ```

  - 这样子就可以直到该用户在6月份的签到情况

### HyperLogLog

#### HyperLogLog是什么

- Redis HyperLogLog是Redis 2.8.9新增的数据类型，是一种用于 统计基数 的数据集合类型，基数统计就是指统计一个集合中不重复的元素。但是HyperLogLog的统计规则是基于概率去完成的，有误差率，大概在 0.81%
- 所以，**HyperLogLog提供不准确的去重计数**
- HyperLogLog的优点是，在输入元素的数量或者体积非常大的时候，计算基数所需要的内存空间总是固定的，并且非常小
- 在Redis里面，**每个HyperLogLog键只需要花费12KB内存，就可以计算接近 `2^64`个不同元素的基数**，和Hash，Set比起来，HyperLogLog非常节省空间

#### 常见命令

- HyperLogLog命令不多：

- ```
  #添加指定元素到HyperLogLog中
  PFADD key element [element...]
  
  #返回给定 HyperLogLog的基数估算值
  PFCOUNT key [key...]
  
  #将多个 HyperLogLog合并为一个HyperLogLog
  PFMERGE deskey sourcekey [sourcekey...]
  ```

#### 应用场景

- 可以使用HyperLogLog来统计百万级网页的UV(独立访客，Unique Visitor)计数。

- 在统计UV时，可以使用PFADD命令（将元素添加到HyperLogLog）把访问的每个用户添加到HyperLogLog中

  - ```
    PFADD page1:uv user1 user2 user3 user4 user5
    ```

- 然后就可以使用PFCOUNT命令直接获取到page1的UV值了，这个命令就是返回HyperLogLog的统计结果

  - ```
    PFCOUNT page1:uv
    ```

- 不过呢，要注意HyperLogLog是有误差的，如果要精确的结果，最好还是使用Set或Hash

### QuickList

- Redis3.0之前，List对象的底层数据结构为双向链表 或 压缩列表。在Redis3.2后，List对象底层改为了quicklist来实现
- quicklist就是 **双向链表 + 压缩列表实现**，quicklist本身是一个链表，链表中的每个元素是一个压缩列表
- 压缩列表的不足在于，虽然可以压缩空间，但是可能会有连锁更新的问题
- quicklist解决方案，**通过控制每个链表节点中的压缩列表的大小或元素个数，来规避连锁更新的问题，因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供更好的访问性能**

#### quicklist的结构设计

- quicklist的结构体和链表很类似，包含了链表头和链表尾，区别就是quicklist中的每个节点都是quicklistNode

- ```c
  typedef struct quicklist {
      //quicklist的链表头
      quicklistNode *head;      //quicklist的链表头
      //quicklist的链表尾
      quicklistNode *tail; 
      //所有压缩列表中的总元素个数
      unsigned long count;
      //quicklistNodes的个数
      unsigned long len;       
      ...
  } quicklist;
  ```

- 看看quicklistNode的结构

- ```c
  typedef struct quicklistNode {
      //前一个quicklistNode
      struct quicklistNode *prev;     //前一个quicklistNode
      //下一个quicklistNode
      struct quicklistNode *next;     //后一个quicklistNode
      //quicklistNode指向的压缩列表
      unsigned char *zl;              
      //压缩列表的的字节大小
      unsigned int sz;                
      //压缩列表的元素个数
      unsigned int count : 16;        //ziplist中的元素个数 
      ....
  } quicklistNode;
  ```

- quicklistNode中保存了前序节点和后继节点，所以就可以形成一个双向链表。链表节点的元素不再是单纯的元素值，而是一个压缩列表：

- ![img](https://cdn.xiaolincoding.com//mysql/other/f46cbe347f65ded522f1cc3fd8dba549.png)

- 在向quicklist添加元素的时候，不会像普通链表那样，直接新建一个节点，而是检查插入位置的压缩列表可不可以容纳该元素，如果可以容纳就直接保存到quicklistNode中的压缩列表，如果容纳不了，才会去新建一个节点quicklistNode

- quicklist会去控制quicklistNode结构里的压缩列表大小或元素，来规避连锁更新带来的风险，但是没有完全解决连锁更新的问题

### listpack

- quicklist没有完全解决连锁更新的问题，这是因为这个和压缩列表的数据结构相关，所以为了规避这个问题，要去设计一个新的数据结构
- 所以在Redis5.0新设计了一个数据结构叫listpack，目的就是代替压缩列表，最大的特点就是listpack的每个节点不再保存前一个节点的长度，而`prelen`这个字段就是压缩列表会产生连锁更新的问题

#### listpack的结构设计

- listpack采取了压缩列表很多优秀的设计，比如还是使用一块连续的内存空间紧凑的保存数据，并且和压缩列表一样，为了节省内存开销，listpack节点会采用不同的编码方式保存不同大小的数据
- 先看看listpack结构：
- ![img](https://cdn.xiaolincoding.com//mysql/other/4d2dc376b5fd68dae70d9284ae82b73a.png)
- listpack头包含了两个属性，分别记录了listpack总字节数和元素数量，然后listpack末尾也有一个表示位。listpack entry就是listpack的节点
- 每个节点的结构如下：
- ![img](https://cdn.xiaolincoding.com//mysql/other/c5fb0a602d4caaca37ff0357f05b0abf.png)
- 主要包含了三个部分：
  - encoding，定义该元素的编码类型，对不同长度的整数和字符串进行编码
  - data，实际存放的数据
  - len，encoding + data的总长度
- 可以看到，**listpack并没有记录前一个节点的长度，而是记录当前节点的长度，当插入一个新元素的时候，并不会影响其他节点的长度字段的变化，所以可以避免连锁更新的问题。**

## Redis中的持久化机制

### RDB(Redis Database)持久化

- 快照持久化：可以通过创建快照的方式获取某个时间点上的副本，用于创建相同数据的服务器副本，也可以用于重启服务器数据恢复

- 在`redis.config`中进行配置，这是默认的持久化方式。

- ```clojure
  save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发bgsave命令创建快照。
  save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发bgsave命令创建快照。
  save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发bgsave命令创建快照。
  ```

- Redis有两个命令来生成RDB快照文件

  - `save`，同步操作，会阻塞Redis主线程
  - `bgsave`，fork一个子进程，子进程进行备份操作，这是默认选项

### AOF(Append Only File)持久化

- AOF持久化有些类似于`InnoDB`中的`redo log`和`bin log`，默认Redis是没有开启的，Redis 6.0后默认开启

  - ```sh
    appendonly yes
    ```

- 开启以后，每执行一条更新语句(更改Redis数据的命令)，就会将命令写入AOF缓冲区`server.aof_buf`（`redo log`是每一条更新语句都会先写入到`redo log buffer`），然后再写入到AOF文件中，此时也还没有写入到磁盘了，还在系统的内存缓冲区（设置为2时`redo log`写入到`page cache`。`bin log`写入到线程自己的`bin log cache`），最后在根据持久化方式，写入磁盘中。(`innodb_flush_log_at_trx_commit`，决定何时刷盘。`sync_binlog`何时从内存缓冲区刷盘)

- 以上说的不管是日志还是AOF持久化，都是先到内存缓冲区的，然后再根据策略决定合适刷盘

  - `innodb_flush_log_at_trx_commit`
    - 0 表示只写到自己的缓冲区，由守护线程去刷盘
    - 1 表示每次事务提交都刷盘
    - 2 表示写到文件缓冲区，由守护线程去刷盘
  - `sync_binlog`
    - 0 表示只写到文件缓冲区，由系统决定刷盘
    - 1 表示每次事务提交都去刷盘。

#### AOF的工作流程

- 5步：
  - **命令追加（append）**：所有的写命令会追加到 AOF 缓冲区中。
  - **文件写入（write）**：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用`write`函数（系统调用），`write`将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。
  - **文件同步（fsync）**：AOF 缓冲区根据对应的持久化方式（ `fsync` 策略）向硬盘做同步操作。这一步需要调用 `fsync` 函数（系统调用）， `fsync` 针对单个文件操作，对其进行强制硬盘同步，`fsync` 将阻塞直到写入磁盘完成后返回，保证了数据持久化。
  - **文件重写（rewrite）**：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
  - **重启加载（load）**：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。
- ![AOF 工作基本流程](https://oss.javaguide.cn/github/javaguide/database/redis/aof-work-process.png)

#### AOF持久化方式（策略）

- 有三种`fsync`策略
  - `appendfsync always`：主线程调用`write`之后，后台线程`aof_fsync`立即执行`fsync`，将内核缓冲区数据写入到磁盘中，最安全，但是效率最低，`write`之后要等待`fsync`返回
  - `appendfsync everysec`：主线程`write`之后立即返回，由`aof_fsync`每秒执行一次`fsync`，效率增加，最多丢失1s数据
  - `appendfsync no`：主线程`write`之后立即返回，由操作系统决定何时进行同步，Linux下默认为30s一次。
- 可以看到这里与MySQL中日志的异同
  - `sync_binlog`设置为0，表示由操作系统来决定何时进行同步。
  - `innodb_flush_log_at_trx_commit`设置为0或2，守护线程1s执行一次。
  - 不过呢，MySQL中的`bin log`在事务提交的时候执行`write`。`redo log`对应的策略设置为2时，也是事务提交的时候执行`write`

#### AOF是在执行命令后再记录的日志

- 而MySQL是在执行命令前记录的日志，这两种有啥区别：
  - 命令后执行：
    - 优点：
      - 不会阻塞当前命令的执行
      - 速度更快，因为不需要进行语法检查
    - 缺点：
      - 如果刚执行完命令就宕机了，这一条修改就消失了，而先记录日志的话，就算执行命令后宕机，也可以恢复。
      - 可能会阻塞后续的命令执行（Redis记录日志是在主线程做的）

#### AOF重写机制

- 因为如果一直追加AOF文件时，会变得越来越大，系统去恢复的时候就会很久，所以要定期进行重写，重写其实很简单，就是将原来AOF文件中的数据进行压缩，比如多条命令改为一条命令，或者说只记录keys的最后状态，原来的冗余丢弃。
- 一般使用`BGREWRITEAOF`，使用子进程去执行重写，这样不会阻塞主进程。
- 重写时会有一个问题，就是此时主进程还在不断地执行新的命令，那这些命令我们肯定不能说丢弃，所以重写的时候会开启一个AOF重写缓冲区，将重写时的新命令记录一下，当子进程完成重写以后，再把缓冲区的新命令加入到AOF末尾，这样就保证了此时的新的AOF文件与数据库一致，最后就将旧的AOF文件进行替换。
- 可以手动执行`BGREWRITEAOF`，也可以配置自动执行
  - `auto-aof-rewrite-min-size`：在AOF文件达到一个上限时，触发AOF，默认为64MB
  - `auto-aof-rewrite-percentage`：当前AOF与上次重写的AOF大小的比值。如果当前文件大小增加了这个百分比，就重写。比如原来重写完是3MB，设置为100%，那么当AOF到达6MB(原来的2倍)，就会开启重写。默认为100，设置为0表示禁用自动重写。

#### 校验机制

- 使用校验和来校验，对整个AOF文件进行CRC64算法计算得数字，如果文件内容发生改变，那么校验和也会改变。AOF最后会记录保存一个校验和，Redis启动时会比较计算得校验和和这个保存得校验和，判断是不是完整。如果不完整，Redis会拒绝启动。

### 大Key对AOF日志，AOF重写和RDB的影响

- 大key对于AOF日志设置为Always时，由于Always策略是一个同步策略，主线程执行完`write()`会立马执行`fsync()`，那么如果写入的是一个大key，那么主线程执行 `fsync()`函数的时候，阻塞时间会比较久，因为写入数据量很大，数据同步到磁盘上的时间很耗时
- 对于 `EverySec`和 `No`，这两个策略都是异步执行的，所以并不会造成影响
- 对于AOF重写和RDB，如果使用后台命令(`bagsave` 和 `bgrewriteaof`)，都是会通过 `fork()`去创建一个子进程来处理任务
- 创建子进程的时候，操作系统会把父进程的 页表 复制给子进程，页表记录了虚拟地址和物理地址的映射，而不会去复制物理地址，所以即使两者的虚拟空间不同，但是可以映射到同一个物理地址
- ![img](https://cdn.xiaolincoding.com//mysql/other/06657cb93ffa4a24b8fc5b3069cb29bf.png)
- 这样子子进程可以共享父进程的物理内存数据，这样可以节约物理内存资源，页表对应的页表项的属性会标记该物理地址权限为只读
- 随着Redis 存在越来越多的大Key，那么Redis就会占用很多内存，对应的页表就会越大
- 在通过 `fork()`函数创建子进程的时候，虽然不会去复制父进程的物理内存，但是 **内核会把父进程的页表复制一份给子进程，如果页表很大，那么复制过程就会很耗时，执行fork()函数的时候就会发生阻塞现象**
- 而 `fork()`函数的调用是在主线程调用的，如果 `fork()`函数发生阻塞，那么就会阻塞Redis主线程，而当主线程阻塞以后，就无法处理后续客户端的请求了
- 可以使用 `info`命令获取到lastest_fork_usec指标，表示Redis最近一次 `fork`操作耗时
- 如果 `fork`耗时很大，比如超过1秒，则需要进行优化
  - 单个实例的内存占用控制在10GB以下，这样子 fork函数可以很快返回
  - 如果Redis只当作缓存，不考虑Redis的数据安全问题，那就可以关闭AOF和AOF重写，这样就不会去调用fork函数了


#### 什么时候发生物理内存的复制？

- 当父进程或者子进程向共享内存发起写操作的时候，CPU会触发 **写保护中断**，这个 写保护中断是由于违反权限导致的，然后操作系统会在 写保护中断处理函数 里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，然后才会对内存进行写操作，这个过程称为 **写时复制**
- ![img](https://cdn.xiaolincoding.com//mysql/other/451024fe10374431aff6f93a8fed4638.png)
- 写时复制就是发生写操作的时候，操作系统才会去复制物理内存，这样子是为了防止fork创建子进程时，由于物理内存数据的复制时间太长而导致父进程长时间阻塞。如果一上来就把物理内存都复制一遍，那假设里面有大Key，就会直接造成阻塞
- 注意，这里是对原有数据进行复制，父进程去修改的是原有物理地址上的数据，而子进程是记录不到父进程修改后的，子进程操作的是复制的物理地址的数据，所以得等到下一次RDB或AOF重写才可以更新到。
- 当然，如果创建完子进程后，**父进程对共享内存中的大Key进行了修改，那么内核就会触发写时复制，会把被操作的物理内存复制一份，而大Key占用的物理内存较大，所以复制为了内存这一过程，就比较耗时，父进程（主线程）就会发生阻塞**
- 所以有两个阶段会造成父进程阻塞
  - 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞时间与页表的大小相关，页表越大，阻塞时间也就越长
  - 创建完子进程后，如果子进程或父进程去修改共享内存，就会发生写时复制，也就是复制物理内存，如果内存越大，那么耗时越长
- 还有一个点，如果 **Redis开启了内存大页，也会影响Redis的性能**
- Linux内核从2.6.38开始支持内存大页机制，该机制支持2MB大小的内存页分配，而常规的内存页分配是4KB
- 如果采用了内存大页，就算客户端请求只是100B的数据，发生写时复制时，也会去拷贝2MB的大页，而使用常规的内存分页，就只是4KB
- 这样子就会拖累Redis的速度，即写操作的执行时间，可以关闭大页（默认就是关闭）

### Redis4.0中得混合持久化

- 混合持久化就是混合了RDB与AOF，在AOF重写得时候，直接将RDB得内容放入文件开头，然后再记录重写缓冲区得内容，最后重写完成，这样可以快速得加载，也避免丢失过多得数据。但是可读性较差，RDB文件时压缩格式，不是AOF格式。

### 那如何选择RDB和AOF呢

- RDB得优点：
  - 存储得是压缩过得二进制数据，保存某个时间点得数据集，因此文件大小很小。而AOF得把命令一个一个写进去，所以文件大小会远远大于RDB，虽然可以重写，但是7.0之前因为重写缓冲区得存在，使得内存占用率也会非常的高
  - RDB因为是保存的数据集，因此恢复的时候直接解析还原即可，不用执行命令。而AOF里面保存的是命令，所以得依次执行命令，速度会较慢。所以大数据集恢复的时候，RDB效率会更高
- AOF的优点：
  - AOF更加安全，可以做到实时和秒级别的持久化数据。RDB文件生成过程比较的繁重，虽然`BGSAVE`不会阻塞主线程，但是依然是在消耗CPU资源的，如果`BGSAVE`过于频繁，可能会把Redis干宕机了。AOF就支持实时和秒级别的持久化数据，而且因为只是将命令Append到文件末尾，所以操作很轻量
  - RDB文件是二进制保存的，而且Redis在版本更新的同时，也会有多个版本的RDB文件，所以有可能老版本的Redis不兼容新版本的RDB文件
  - AOF文件是可读的，包含了可理解，可解析的操作日志。我们可以导出AOF进行分析，也可以直接修改AOF进行解决一些问题。最经典的就是比如不小心执行了一个FLUSHALL文件，在AOF还没被重写的时候，只要把最后一行FLUSHALL给他删掉，再重启即可。
- 所以呢：
  - 如果Redis保存的数据丢失一些也没关系，选择RDB
  - 不建议单独使用AOF，因为时不时创建一个RDB快照可以进行数据库的备份，也可以更快的重启
  - 如果安全系数较高的环境下，选择同时开启RDB和AOF，或者使用混合持久化。

# Netty

## BIO和NIO

- BIO是阻塞IO，相关方法都会使线程阻塞
  - `ServerSocketChannel.accept()`会在没有建立连接的时候阻塞
  - `SocketChannel.read`会在没有数据可读的时候阻塞
- NIO是非阻塞IO，Java中的NIO还包含了多路复用：
  - `ServerSocketChannel.accept()`在非阻塞模式下如果没有建立连接，会返回null，继续运行
  - `SocketChannel.read`在没有数据可读的情况下，会返回0，线程不会阻塞。可以去执行其他`SocketChannel`的read方法
  - 可是，我们一般会使用`while(true)`来不断监听连接，如果不阻塞的话线程就会空轮询。

## 多路复用

- 多路复用可以使用Selector完成对多个Channel可读时间的监控。

  - 仅针对网络IO
  - 可以保证：
    - 有连接事件再去链接
    - 有可读事件再去读取
    - 有可写事件再去写入

- ```java
  package com.bomnmi.nio.c4;
  
  import lombok.SneakyThrows;
  import lombok.extern.slf4j.Slf4j;
  
  import java.io.IOException;
  import java.net.InetSocketAddress;
  import java.nio.ByteBuffer;
  import java.nio.channels.*;
  import java.util.Iterator;
  
  import static com.bomnmi.nio.c1.ByteBufferUtil.debugAll;
  
  /**
   * @author Bomnmi
   * @version 1.0
   * @date 2023/12/10 13:27
   */
  @Slf4j
  public class Server {
  
      @SneakyThrows
      public static void main(String[] args) {
          //1、创建Selector，管理多个Channel
          Selector selector = Selector.open();
  
          ServerSocketChannel ssc = ServerSocketChannel.open();
          ssc.configureBlocking(false);
          ssc.bind(new InetSocketAddress(8080));
  
          //2、建立 Selector和Channel之间的联系(注册)
          //SelectionKey 就是将来事件发生后，通过它可以知道事件和哪个Channel的事件
          SelectionKey sscKey = ssc.register(selector, 0, null);
          //sscKey只关注Accept事件
          sscKey.interestOps(SelectionKey.OP_ACCEPT);
          log.debug("register key:{}",sscKey);
          while(true){
              //3、select 方法，没有事件，线程阻塞。有了事件发生了，线程恢复运行。
              // select 在事件未处理时，它不会阻塞。事件发生后，要么处理，要么取消，不能置之不理。
              selector.select();
              //4、处理事件，selectedKeys 内部包含了所有发生的事件。
              Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();
              while (iterator.hasNext()) {
                  SelectionKey key = iterator.next();
                  //事件完成之后,selectedKeys中的元素不会自己删除,需要手动删除,否则下次处理就会出问题.
                  iterator.remove();
                  log.debug("key: {}", key);
                  //5.区分事件类型
                  if (key.isAcceptable()) {
                      ServerSocketChannel channel = (ServerSocketChannel)key.channel();
                      SocketChannel sc = channel.accept();
                      sc.configureBlocking(false);
                      ByteBuffer buffer = ByteBuffer.allocate(16); // attachment
                      SelectionKey scKey = sc.register(selector, 0, buffer); //将一个ByteBuffer作为附件关联到SelectionKey上
                      scKey.interestOps(SelectionKey.OP_READ);
                      log.debug("{}", sc);
                  } else if (key.isReadable()) { //如果是 read
                      try {
                          SocketChannel channel = (SocketChannel)key.channel();
                          //获取SelectionKey关联的附件.
                          ByteBuffer buffer = (ByteBuffer) key.attachment();
                          int read = channel.read(buffer); //如果是正常断开,read方法的返回值是-1
                          if (read == -1) {
                              key.cancel();
                          }else{
                              split(buffer);
                              if (buffer.position() == buffer.limit()) {
                                  ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity() * 2);
                                  buffer.flip();
                                  newBuffer.put(buffer);
                                  key.attach(newBuffer);
                              }
                              //debugRead(buffer);
                          }
                      } catch (IOException e) {
                          e.printStackTrace();
                          //客户端断开的时候,会发送read事件.
                          key.cancel(); //因为客户端断开了,因此需要将key取消
                      }
                  }
              }
          }
      }
      public static void split(ByteBuffer source) {
          source.flip();
          for (int i = 0; i < source.limit(); i++) {
              if (source.get(i) == '\n') {
                  int length = i - source.position() + 1;
                  ByteBuffer buffer = ByteBuffer.allocate(length);
                  for (int j = 0; j < length; j++) {
                      buffer.put(source.get());
                  }
                  debugAll(buffer);
              }
          }
          source.compact();
      }
  }
  ```

- 当select事件发生之后，会把相关的key放入`selectedKeys`集合当中，不过呢，处理完之后他不会自己删除，得我们手动删除一下。

  - 如果不删除的话，下次事件来以后，又会重复调用原来的事件，但是这个事件其实没有人触发，所以可能会造成空指针问题。

  - 比如第一次有一个链接事件accept，但是没有在`selectedKeys`集合中删除它，第二次又会进入这个判断，我们以为有新的连接了，但是其实是没有的，所以在给这个`SocketChannel`绑定时就会出现空指针异常

  - ```java
    ServerSocketChannel channel = (ServerSocketChannel)key.channel();
                        SocketChannel sc = channel.accept(); //这里sc是null，因为错误的进来了
                        sc.configureBlocking(false);
                        ByteBuffer buffer = ByteBuffer.allocate(16); // attachment
                        SelectionKey scKey = sc.register(selector, 0, buffer); //将一个ByteBuffer作为附件关联到SelectionKey上
                        scKey.interestOps(SelectionKey.OP_READ);
                        log.debug("{}", sc);
    ```

- `key.cancel`会把`selector`中的`channel`取消注册，后续就不关注它了。

## 零拷贝

### 传统IO的问题

- ![](D:\Idea\Netty\黑马Netty\讲义\Netty-讲义\img\0024.png)

- Java本身不具备IO读写能力，得使用操作系统的方法，所以要从用户态转换成内核态，然后调用操作系统的`read`将数据读入内核缓冲区。操作系统则使用`DMA(Direct Memory Access)`完成文件读，不会使用CPU
- 然后内核态转换成用户态，将内核缓冲区的数据读入用户缓冲区，CPU会参与拷贝，没有利用到DMA
- 调用`write`方法，将数据写入`socket`缓冲区，CPU参与拷贝
- 最后，因为Java不具备向网卡写数据的能力，所以得从用户态转换成内核他，调用操作系统的写能力，使用DMA将数据从`socket`缓冲区写入网卡。

### NIO的优化

- NIO使用`DirectByteBuf`，使用的是操作系统的内存
- 此时，我们不需要将内核缓冲区的数据拷贝到用户缓冲区去使用了，所以减少了一次复制，但是用户态与内核态的转换次数还是没有变，依旧是3次。
- ![](D:\Idea\Netty\黑马Netty\讲义\Netty-讲义\img\0025.png)
- 进一步优化，底层使用了linux2.1后提供的`sendFile`方法，Java中对应着两个`channel`调用`transferTo/transferFrom`拷贝数据
- ![](D:\Idea\Netty\黑马Netty\讲义\Netty-讲义\img\0026.png)
- Java调用`transferTo`后，从用户态转换成内核态，然后使用DMA从磁盘中读取到内核缓冲区
- 数据从内核缓冲区直接写入到`socket`缓冲区，这里要利用CPU复制
- 最后使用DMA将数据写入到网卡中
- 再次进一步优化 linux2.4
- ![](D:\Idea\Netty\黑马Netty\讲义\Netty-讲义\img\0027.png)
- Java调用`transferTo`方法后，用户态转换成内核态，使用DMA从磁盘中读取到内核缓冲区
- 将offset，length信息拷贝到socket缓冲区，基本上无消耗
- DMA通过`socket`缓冲区的这些信息，直接将数据从内核缓冲区写入网卡。
- 所谓的【零拷贝】，并不是真正无拷贝，而是在不会拷贝重复数据到 `jvm` 内存中，零拷贝的优点有

  * 更少的用户态与内核态的切换
  * 不利用 cpu 计算，减少 cpu 缓存伪共享
  * 零拷贝适合小文件传输

## Netty构建

### 服务器

- ```java
  new ServerBootstrap() //服务器启动器
      .group(new NioEventLoopGroup()) // 1 这里是线程池+selector多路复用
      .channel(NioServerSocketChannel.class) // 2 Channel的实现类，服务器的话就是NioServerSocketChannel
      .childHandler(new ChannelInitializer<NioSocketChannel>() { // 3 绑定一个子处理器，用来处理SocketChannel请求
          protected void initChannel(NioSocketChannel ch) {
              ch.pipeline().addLast(new StringDecoder()); // 5 解码器
              ch.pipeline().addLast(new SimpleChannelInboundHandler<String>() { // 6 真正处理的业务
                  @Override
                  protected void channelRead0(ChannelHandlerContext ctx, String msg) {
                      System.out.println(msg);
                  }
              });
          }
      })
      .bind(8080); // 4 绑定监听端口号
  ```

### 客户端

- ```java
  new Bootstrap() //启动客户端
      .group(new NioEventLoopGroup()) // 1 多路复用的实现，线程池 + selector
      .channel(NioSocketChannel.class) // 2 NioSocketChannel实现
      .handler(new ChannelInitializer<Channel>() { // 3 业务handler处理器
          @Override
          protected void initChannel(Channel ch) {
              ch.pipeline().addLast(new StringEncoder()); // 8 编码器
          }
      })
      .connect("127.0.0.1", 8080) // 4 连接端口号和ip
      .sync() // 5 同步方法，连接完成之前都在这里阻塞
      .channel() // 6 获取到对应的Channel
      .writeAndFlush(new Date() + ": hello world!"); // 7 写数据
  ```

### 核心组件

#### ByteBuf字节容器

- Netty对Java中的ByteBuffer进行了封装以及功能的增强。ByteBuffer使用起来过于繁琐，读写指针要不停的切换
- Netty中的ByteBuf使用了池化技术，ByteBuf可以被回收重复利用，不需要重复的创建新的ByteBuf
  - ByteBuf使用引用计数的方式来管理它的内存，当ByteBuf引用将为0时，会自动释放相关的资源，防止内存泄漏。
  - `PooledByteBuf`就是池化的ByteBuf，每个ByteBuf都是实现了`ReferenceCounted`接口，每个ByteBuf对象初始计数为1，调用`retain`方法则会使计数+1，`release`方法则会使计数-1。
  - 计数为0时会被回收至对象池中。因为JVM不知道这个引用计数的实现，所以如果一个ByteBuf对象不可达时，一样会被GC掉，此时，因为计数如果不为0的话，也不会回收到对象池中，那么就发生了内存泄漏。
- 扩容：
  - ByteBuf会自动扩容，不设定容量的话初始容量为10，规则是：
    - 如果内容不超过512的话，则选择下一个16的整数倍
    - 超过512的话，就按照2^n进行扩容，比如写入后大小为513，则扩容到1024
- 零拷贝相关的体现：
  - slice方法：
    - ByteBuf进行slice()之后，并不是真正的将原有的数据复制到切片当中，而是逻辑上将他分隔了，实际上底层还是同一个ByteBuf
    - ![](D:\Idea\Netty\黑马Netty\讲义\Netty-讲义\img\0011.png)
    -  不过，切片拥有自己的读写指针，所以原始ByteBuf读或写不会影响Slice
    - 但是原始ByteBuf或者切片进行了修改内容，那么就都会受到影响
  - duplicate方法
    - ![](D:\Idea\Netty\黑马Netty\讲义\Netty-讲义\img\0012.png)
    - 截取了原始ByteBuf中的内容，但是实际上并没有复制，而是与原始ByteBuf共用一个物理内存，拥有自己的读写指针
  - CompositeByteBuf
    - 可以将多个ByteBuf进行逻辑上的合并，避免真正的拷贝。
    - CompositeByteBuf 是一个组合的 ByteBuf，它内部维护了一个 Component 数组，每个 Component 管理一个 ByteBuf，记录了这个 ByteBuf 相对于整体偏移量等信息，代表着整体中某一段的数据。

      * 优点，对外是一个虚拟视图，组合这些 ByteBuf不会产生内存复制
      * 缺点，复杂了很多，多次操作会带来性能的损耗

#### EventLoop与EventLoopGroup

- `EventLoop`其实就是一个线程加上一个`selector`的组合，里面的run方法会处理`Channel`上的事件
  - 继承了`j.u.c.ScheduledExecutorService `因此包含了线程池中所有的方法
  - 继承了Netty自己的`OrderedEventExecutor`
- `EventLoopGroup`是包含多个`EventLoop`，管理所有的`EventLoop`的生命周期
- ![6e1e15c1448cc2bf5d9c24446f3c515b.png](https://cdn.nlark.com/yuque/0/2023/png/738439/1679572213010-4d5430af-5506-493a-9741-ec7fcaee5853.png?x-oss-process=image%2Fresize%2Cw_897%2Climit_0)

# 操作系统

## 操作系统基础

### 什么是操作系统

- 操作系统OS，是管理计算机硬件和软件的程序
- 操作系统本质上是一个运行在计算机的软件程序。
- 操作系统屏蔽了底层硬件层的复杂性
- Kernel(内核)是操作系统的核心，它负责系统的内存管理，硬件管理，文件系统管理以及软件程序管理

### 操作系统的主要功能

- 主要有6大功能：
  - **进程和线程的管理**：进程的创建、撤销、阻塞、唤醒，进程间的通信
  - **存储管理**：内存的分配和管理，外存(磁盘)的分配和管理等
  - **文件管理**：文件的读、写、创建和删除操作等
  - **设备管理**：完成设备（输入，输出设备和外部存储设备）的请求或释放，以及设备启动等功能
  - **网络管理**：负责管理计算机网络配置、连接、通信和安全，提供可靠的网络服务
  - **安全认证**：用户的身份认证、访问控制、文件加密

### 用户态和内核态

- 用户态(User Mode)：用户运行的进程可以直接读取用户程序的数据，但是权限较低，想要去读取磁盘信息，进行IO流操作，网络通信等操作，就需要向操作系统发起系统调用，进入内核态
- 内核态(Kernel Mode)：内核运行的进程几乎可以访问计算机的任何资源，包括内存空间，设备，驱动等，有很高的权限。当操作系统收到进程的系统调用时，就会从用户态转换到内核态，进行系统调用，将结果返回给用户，再回到内核态
- 内核态有很高的权限，不过用户态切换到内核态的操作需要较高的开销，还是应该尽量减少进入内核态的次数

#### 为什么要有内核态呢？

- CPU指令中，有些指令是比较危险的指令，比如内存分配、设置时钟、IO处理等，如果所有程序都有权限使用这些指令，就比较灾难了，所以要限制这些指令只能在内核态运行。这些指令也叫做**特权指令**
- 如果系统只有一个内核态，那么所有程序和进程必须共享系统资源，会造成系统资源的竞争和冲突，从而影响到系统的效率，并且会降低系统安全性。
- 所以，搞一个用户态就是为了保证系统安全，高效的运行。

#### 用户态和内核态如何进行切换的

- ![用户态切换到内核态的 3 种方式](https://oss.javaguide.cn/github/javaguide/cs-basics/operating-system/the-way-switch-between-user-mode-and-kernel-mode.drawio.png)
- 3种方式：
  - **系统调用(Trap)**：用户进程主动要求切换到内核态，主要是为了操作一些只有内核态才能做的指令，比如IO读取，磁盘操作。系统调用的机制其核心是使用了操作系统为用户特别开放的一个中断来实现
  - **中断(Interrupt)**：当外围设备完成用户请求之后，会向CPU发起一个相应的中断信号，CPU此时会暂停下一条执行的指令，转而去执行与中断信号对于的处理程序，如果先前执行的指令是用户态下的程序，那么就会从用户态转换到内核态，处理外围设备的操作。
  - **异常(Exception)**：当CPU在执行用户态下的程序时，发生了事先不可预知的异常，就会从当前进程切换到处理该异常的内核相关程序中，也从用户态转换到了内核态。

### 系统调用

#### 什么是系统调用

- 我们运行在计算机的程序基本上都是在用户态，如果要去调用操作系统提供的内核态级别的子功能，就需要使用到系统调用了
- 凡是在运行的用户程序中，有与系统级别资源相关的操作（文件管理、进程管理、内存管理等），都必须通过系统调用的方式向系统发起服务请求，然后系统帮我们去完成
- 系统调用按照功能分为：
  - 设备管理：完成设备的请求或释放，或设备启动等功能
  - 文件管理：文件的读写、创建删除
  - 进程管理：进程的创建销毁，阻塞唤醒，进程间通信
  - 内存管理：内存的分配，回收，作业占用内存区大小，地址等功能。
- 系统调用和普通库函数调用很类似，只不过系统调用是由操作系统内核提供，属于内核态，而普通库函数调用由函数库，或用户提供，运行于用户态
- 所以系统调用就是程序于操作系统之间交互的一种方式，通过系统调用，通过系统调用，应用程序可以访问操作系统底层资源

#### 系统调用的过程

- 系统调用可以分为几个步骤
  - 用户态的程序发起系统调用，因为系统调用涉及一些特权指令（只能由操作系统内核态执行的指令），由于用户权限不足，会中断值，也就是`Trap`，Trap其实是一种中断
  - 发生中断后，当前CPU执行的程序会中断，跳转到中断处理程序。内核程序开始运行，处理系统调用
  - 内核处理完成后，主动触发Trap，这样子再次完成中断，切回用户态
- ![系统调用的过程](https://oss.javaguide.cn/github/javaguide/cs-basics/operating-system/system-call-procedure.png)

## 进程和线程

### 什么是进程和线程

- **进程(Process)**：指计算机正在运行的一个程序实例，比如打开的微信就是一个进程
- **线程(Thread)**：也可以称为是轻量级线程，更加轻量。多个线程可以在同一个进程中同时执行。并且共享进程的资源，比如内存空间、文件句柄、网络连接等。比如微信中就有一个专门的线程来拉取别人发的消息。

### 进程和线程的区别是什么？

- 从JVM的角度来说，一个进程中可以有多个线程，多个线程共享进程的堆和方法区资源，但是每个线程有自己的程序计数器（CPU发生线程切换后可以通过计数器知道上次运行到哪里了），虚拟机栈和本地方法栈
- 总结：
  - 线程是进程划分的更小的运行单位，一个进程中可以产生多个线程
  - 线程和进程最大的不同是，基本上进程是隔离的，而各线程不一定，所以同进程中的线程极大概率会互相影响
  - 线程开销小，但是不利于资源的管理和保护、而进程相反

### 有了进程为什么还需要线程

- 进程的切换是一个开销很大的操作，线程的切换成本就较低
- 线程更加轻量，一个线程可以创建多个进程
- 多个线程可以并发处理不同的任务，更有效的利用了多核计算机和CPU，而进程同一时间只能干一件事情，如果执行过程中遇到了阻塞问题，比如IO阻塞， 就会挂起直到结果返回
- 同一进程中的线程共享内存和文件，所以它们之间通信不需要调用内核。

### 为什么要使用多线程

- 从总体来说：
  - 计算机底层：线程是轻量级的进程，程序执行的最小单位，线程间的切换和调度成本是远远小于进程的。而且现在CPU都是多核的，这意味着线程可以同时并行，减少了线程之间的上下文切换
  - 互联网发展趋势：现在都是高并发量的请求，而多线程并发编程就是高并发系统的基础
- 计算机底层
  - 单核时代：单核时代下，多线程主要为了提供单进程利用CPU和IO的效率。假设只允许一个Java进程，当请求IO的时候，如果只有一个线程，那么线程就会被IO阻塞， 整个进程被阻塞，CPU和IO设备只有一个在运行。使用多线程的话，一个线程被IO阻塞， 其他线程还可以继续使用CPU，提高了Java进程整体对系统资源的利用
  - 多核时代：多核时代多线程主要为了提高进程利用多核CPU的能力。假设我们要去计算一个复杂任务，只使用一个线程的话，那么不论有多少个CPU核心，都只有一个核心在被使用。而创建多线程的话，这些线程会被映射到不同的核心上面，效率会显著提升。

### 线程间同步的方式

- 因为线程可能会去访问共享资源，所以要有手段避免这种冲突
- **互斥锁**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以可以保证共享资源不被多线程同时访问。Java中使用`synchronized`关键字（主要是监视器锁的模式），或者各种`Lock`来实现（使用AQS模式，在代码层面上控制线程获取内部资源）
- **读写锁**：允许多个线程同时访问一个资源，但是只有一个线程可以去对资源进行修改。MySQL中大量使用了读写锁机制。
- **信号量**：允许时刻多个线程访问共享资源，但是要控制同一时刻访问的最大线程数
- **屏障**：屏障用于等待多个线程到达某一个点再一起继续执行。当一个线程到达屏障后，会去停止运行等待其他线程到达屏障，直到所有线程都到达屏障后，才一起继续执行
- **事件**：Wait/Notify，通过通知的方式来保持多线程同步。

### PCB是什么

- PCB(Process Control Block)：进程控制块，操作系统用于管理和跟踪进程的数据结构，每个进程有一个独立的PCB
- 当操作系统创建一个进程之后，会为这个进程创建一个独立的进程ID，并且创建一个PCB，当进程执行的时候，PCB中的信息会不断变化，操作系统根据这些信息来管理和调度进程
- PCB主要包含：
  - 进程的描述信息，包括进程的名称，标识符等等
  - 进程的调度信息，包括进程阻塞原因、进程状态（就绪，运行、阻塞）、进程优先级
  - 进程对资源的需求情况，包括CPU时间、内存空间、IO设备等
  - 进程打开文件的信息，包括文件描述符、文件类型、打开模式
  - 处理机的状态信息（由处理机的各种寄存器中的内容组成），包括通用寄存器，指令计数器，程序状态字PSW、用户栈指针等

### 进程有哪几种状态？

- 进程大致分为5种状态：
  - 创建状态(New)：进程正在被创建，还没有到就绪状态
  - 就绪状态(Ready)：进程处于准备运行的状态，即进程获得了除了处理器之外的一切资源，一旦得到处理器的资源（处理器的时间片），就可以开始运行
  - 运行状态(Running)：进程正在处理器进行运行(单核CPU下任意时刻只有一个进程处于运行状态)
  - 阻塞状态(Waiting)：或称为等待状态，进程正在等待某个事件而暂停了，比如等待某个资源可用，或者等待IO操作完成。即使处理器空闲，因为没有等到事件，所以也不会允许
  - 结束状态(Terminated)：进程正从系统种消失。可能是进程正常退出，或者其他原因中断退出运行
  - ![进程状态图转换图](https://oss.javaguide.cn/github/javaguide/cs-basics/operating-system/state-transition-of-process.png)

### 进程间的通信方式有哪些？

#### 进程通信的概念

- 每个进程有自己的用户地址空间，任何进程的全局变量在另一个进程都看不到，所以进程交换数据必须通过内核，在内核中开辟一个缓冲区，把进程1数据从用户空间拷贝到内核缓冲区，进程2再从缓冲区取走，这种机制就是进程间通信(IPC, InterProcess Communication)

#### 进程通信的7中方式

##### 传统UNIX通信机制

###### 管道/匿名管道(pipe)

- 管道是半双工的，数据只能向一个方向流动；如果需要双方通信，就得建立两个管道
- 只能用于父子进程/兄弟进程（具有血缘关系的进程）
- 单独构成一种独立的文件系统：管道对于管道两端的进程来说，就是一个文件，但不是普通的文件，不属于某种文件系统，而是单独构成一个文件系统，只能存在于内存中
- 数据读写：一个进程向管道中写的内容被管道另一边的进程读出。写入的内容添加到管道缓冲区末尾，每次从缓冲区头部读取数据
- ![img](https://upload-images.jianshu.io/upload_images/1281379-05378521a7b41af4.png?imageMogr2/auto-orient/strip|imageView2/2/w/228/format/webp)

###### 管道的实质

- 管道其实就是一个内核缓冲区，进程以先进先出的顺序从缓冲区存取数据，管道一端的进程顺序写入数据，另一端顺序读取数据
- 一个数据只能读取一次，读取出来以后缓冲区就没有这个数据了
- 缓冲区如果空，或满，都需要控制两端进程（生产者，消费者模式）

###### 管道的局限

- 只能支持单向数据流
- 只能用于有血缘关系的进程
- 没有名字
- 管道的缓冲区有限（因为是在内存中创建，创建时会分配一个页面大小）
- 管道传输的是无格式字节流，所以读写双方需要约定好数据格式

###### 有名管道(FIFO)

- 匿名管道Pipe，由于没有名字，就只能用于血缘关系的进程进行通信，为了克服这个，提出了有名管道
- 有名管道和匿名管道的不同之处在于，有名管道提供了一个路径名于其关联，**以有名管道的文件形式存在于文件系统当中**，这样，即使有名管道双方的进程不具有血缘关系，只要访问该路径，就可以彼此通信了。所以，有名管道存在于文件系统中，内容放在内存中

###### 总结

- 管道都是一个先进先出的结构，不能进行定位读写
- 匿名管道是单向的，只能在有血缘关系的进程之间通信，而有名管道以磁盘文件的方式存在于文件系统中，可以实现任意两个进程的通信
- 无名管道阻塞问题：
  - 无名管道无需显示的打开，创建时直接返回文件描述符（读端的文件描述符和写端的文件描述符），在读写时需要确定对方的存在，否则就退出。如果当前进程向匿名管道写数据，必须确定另一端有进程。如果写入匿名管道的数据超过最大值，就会阻塞。如果管道中没有数据，读操作将阻塞。如果管道那个发现另一端断开，将自动退出
  - Linux中，`|`其实就是一个匿名管道
- 有名管道的阻塞问题：
  - 有名管道打开时需要确实对方的存在，否则就阻塞，也就是读操作在打开有名管道的时候，必须之前有进程已经写操作打开了管道，否则就会阻塞（其实也是生产者消费者的模式，如果管道空，那么读操作阻塞，如果管道满，那么写操作阻塞）。但是，可以使用读写模式打开有名管道，当前进程读，当前进程写，不会阻塞
  - Linux中，使用`mkfifo mypipe`创建一个有名管道（其实创建了一个文件，这个文件就是有名管道）
  - 可以对管道进行写入：`echo "Hello, FIFO" > mypipe`，对管道进行读取`cat < mypipe`

##### 信号(Signal)

- 信号是Linux系统用于进程间通信的一种机制，信号可以在任何时候发给某个进程，不需要知道该进程的状态
- 如果该进程不处于运行状态，那么信号会被内核保存起来，直到该进程恢复执行并传递给他为止
- 如果一个信号被进程设置为阻塞，该信号的传递被延迟，直到其阻塞被取消时才传递给进程。
- ![image-20240310210011634](C:\Users\62488\AppData\Roaming\Typora\typora-user-images\image-20240310210011634.png)

###### 信号来源

- 信号是软件层次对中断机制的一种模拟，是一种异步通信方式，信号可以在内核和用户进程直接通信，内核可以利用信号来通知用户空间的进程发生了什么系统事件，信号的来源主要两种
  - 硬件来源：比如`Ctrl + C`退出、硬件异常如无效的存储访问等
  - 软件终止：终止进程信号、其他进程调用kill函数、软件异常产生的异常

###### 信号生命周期和处理流程

- 信号被某个进程产生，并设置该信号的传递对象(进程的对于PID)，然后传递给操作系统
- 操作系统根据接收进程的设置(是否阻塞)，选择性的发送给接收者，如果接收者阻塞该信号（且该信号是可以阻塞的），操作系统将暂时保留该信号，不传递，直到该进程解除了对信号的阻塞（如果对于进程已经退出，则丢弃该信号），如果接收进程没有阻塞，那么就传递给它
- 目的进程收到信号后，将根据当前进程对此信号设置的预处理方式，暂时终止当前代码的执行，保护上下文（临时寄存器数据，当前程序位置以及CPU状态），转而执行中断服务程序，执行完成后，恢复到中断的位置。
- ![img](https://upload-images.jianshu.io/upload_images/1281379-3eed8cca67aa9f55.png?imageMogr2/auto-orient/strip|imageView2/2/w/889/format/webp)

###### 信号和中断的区别

- 中断：
  - 中断主要是硬件产生的，用于通知CPU需要立刻处理某些事件，例如，当硬盘完成数据读取数据之后，会发送中断信号给CPU，CPU中断当前的操作来处理这个事件
  - 中断主要工作在硬件和操作系统底层，是操作系统于硬件交互的基本机制
  - 中断由CPU直接处理，操作系统为每个中断定义了一个中断处理程序(Interrupt Service Routine ISR)
- 信号：
  - 信号是操作系统用来通知进程某个事件已经发生的机制，信号可以由用户发送，也可以由其他进程发送，还可以由操作系统自身生成
  - 信号工作在操作系统和进程的层面，是一种IPC形式
  - 信号处理比较灵活，可以去忽略信号(除了SIGKILL和SIGTERM，这个会默认终止进程，SIGSTOP会默认暂停进程)，也可以捕捉处理信号（可以注册一个信号处理函数，特定信号到达后进行处理）。
- 所以主要区别在于：
  - 来源：中断主要来自于硬件，而信号主要是进程间的通信
  - 处理层次：中断直接涉及CPU和硬件的交互，处理过程对于操作系统和应用程序是透明的。而信号是操作系统内部的进程通信，处理逻辑由进程决定
  - 目的：中断是为了实现CPU和硬件的交互，确保硬件事件可以及时处理。而信号是为了进程之间的通信，操作系统对进程的控制，比如异常处理、进程间通信等。

##### 消息队列

- 消息队列是存放在内核中的消息链表，每个消息队列由队列标识符表示
- 与管道(匿名管道：只存在内存中。有名管道：存在于实质磁盘介质或文件系统)不同的是，消息队列存放在内核中，只有内核重启（操作系统重启）或者显示地删除消息队列，消息队列才会真正地删除
- 与管道不同的是，消息队列可以进行异步写入，即消息队列在某个进程写入消息之前，不需要有其他进程在消息队列上等待。

###### 总结

- 消息队列是消息地链表，具有特定地格式，存放在内存中，由消息队列表示符标识
- 消息队列允许一个或多个进程向它写入与读取消息
- 管道和消息队列都是先进先出的结构
- 消息队列可以实现消息的随机查询，不一定要以先进先出的次序读取，也可以按照类型读取，比FIFO更有优势
- 消息队列克服了信号成载量少，管道只能承载无格式字节流

##### 共享内存

- 多个进程可以直接读写同一块空间，效率非常之高，是最快的IPC形式
- 为了多个进程交换信息，内核专门流出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接对这一块内存进行读写，而不需要进行数据的拷贝操作，大大提升效率
- 由于多个进程访问同一块空间，需要使用同步机制（比如信号量）来达成进程间的同步
- ![img](https://upload-images.jianshu.io/upload_images/1281379-adfde0d80334c1f8.png?imageMogr2/auto-orient/strip|imageView2/2/w/538/format/webp)

##### 信号量

- 信号量是一个计数器，用于多进程对共享数据的访问，目的在于进程间的同步
- 为了获得一个共享变量，进程需要执行以下操作：
  - 创建一个信号量：需要调用者指定初始值，对于二值信号来说，一般为1，也可以是0
  - 等待一个信号量：会去测试信号量的值，如果小于0，就阻塞，也称为P操作
  - 挂出一个信号量：该操作将信号量的值 + 1，也称为V操作
- 为了正确的实现信号量的加减，它的操作应该是原子性的，所以通常由内核中实现。Linux下有三种类型：
  - Posix（可移植操作系统接口）有名信号量（使用 Posix IPC名字标识）、Posix基于内存的信号量（存放在共享内存中）、System V信号量（在内核中维护）。这三种信号量都可以做到进程间或者线程间的同步

###### 信号量与普通整数的区别

- 信号量是非负整型变量，除了初始化之外，只能通过原子操作：wait和singal来访问
- 操作也称为PV原语（P来自荷兰语proberen “测试”， V来自荷兰语verhogen “增加”）

###### 信号量和互斥量的区别

- 互斥量用于线程的互斥，信号量用于线程的同步
  - 互斥：某个资源同一时间只允许一个访问者访问，具有唯一性和排他性
  - 同步：在互斥的基础上，通过其他机制完成访问者对资源的有序访问
- 互斥量只能为二值，也就是0/1，因为一个互斥量只能用于一个资源的互斥访问。而信号量可以实现多个同类资源的多线程访问，也可以设置为二值，达到互斥的效果

##### 套接字(Socket)

- Socket是一种通信机制，通过这种机制，客户端/服务端系统的开发工作既可以在本地进行，也可以跨网络进行。
- Socket是支持TCP/IP的网络通信的基本操作单元，可以看作是不同主机之间进程进行双向通信的端点，通信双方的一种约定

###### 套接字特性

- 套接字特性有三个属性决定：域，端口，协议类型
  - 域：指套接字通信中使用的网络介质，最常见的有两种
    - AF_INET，指的是Internet网络。当客户端使用套接字进行跨网络连接时，就需要用到服务端计算机的IP地址和端口指定目标主机的特定服务，所以在使用Socket作为通信的终点时，服务端应用程序必须在通信开始之前先绑定监听一个端口，等待客户端的连接
    - AF_UNIX：表示UNIX文件系统，就是文件输入/输出，地址就是文件名
  - 端口号：
    - 每个TCP/IP网络通讯的进程都有唯一的端口和端口号，端口是一个消息缓冲区，用于保存Socket中的输入和输出信息，端口号是一个16位无符号位，范围是0 - 65535，用来区分主机的每个程序，低于256的端口号保留给标准应用程序，每一个套接字都组合了IP地址、端口这样的四元组，可以区分套接字。
  - 套接字的协议类型：
    - 因特网提供了三种通信类型：
      - 流套接字：流套接字在域中可以通过TCP/IP连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供了可靠、有序、双向字节流的连接。也就是TCP的特性，超时重传，数据序号保证不乱徐
      - 数据报套接字：不需要建立TCP/IP连接，而是使用UDP/IP协议实现，具有UDP的特性
      - 原始套接字：允许对较为底层的协议直接访问，比如IP，ICMP协议，常用于校验新的协议实现，或者访问现有服务中配置的新设备。对网络底层的传输机制可以进行控制

###### 原始套接字和标准套接字的区别

- 原始套接字可以读写内核中没有处理的IP包，而流套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数。因此，如果访问其他协议发送的数据就必须使用原始套接字。

### 进程的调度算法

- 一共五种调度算法，调度算法是为了确定首先执行哪个进程以及最后执行哪个进程可以实现最大的CPU利用率

  - **先到先服务调度算法（FCFS，First Come， First Served）**：从就绪队列中选择一个最先进入该队列的进程，为它分配资源，使它立即执行直到完成或发生事件而被阻塞放弃占用CPU，再重新调度

  - **短作业优先调度算法（SJF， Shortest Job First）**：从就绪队列中选择一个估计运行时间最短的进程为止分配资源，使它立即执行直到完成或发生事件而被阻塞放弃CPU，再重新调度

  - **时间片轮转调度（RR，Round-Robin）**：时间片轮转调度是最简单的一种调度算法，每个进程被分配了一个时间段，称为时间片，当进程的时间片用完，就要切换到其他进程进行运行

  - **多级反馈队列调度算法（MFQ，Multi-Level FeedBack Queue）：**前面几种进程调度算法都没有很好的兼顾短进程和长进程，比如**先到先服务算法**对于长进程比较友好，而如果短进程前面有大量长进程，那么就要等待很久。**短作业优先算法**对于短作业很友好，但是如果长进程前面有太多短进程，那么长进程就一直执行不到。

    - 多级：表示有多个队列，每个队列优先级从高到低，时间片从短到长（优先级越高的队列时间片越短）
    - 反馈：如果有新的进程进入到了优先级高的队列，立即停止当前运行的进程，转而运行优先级高的队列
    - 如何工作的？
      - 设置了多个队列，每个队列有不同的优先级，每个队列的优先级由高到低，时间片由短到长
      - 新的进程会被加入到第一级队列的末尾，按照先到先服务的原则排队等待调度，如果在第一级队列规定的时间片还没运行完毕，那就会转入到第二级队列末尾，依次类推
      - 当较高优先级队列为空时，才会调度较低优先级的队列中的进程，如果进程运行时，有新进程进入到了较高优先级的队列，那么就停止当前运行的进程，将其转入到原队列末尾，接着让较高优先级队列的进程先运行
    - 可以发现，短作业进入第一级队列后可以很快的处理完毕。长作业一开始放入第一级队列，但是规定时间片肯定完不成，就会放到后续的队列中，虽然等待时间可能较长，但是在后续队列中，运行的时间片也长。所以兼顾了长短作业，同时也有较好的响应时间。

  - **高响应比优先调度算法(Highest Response Ratio Next, HRRN)：**高响应比优先调度算法也是一种兼顾长短作业的算法，在每次调度时，先计算响应优先比，然后把响应优先比最高的进程投入运行：

    - $$
      优先权 = \frac{等待时间 + 要求服务时间}{要求服务时间}
      $$

    - 可以看到，对于短作业来说，如果等待时间相同，短作业的要求服务时间会短，所有响应比高

    - 对于长作业来说，因为等待时间较长，要求服务时间相同，响应比就较高，这要就兼顾了长作业运行，因为响应比会随着等待时间增大而增大。

  - **优先级调度算法(Priority)**：为每一个进程分配优先级，首先执行具有最高优先级的进程，以此类推。如果有相同优先级，那么就以FCFS方式。


### 什么是僵尸进程和孤儿进程

- 在Linux/Unix系统中，子进程通常使用`fork()`系统调用去创建。这个调用会创建一个新进程，这个进程是原进程的一个副本。子进程和父进程的运行是相互独立的，各自都有自己的PCB，即使父进程结束了，子进程也可以继续运行
- 当进程调用`exit()`系统调用结束自己的生命，内存会释放该进程的所有资源，包括打开的文件、占用的内存等，但是该进程对应的PCB还存在于系统中，这些信息只有在父进程调用`wait()`或`waitpid()`系统调用时才会被释放，以便让父进程得到子进程的运行状态
- 这样子设计主要就是为了父进程在子进程结束的时候可以得到子进程的运行状态，并且避免出现`僵尸进程`(即子进程结束后，PCB任然存在但父进程无法得到状态信息的情况)
  - **僵尸进程**：子进程已经终止，但是父进程还在运行，且父进程没有去调用`wait()`或`waitpid()`等系统调用来获取子进程的信息，释放子进程占用的资源，导致子进程的PCB一直存在与系统中，但无法被进一步使用。这种情况下，子进程被称为僵尸进程。为了避免僵尸进程产生，父进程需要及时去调用`wait()`或`waitpid()`系统调用来回收子进程
  - **孤儿进程**：一个进程的父进程已经结束了，但子进程还在运行，这种情况下，子进程就是孤儿进程。孤儿进程通常是由于父进程意外终止或没有及时调用`wait()`或`waitpid()`来回收子进程导致。为了避免孤儿进程占用系统资源，操作系统会将孤儿进程的父进程设置为init进程（进程号为1），由init进程来回收子进程。

## 死锁

### 什么是死锁

- 死锁就是，多个线程/进程同时阻塞，它们中的一个或全部都在等待某个资源释放。由于进程/线程无限期的阻塞，所以程序不可能正常终止

### 举个例子

- 假设有两个进程A和B，以及两个资源X，Y

- | 进程 | 占用资源 | 需求资源 |
  | ---- | -------- | -------- |
  | A    | X        | Y        |
  | B    | Y        | X        |

- 此时，进程 A 占用资源 X 并且请求资源 Y，而进程B占有资源Y并且请求资源X。两个资源都在等待对方释放资源，无法执行，陷入死锁

### 产生死锁的四个条件是什么？

- **互斥**：资源必须处于非共享状态，即一次只有一个进程可以使用，如果另一个进程申请该资源，必须等待
- **占有并等待**：一个进程至少应该占有一个资源，并等待另一个资源，而该资源被其他进程所占有
- **非抢占**：资源不能被抢占，只能持有资源的进程结束以后才能释放
- **循环等待**：有一组等待进程`{P0, P1, P2,...}`，`P0`等待的资源被`P1`占有，`P1`占有的资源被`P2`占有。。。`Pn - 1`的资源被`Pn`占有，`Pn`的资源被`P0`占有。
- 这四个条件就是死锁的必要条件，也就是说，系统发生死锁，就是由于以上条件成立了，那只要以上条件有一个不满足，就不会发生死锁。

### 解决死锁的方法

- 解决死锁的方法主要有四种
  - **预防**：采用某种策略，限制并发进程对资源的请求，从而使得产生死锁的条件在系统执行的任何事件上都不成立
  - **避免**：在系统分配资源的时候，根据资源的使用情况，提前做出预测，避免死锁发生
  - **检测**：使用专门的工具去检测死锁的发生，并且指出死锁的进程和资源。在Java中，可以使用`JConsole`或`JStack`去查看是否有死锁产生，以及对应的线程
  - **解除**：将进程从死锁状态下解除

#### 预防死锁

- 破坏死锁的四种必要条件，就可以做到预防死锁的发生
- 可以破坏第一个 **互斥条件**：使得资源是可以被同时访问的，这是很简单的做法，但是大部分情况下资源往往是不能同时被访问的
- 破坏第三种 **非抢占**：可以使用**剥夺式调度算法**，但是剥夺是调度算法目前一般使用主资源和处理器资源的分配（其实其实上面所说的**时间片轮转**，**优先级调度**, **高响应比**, **短作业优先**, **多级反馈算法**等调度算法，都是用于处理器资源分配给进程的情况），不适用于所有的资源
- 所以一般考虑破坏第二种和第四种条件
- 破坏占有并等待之 **静态分配策略**：
  - 静态分配策略指的是进程在执行前，必须获取到所有它所需要的资源，并且知道它所有资源都得到满足后才执行。进程要么占有所有资源然后开始执行，要不然不占有资源，不会出现占有一些资源，等待一些资源的情况
  - 静态分配策略逻辑很简单，实现也很容易，但是**严重地降低了资源利用率**，因为每个进程需要的资源里，有些资源可能是很靠后的时间段才会使用，有些资源甚至是额外的情况下才会去使用，如果把这些几乎不用的资源提前占有好，那其他进程就需要等待这些资源很长的时间
- 破坏循环等待之**层次分配策略**：
  - 在层次分配策略下，所有资源都分成了多个层次，一个进程得到一个资源后，它只能去申请更高一层的资源；当一个进程需要释放一个资源的时候，必须先去释放更高层的资源。这种策略下，就不会出现循环等待的情况。因为那样子会出现已经申请了较高层的资源，反而去申请较低层的资源，不符合层次分配策略。
  - 比如两个资源在不同的层，一个进程有第一层的资源，它可以去请求第二层的资源，而另一个进程假设拥有第二层的资源，它不可能去请求第一层的资源，因为不符合层次分配了，第二个进程如果也要这两个资源，它只能先去申请第一层的资源。

#### 死锁避免

- 预防死锁确实可行，但是会造成低效的进程，和资源利用率。而死锁避免则允许系统中存在四个条件，不过在进行分配资源的时候，做出明智的选择，避免死锁的发生。
- 我们将系统分为**安全状态**和**不安全状态**，每当在为申请者分配资源之前，先测试一下系统状态，如果发现分配给申请者会产生死锁，就拒绝分配，否则接收分配。
  - 如果操作系统能够保证所有的进程在有限的时间内得到所有资源，则称系统处于安全状态，否则说系统是不安全的。
- 如果保证系统保持在安全状态呢？银行家算法
- 银行家算法可以改善资源使用率低的问题，但是它得不断地去检测各种请求资源是否安全，所以也比较耗时

##### 银行家算法

- 银行家算法其实很简单：当一个进程申请资源时候，银行家算法先试探分配该资源给该资源，然后通过安全性算法判断分配后的系统是否处于安全状态，如果不安全就不可以申请。
- ![这里写图片描述](https://img-blog.csdn.net/20180508204335770?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDE0Mjcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
- ![这里写图片描述](https://img-blog.csdn.net/20180508210408944)
  - 是否安全呢？我们现在有各个资源 1 6 2 2，发现可以分配给P0，那么将他的资源回收
  - 现在拥有 1 6 5 4，发现可以分配给P3，那么将它资源回收
  - 现在拥有 1 9 8 6, 发现可以分配 P1或P4，所以都可以，这边将资源分配给P1
  - 现在拥有2 9 8 6，可以分配给P2或P4，这里分配给P2
  - 现在拥有3 12 13 10，最后分配给P4
- 那假设P2想申请1 2 2 2，可以给他申请吗？
  - 那我们看看现在资源够不够它申请，发现 1 6 2 2是够的，那就假定先给它
  - 现在资源是0 4 0 0，发现谁都满足不了了，那就说明此时系统是不安全的，所以不能分配给P2

#### 死锁的检测

- 对资源的分配进行限制，可以做到预防和避免死锁的发生，但是不利于资源的充分共享。解决死锁的另一途径是死锁的检测和解除
  - 有点像乐观锁和悲观锁的模式。死锁的检测和解除就像乐观锁，分配时不管会不会发生死锁，真的出现死锁再解决就好了
  - 而预防和避免就像悲观锁，总觉得死锁会出现，所以提前解决
- 检测的话，不对资源分配进行限制，但系统会定时去检测是否有死锁发生，如果有，再去解决它

#####  进程-资源分配图

- 操作系统中的每一时刻的系统状态都可以使用**进程-资源分配图**来表示，这是一个有向图，描述了进程和资源的分配关系
- ![进程-资源分配图](https://oss.javaguide.cn/github/javaguide/cs-basics/operating-system/process-resource-allocation-diagram.jpg)
- 2-21就发生了死锁，因为所有进程都在等待资源被释放，而资源又被其他进程所拥有
- 2-22就不会发生死锁，虽然有环路，但是P2和P4在结束之后就会释放R1和R2，那么P3和P1就可以去完成任务

##### 死锁检测步骤

- 知道以上原理，我们就可以去编写死锁检测的程序
  - 如果进程-资源图没有环路，那么就没有发生死锁
  - 如果进程-资源图有环路，且每个资源类只有一个资源，那么系统就发生了死锁
  - 如果进程-资源图有环路，但是设计的资源类有多个资源，系统不一定发生死锁。如果可以在进程-资源图中找到即不阻塞又非独立的进程，这个进程可以在有限时间内归还资源，那么就会把这条边擦除，重复这个过程，直到可以在有限的时间内将边所有擦除，则不会发生死锁，否则认为发生了死锁

#### 死锁的解除

- 当系统检测到发生了死锁，应该要去让他解除，这里有四种方式
  - **立即结束所有进程执行，然后重启操作系统**：这种方式简单，但是以前的工作全部作废
  - **撤销涉及死锁的所有进程，解除死锁后运行**：这种方式可以打破死锁的循环等待，但是付出的代价也很大，比如某个进程运算了很长时间，结果撤销了，那么就得重新计算
  - **逐个撤销涉及死锁的进程，回收其资源直至死锁消除**
  - **抢占资源**：从涉及死锁的一个或几个进程中抢占资源，把剥夺的资源分配给涉及死锁的进程直至死锁解除。

## 内存管理

### 内存管理主要做什么？

- 操作系统的内存管理十分重要，主要负责：
  - 内存的分配和回收：对进程所需的内存进行分配和释放，`malloc`函数：申请内存，`free`函数，释放内存
  - 地址转换：将程序中的虚拟地址转换成内存中的物理地址
  - 内存扩充：当系统没有足够内存时，利用虚拟内存技术或自动覆盖技术从逻辑上扩充内存
  - 内存映射：将一个文件直接映射到进程的进程空间中，这样可以通过内存指针读写内存的方法直接存取文件内容，速度更快
  - 内存优化：通过调整内存分配策略和回收算法来优化内存使用效率
  - 内存安全：保证进程之间的使用内存互不干扰，避免恶意程序通过修改内存来破坏系统安全

### 什么是内存碎片

- 内存碎片是由内存的申请和释放产生的，通常分为两种
  - 内部内存碎片(Internal Memory Fragmentation，简称内存碎片)：已经分配给进程使用，但未被使用的内存。导致内存碎片的主要原因是，采用固定的比例例如2的幂次方去进行内存分片。进程此时分配到的内存可能比需要的要大，比如进程只需要65字节的内存，但为其分配了128字节，剩下的63字节内存就是内部内存碎片
- 外部内存碎片（External Memory Fragmentation，简称外部碎片）：由于未分配的连续内存区域太小，导致无法满足任何进程的内存分配请求，这小小片段且不连续的内存空间被称为外部碎片。也就是说，外部碎片指的是那些没有分配给任何进程，但是也无法使用的内存
- ![内存碎片](https://oss.javaguide.cn/github/javaguide/cs-basics/operating-system/internal-and-external-fragmentation.png)

### 常见的内存管理方式

- 内存碎片会导致内存利用率下降，如何管理是很重要的
- 简单分为两种：
  - 连续内存管理：为一个用户程序分配一个连续的内存空间，内存利用率一般不高
  - 非连续内存管理：允许一个程序使用的内存分布在离散或者不相邻的内存中，相对灵活一些

#### 连续内存管理

- 块式管理：早期操作系统的一种连续内存管理，存在严重的内存碎片问题。块式管理是将内存分为固定大小的块，，每个块中只包含一个进程。如果程序需要内存的话，操作系统就分给它一块，但是如果程序只需要很小的空间，那么一大块的内存就会被浪费掉，这些分配好的内存，但是没有被进程利用到，就是内部内存碎片。除了内部内存碎片之外，外部的内存块之前也可能存在外部碎片，这些不连续内存块之间的碎片由于太小也无法被利用到
- 在Linux系统中，连续内存管理使用**伙伴系统算法**来实现，可以有效解决外部内存碎片的问题。伙伴系统的原理是将内存按2的幂次方分配，并将相邻的内存块组成一对伙伴（相邻指的是地址也是相邻的）。当进行内存分配时，伙伴系统会尝试找到大小最合适的内存块，如果找到的内存块比较大（比如分配10K内存，理应找到2^4 16K的块进行分配，但是假设此时16K的块都不空闲，那么就只能去找2^5 32K的块进行分配了，依次类推），那么就需要将其一分为2，直到到达合适大小。最后，分配给进程一块，剩余的块拼接到各个对应的链表中。
- 假设两个相邻的内存块都被释放了，那么就将他们拼接称为一个更大的内存块，以便后续的内存分配。
- 伙伴系统解决了外部碎片的问题，但是还是会有内部内存碎片的存在，比如需要65K大小的内存，还是只能分配给其128K大小的内存块，这样子浪费了63K内存
- 对于内部内存碎片问题，Linux采用SLAB进行解决。

#### 非连续内存管理

- 在非连续内存管理之前，先来看看什么是虚拟内存

##### 虚拟内存

- 操作系统为每个进程分配独立的一套虚拟内存，人人都有，进程使用自己的地址就可以了，互不干涉，至于具体怎么映射到物理地址，进程是透明的，由操作系统来安排，操作系统会提供一种机制将虚拟地址和不同的物理地址映射起来。
- 如果程序要访问虚拟地址，由操作系统转换成不同的物理地址，这样子让不同的进程运行的时候，写入的是不同的物理地址，就不冲突了
- 于是就有两种概念：
  - 程序所使用的内存地址叫做：虚拟内存地址（Virtual Memory Address）
  - 实际存在硬件上的空间地址叫：物理内存地址（Physical Memory Address）
- 虚拟地址会通过CPU芯片中的内存管理单位(MMU)的映射关系，来转换成物理地址，然后通过物理地址访问内存![img](https://cdn.xiaolincoding.com//mysql/other/72ab76ba697e470b8ceb14d5fc5688d9.png)

##### 内存分段

- 程序是由多个逻辑分段组成的，比如由代码分段、数据分段、栈段、堆段组成。不同的段有不同的属性，所以就用分段的形式将这些段分离出来

###### 分段机制下。虚拟地址和物理地址如何映射

- 分段机制下，虚拟地址由两个部分组成：段选择因子和段内偏移量
- ![img](https://cdn.xiaolincoding.com//mysql/other/a9ed979e2ed8414f9828767592aadc21.png)
  - **段选择因子**：保存在段寄存器中。段选择因子里面最重要的是短段号，作为段表的索引，段表里面保存的是这个段的基地址、段的界限和特权等级等
  - **段内偏移量**：应该位于0和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理地址内存
- 例子：
  - ![img](https://cdn.xiaolincoding.com//mysql/other/c5e2ab63e6ee4c8db575f3c7c9c85962.png)
  - 如果要访问段1中偏移量为260的地址，那么就直接计算出物理地址，段2的基地址 + 偏移量： 6260
- 分段很好的解决了程序本身不需要关系物理地址内存问题，但是也有一些缺点：
  - 会有内存碎片的问题
  - 内存交换的效率低

###### 为什么会有内存碎片问题

- ![img](https://cdn.xiaolincoding.com//mysql/other/6142bc3c917e4a6298bdb62936e0d332.png)
- 一开始打开了游戏，浏览器和音乐，然后关闭了浏览器，内存释放，但是此时空间不足以打开一个内存需求200MB的程序了。

###### 内存分段的内存碎片问题

- 分段不会出现内部内存碎片问题，因为是可以段根据实际需求去分配内存的，有多少需求就去分多少内存，所以不会出现内部内存碎片
- 但是因为每个段长度不固定，所以多个段未必可以很好的利用所有的空间，就比如以上例子，就算来一个64MB的程序，但是中间的小碎片还是无法利用到，所以会出现外部内存碎片问题
- 如何解决呢？使用内存交换
  - 可以将音乐程序的内存先写到磁盘上，然后再读回到内存中，不过读回来的时候，需要贴着已被占有的512MB后面，这样子两个128MB就可以连续起来形成一个256MB的空间，新的程序就可以运行了
  - 内存交换空间，在Linux系统中，是SWAP空间，这个空间是硬盘划出来专门用于内存和磁盘空间交换的

###### 为什么内存交换效率低

- 多进程环境下， 使用分段的方式，外部内存碎片不可避免，那就要频繁的使用Swap去进行内存交换，但是磁盘的访问速度比内存要慢很多很多
- 所以如果交换的是一个占内存空间很大的程序，就会导致整个机器都显得卡顿。
- 为了解决外部内存碎片和内存交换效率低的问题，出现了内存分页

##### 内存分页

- 内存分段的好处就是可以产生连续的内存空间，但会出现外部内存碎片太大和内存交换空间太大的问题，那如何减少外部内存碎片太大呢，然后如何减少内存交换空间的大小呢？这个办法就是内存分页
- **分页是整个虚拟和物理内存空间切成一段段固定尺寸的大小**，这样一个连续并且尺寸固定的内存空间我们叫做页，在Linux下，每个页大小为4KB
- 虚拟地址和物理地址由页表来映射![img](https://cdn.xiaolincoding.com//mysql/other/08a8e315fedc4a858060db5cb4a654af.png)
- 页表是存储在内存中的，内存管理单元（MMU）就做将内存地址转换为物理地址的工作
- 当进程访问的虚拟地址在页表中查询不到的时候，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后返回用户空间，恢复进程的运行

###### 分页如何解决分段的外部内存碎片和内存交换效率低问题

- 由于内存分页中的内存空间都是预先划分好的，所以页和页之间也就不会出现间隙，所以不会有外部内存碎片
- 但是因为最小的单位是一页，所以页内会出现内存浪费，所以内存分页机制会出现内部内存碎片的现象
- 如果内存空间不足，操作系统会将其他正在运行的进程中`最近没被使用`的内存页面释放掉，也就是暂时写到磁盘上，称为换出，一旦需要的时候，再加载进来，称为换入。一次性写入磁盘的只有少数的一个页或者几个页，所以内存交换效率较高。
- 分页的方式可以让我们在加载程序的时候，不需要一次性的把程序加载到物理内存中，可以先进行虚拟内存和物理内存的页之间映射之后，不真的把页加载到物理内存中，只需要在程序运行的时候，将需要用到的虚拟内存页里面的指令和数据加载到物理内存

###### 分页机制，虚拟内存和物理内存如何映射

- 和分段机制类似（段号 + 段内偏移量）。分页机制下，虚拟地址分为两个部分，页号和页内偏移量。页号为页表的索引，页表包含了物理页中每页所在的物理内存基地址，这个基地址 + 偏移量就组合了物理内存地址![img](https://cdn.xiaolincoding.com//mysql/other/7884f4d8db4949f7a5bb4bbd0f452609.png)
- 对于一个内存地址转换：
  - 把虚拟内存地址切分成页面和偏移量
  - 根据页号，从页表里面查找到物理页号
  - 直接拿物理页号，和前面的偏移量，就得到了物理内存地址
- ![img](https://cdn.xiaolincoding.com//mysql/other/8f187878c809414ca2486b0b71e8880e.png)

###### 简单的分页有什么缺陷吗

- 空间上有权限，因为操作系统是可以同时运行多个进程的，意味着页表会非常庞大
- 32位环境下，虚拟地址空间有4GB，假设一个页大小为4KB(2 ^ 12)，那么需要100万(2 ^ 20)个页，每个页表项需要4个字节大小来存储，那么就需要4 * 2 ^ 20 也就是4MB来存储
- 这个只是一个页表哦，每个进程都有自己的虚拟空间，所以每个进程都会维护一个页表，那假设有100个进程，就有400MB的内存来维护页表了，更不用说在64位环境下

###### 多级页表

- 单页表的实现前面看到了，会占用4MB的内存，不过，当我们去推广到一个多级页表，就可以解决这个问题
- 我们现在考虑二级页表，也就是每个一级页表项中间，包含1024个二级页表项，一共1024个一级页表项。2^10 * 2 ^ 10 = 2 ^ 20，没问题
- ![img](https://cdn.xiaolincoding.com//mysql/other/19296e249b2240c29f9c52be70f611d5.png)
- 那为什么这样子可以解决呢？
- 计算机组成原理中的局部性原理起作用了，因为我们不会为一个进程分配那么多的空间，大多数程序不可能占满虚拟地址空间，所以大部分的页表项都是空的，我们只要分配真正存在的页表项不就好了。
- 一级页表已经可以覆盖整个4G的虚拟空间了，如果某个一级页表项没有被用到，那么就不需要创建这个页表项所对应的二级页表。比如只有20%的一级页表项被用到，整个空间为 4KB(一级页表的空间) + 20% * 4MB（二级页表的空间）= 0.804MB。
- 如果我们只有一个页表，因为虚拟空间必须得找到一个映射，所以页表必须包含所有虚拟地址空间，不分级的话就得有100万个页表项，分级以后只需要1024个页表项。
- 对于64位系统，那2级分表也不够用了，64位意味着有 2 ^ 52个页，就算二级分页，一级也得2 ^ 26，太大了，所以实际上会分四级
  - 全局页目录项 PGD（*Page Global Directory*）；
  - 上层页目录项 PUD（*Page Upper Directory*）；
  - 中间页目录项 PMD（*Page Middle Directory*）；
  - 页表项 PTE（*Page Table Entry*）；
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%9B%9B%E7%BA%A7%E5%88%86%E9%A1%B5.png)

###### TLB

- 多级分页出现以后，虽然解决了占用内存大的问题，但是现在想要找到一个物理地址，得需要层层翻译转换，为了提高这个转换效率，操作系统引入了转地旁路缓存(Translation Lookaside Buffer)，也称为快表
- TLB属于MMU(Memory Management Unit，内存管理单元)内部的单元，本质上就是一个高速缓存(Cache)，缓存了虚拟页号到物理页号的映射关系，其实可以看作就是存储虚拟页号和物理页号的哈希表
- 翻译流程：
  - 用虚拟地址中的虚拟页号作为key去TLB查询
  - 如果查到物理页了，就不需要查询页表了，这叫做TLB命中
  - 如果查不到对应物理页，那就需要去查询主存中的页表，同时将页表中的该映射表项添加到TLB中，这叫做TLB未命中
  - 当TLB填满之后，又要登记新页时，就需要按照一定策略淘汰快表中的一个页

###### 什么是页缺失

> 页缺失（Page Fault，又名硬错误、硬中断、分页错误、寻页缺失、缺页中断、页故障等）指的是当软件试图访问已映射在虚拟地址空间中，但是目前并未被加载在物理内存中的一个分页时，由 MMU 所发出的中断。

- 常见的页缺失有：
  - **硬性页缺失(Hard Page Fault)**：物理内存中没有对应的物理页，于是，Page Fault Handler会指示CPU从已经打开的磁盘文件中读取相应的内容到物理内存，而后交给MMU来建立相应的虚拟页和物理页的映射关系
  - **软性页缺失(Soft page Fault)**：物理内存中有对应的物理页，但虚拟页还没和物理页建立映射，于是Page Fault Handler会指示MMU建立相应虚拟也和物理页的映射关系
- 这两种缺页错误，指的是应用程序访问的是有效的物理内存，只是出现了物理内存页缺失或者虚拟也和物理页映射关系未建立的问题。如果进程访问的是无效的物理内存，那就会出现**无效缺页错误（Invalid Page Fault）**

###### 常见的页面置换算法有什么？

- 当发生硬性页面缺失的时候，如果物理内存中没有空闲的物理页面可用的话，操作系统就必须将物理内存中的一个物理页淘汰出去，这样就可以腾出空间加载新页面了
- 选择淘汰哪一个物理页的规则就叫做**页面置换算法**，
- 页缺失如果发生的太频繁就会非常影响性能(因为要频繁从磁盘中换取页面)，一个好的页面置换算法可以减少页缺失出现的次数
- 常见的有5种：
  - **最佳页面置换算法（OPT，Optimal）**：优先选择淘汰的页面是以后永不使用的，或者最长时间内不再访问的页面，这样可以保证最低的缺页率。但是人们现在无法预知进程再内存下若干页面中哪个是未来不会被访问的，所以这个无法被实现，只是理论上最优的页面置换算法
  - **先进先出页面置换算法（FIFO）**：最简单的页面置换算法，总是淘汰优先进入内存的页面，即选择在内存中驻留最久的页面进行淘汰。该算法很容易实现和理解，只需要一个队列即可实现，但是性能不好
  - **最近最久未使用页面置换算法（LRU）**：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，当要淘汰一个页面的时候，选择现有页面T值最大的，即最近最久未使用的页面，LRU是根据各页之前的访问情况来实现，可以实现。OPT是根据未来访问情况来实现的，所以不可实现
  - **最少使用页面置换算法（LFU）**：和LRU算法很像，不过选择的是前一段时间最少使用的页面作为淘汰页。
  - **时钟页面置换算法（Clock）**：可以认为是一种最近未使用算法，逐出的页面都是最近没有使用的

###### 为什么FIFO性能不好

- 主要两个原因：
  - 经常访问的页或者长期需要存在的页会被频繁的调入调出：较早调入的页往往是需要经常访问的，如果使用FIFO，这些页会被调出去，然后又调回来。
  - 存在Belady现象：Belady现象是是随着分配给进程的物理内存页面增加，发生缺页中断的次数反而增加。使用FIFO的话，被置换的页面并不是进程不会访问的，因为FIFO只考虑了页面进入内存的顺序，并没有考虑页面使用的频率。



##### 段页式内存管理

- 内存分段和内存分页并不是对立的，它们可以组合起来使用，称为段页式内存管理。
- 段页式内存管理实现方式：
  - 将程序划分为多个有逻辑意义的段
  - 接着把段分为多个页，也就是将分段划出来的连续空间，再划分为固定的页
- 地址结构为段号、段内页号、页内位移三个部分组成
- ![img](https://cdn.xiaolincoding.com//mysql/other/8904fb89ae0c49c4b0f2f7b5a0a7b099.png)

## 文件系统

### 文件系统基本组成

- Linux文件系统会为每个文件分配两个数据结构：索引节点(Index node)和目录项(Directory Entry)。主要用来记录文件的元信息和目录层次结构
  - **索引节点**：也就是`inode`，用来记录文件的元信息，比如inode编号，文件大小、访问权限、创建时间、修改时间、**数据在磁盘的位置**等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会存储在磁盘中，所以索引节点同样占用磁盘空间
  - **目录项**：也就是`dentry`，用来记录文件的名字、**索引节点指针**以及其他目录项的层次关联关系。多个目录项关联起来，就会形成目录结构，但与索引节点不同的是，目录项是内核维护的一个数据结构，不存放在磁盘中，缓存在内存中
- 索引节点和文件一一对应，目录项则记录着文件的名字，所以目录项和索引节点的关系是多对一，一个文件可以有多个别名。
- 目录也是文件，也有索引节点对应，不过普通文件在磁盘中保存的是文件数据，而目录保存的是子目录和文件

#### 目录项和目录？

- 不是一个东西，目录是文件，而目录项是内核的一个数据结构，缓存在内存中
- 如果查询目录频繁从磁盘中读，那么效率很低，所以内核把已经读过的目录用目录项这个数据结构缓存在内存中，下次再读到相同的目录时，只需要从内存读就可以了，大大提高文件系统的效率
- 目录项这个数据结构也是可以表示文件的，不仅仅标识目录

#### 文件数据如何存储在磁盘呢？

- 磁盘读写的最小单位是**扇区**，扇区的大小只有`512B`，如果每次都读这么小为单位，那么效率会很低
- 所以文件系统把多个扇区组成一个**逻辑块**，每次读写的最小单位就是逻辑块。Linux中阿逻辑块大小为`4KB`，也就是一次性读取8个扇区，大大提高读写的效率
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%9B%AE%E5%BD%95%E9%A1%B9%E5%92%8C%E7%B4%A2%E5%BC%95%E5%85%B3%E7%B3%BB%E5%9B%BE.png)
- 索引节点是存储在硬盘上的数据，为了加速文件的访问，会把索引节点加载到内存中
- 另外，磁盘进行格式化的时候，会被分成三个存储区域，分别是**超级块**，**索引节点区**和**数据块区**
  - **超级块**：用来存储文件系统的详细信息，比如块个数、块大小、空闲块等
  - **索引节点区**：用来存储索引节点
  - **数据块区**：用来存储文件或目录数据
- 我们不可能把超级快和索引节点区全部加载到内存中，这样内存撑不住，所以只有在需要的时候，才会将其加载内存
  - 超级快：当文件系统挂载时进入内存
  - 索引节点区：当文件被访问同时进入内存

### 虚拟文件系统

- 文件系统的种类众多，而操作系统希望对**用户提供一个统一的接口**，于是在用户层和文件系统层引入了一个中间层，这个中间层称为**虚拟文件系统**（Virtual File System，VFS）
- VFS定义了一组所有文件系统都支持的数据结构和标准接口，程序员就不需要了解文件系统的工作原理，只要知道VFS提供的统一接口就行了
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png)
- Linux支持的文件系统不少，根据存储位置的不同，可以把文件系统分为三类：
  - **磁盘的文件系统**：直接存储在磁盘中的数据，比如Ext 2/3/4，XFS都是这类文件系统
  - **内存的文件系统**：这类文件系统数据不是存储在磁盘中的，而是占用内存空间，比如`/proc`和`/sys`都属于这一类。
  - **网络的文件系统**：用来访问其他计算机主机的文件系统，比如NFS，SMB等
- 文件系统得先挂载到某个目录才可以使用，比如Linux系统在启动的时，会把文件系统挂载到根目录

### 文件的使用

- 如何去使用文件呢？首先得通过系统调用去打开一个文件

- ![write 的过程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%86%99%E5%88%B0%E7%A3%81%E7%9B%98%E8%BF%87%E7%A8%8B.png)

- ```c
  fd = open(name, flag); # 打开文件
  ...
  write(fd,...);         # 写数据
  ...
  close(fd);             # 关闭文件
  ```

  - 首先使用`open`系统调用打开文件，参数包含文件的路径名和文件名
  - 然后使用`write`去写数据，其中`write`使用`open`返回的文件描述符，并不使用文件名作为参数
  - 使用完文件以后，使用`close`系统调用关闭文件，避免资源的泄漏

- 打开一个文件以后，操作系统会去跟踪进程打开的所有文件，所谓跟踪就是操作系统会去维护一个打开文件表，文件表里的每一项代表 **文件描述符**，所以说文件描述符是打开文件的标识

- ![打开文件表](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E6%89%93%E5%BC%80%E8%A1%A8.png)

- 操作系统在**打开文件表**中维护着打开文件的状态和信息

  - **文件指针**：系统跟踪上次读写位置作为当前文件位置的指针，这种指针对于打开文件的某个进程是唯一的
  - **文件打开计数器**：文件关闭时，操作系统必须重用其打开文件表条目，否则表的空间不够用了。因为多个进程可能打开同一个文件，所以系统在删除文件条目之前，得确保所有进程都关闭了这个文件，这个计数器跟踪打开和关闭的数量，当计数为0时，系统关闭文件，删除该条目
  - **文件磁盘位置**：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都需要从磁盘中读取
  - **访问权限**：每个进程打开文件都有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统可以允许或拒绝之后的I/O请求

- 用户看来，文件就是一个持久化的数据结构，而操作系统不关心磁盘上的任何数据结构，它只想把文件数据和磁盘块对应起来

- 所以，用户和操作系统对文件的读写操作是有差异的，用户以字节方式读取文件，而操作系统是以数据块来读写文件。

- 读文件和写文件的过程：

  - 当用户进程从文件读取1个字节大小的数据时，文件系统需要获取字节所在的数据块，再返回数据块对应用户进程的数据部分
  - 当用户进程需要写入一个字节大小的数据时，文件系统则需要找到写入数据的数据块位置，然后修改数据块中对应的部分，最后把数据块写回磁盘。

### 文件的存储

- 文件的数据是要存储在硬盘上面，数据在磁盘上的存储方式，就像数据在内存中存储的方式一样，有两种：
  - 连续空间存放方式
  - 非连续空间存放方式
- 其中，非连续空间存放方式又可以分为 **链表方式**和 **索引方式**

#### 连续空间存放方式

- 连续空间顾名思义，**文件存放在磁盘连续的物理空间中**。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件
- 使用连续空间存放的方式得知道文件的大小，这样文件系统才会根据文件的大小在磁盘中找一块连续的空间分配给文件
- 所以，**文件头里需要指定 起始块位置 和 长度**，有这两个信息就可以很好的表示文件存放是一块连续的磁盘空间。
- 连续空间存放的方式虽然读写效率高，但是 **磁盘空间碎片** 和 **文件长度不易扩展** 是缺陷
- ![磁盘碎片](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F-%E7%A3%81%E7%9B%98%E7%A2%8E%E7%89%87.png)
- 另一个问题就是文件长度扩展不方便，比如上面文件A想要扩展一下，需要更多的磁盘空间，只能去挪动其余文件将空闲块放在一起，但是在硬盘中移动文件的效率是很低的
- 如何解决呢？就像在连续内存分配一样，可以使用非连续空间存放方式

#### 非连续空间存放方式

- 非连续空间存放方式分为 链表方式 和 索引方式

##### 链表方式

- 链表的方式存放是 **离散的，不用连续的**，所以可以消除磁盘碎片，可以大大提高磁盘的使用率，同时 **文件的长度可以动态扩展**。根据实现的方式的不同，链表可以分为 **隐式链表**和 **显示链表**
- 文件如果要使用 **隐式链表**的方式存放的话，**实现的方式是文件头要包含 第一块 和 最后一块 的位置，并且每个数据块里面流出一个指针空间，用来存放下一个数据块的位置**，这样子一个数据块连着一个数据块，从链头开始就可以顺着指针找到所有数据块，所以存放的方式可以是不连续的
- ![隐式链表](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F-%E9%93%BE%E8%A1%A8%E6%96%B9%E5%BC%8F.png)
- 隐式链表存放方式的缺陷就在于，**无法直接访问某个数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间**。隐式链表分配的 **稳定性较差**，系统在运行过程中由于软件或者硬件错误 **导致链表中指针丢失或损坏，会导致文件数据丢失**。
- 如果取出每个数据块的指针，将他们存放在内存中的一个表里，就可以解决隐式链表的两个不足。这种实现方式就是 **显示链接**，它指 **把用于链接文件各数据块的指针，显示地存放在内存的一张链接表中**，该表在整个磁盘仅设置一张，**每个表项存放链接指针，指向下一个数据块号**。
- ![显式链接](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E5%88%86%E9%85%8D%E8%A1%A8.png)
- 以上这个例子，文件A依次使用了数据块 4、7、2、10、12，文件B依次使用了 6、3、11、14。使用上表，可以从第四块开始，顺着链表走到最后，找到A文件的所有数据块，对于B也是一样。最后两个链都以一个不属于有效磁盘编号特殊标记（-1）结束。内存中这样的一个表称为文件分配表**（File Allocation Table FAT）**
- 由于查找记录的过程都是在内存中进行的，所以检索速度非常快，而且大大减少了访问磁盘的次数。但是也是因为表在内存中存储，所以不适用于大磁盘
- 假设我们有一个200GB的磁盘和1KB大小的块，那么这张表就得有2亿项，每一项对应于这2亿个磁盘块的一个块，每项如果需要4个字节，那么总共就是800MB的内存，显然FAT对大磁盘不太适合

##### 索引的方式

- 链表的方式解决了磁盘碎片和文件动态扩展的问题，但不支持有效的直接访问（FAT除外），索引可以解决这个问题
- 索引的实现是为每个文件创建一块 **索引数据块**，里面存放的是 **指向文件数据块的指针列表**。
- 另外，**文件头需要包含指向 索引数据块指针**，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块
- 创建文件时，索引块的所有指针都设为空，当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目
- ![索引的方式](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F-%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F.png)
- 索引的方式优点在于：
  - 文件的创建、增大、缩小很方便
  - 不会有碎片的问题
  - 支持顺序读写和随机读写
- 由于索引数据也是存放在磁盘块中的，所以如果文件很小，明明一块就可以放下了，却还是要分配额外的一个索引块来存放索引数据，这就是缺陷之一：存储索引带来的消耗
- 如果文件很大，一个索引块都存储不完索引信息，如果出来大文件的存放呢？可以通过组合的方式来处理
- 链表 + 索引的组合，这种组合称为 **链式索引块**，实现方式是在索引块中留出一个存放下一个索引块的指针，也就是当一个索引块用完了，可以使用指针的方式读取下一个索引块的信息。当然，会出现前面链式存放的问题，如果某个指针损坏， 后面的数据就无法读取了![链式索引块](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%93%BE%E5%BC%8F%E7%B4%A2%E5%BC%95%E5%9D%97.png)
- 还有一种方式是 索引 + 索引的方式，这种组合称为 **多级索引块**，实现方式是 **通过一个索引块来存放多个索引块**，一层套一层索引![多级索引块](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%9D%97.png)

#### UNIX文件的实现方式

- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83.png)
- 早期UNIX文件系统是组合了前面的文件存放方式的优点：![早期 Unix 文件系统](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/Unix%20%E5%A4%9A%E7%BA%A7%E7%B4%A2%E5%BC%95.png)
- 根据文件的大小，存放的方式有变化：
  - 小于等于10个数据块：采用直接查找的方式
  - 超过10个数据块，采用一级间接索引方式
  - 如果前面两种方式都不够存放大文件，采用二级间接索引方式
  - 如果二级间接索引也不够存放大文件，采用三级间接索引方式
- 所以，文件头(Inode)就需要包含13个指针
  - 10个指向数据块的直接指针
  - 第11个指向索引块的一级间接指针
  - 第12个指向二级索引块的二级间接指针
  - 第13个指向三级索引块的三级间接指针
- 对于小文件来说，使用直接查找的方式，可以减少索引数据块带来的开销
- 对于大文件来说，使用多级索引的方式来支持，访问时需要大量的查询

### 空闲空间管理

- 如果保存一个数据块，应该放在硬盘中的哪个位置呢？难道要扫描硬盘的所有位置吗？
- 常见的方式有：
  - 空闲表法
  - 空闲链表法
  - 位图法

#### 空闲表法

- 空闲表就是为所有空闲空间建立一张表，表的内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的
- ![空闲表法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A9%BA%E9%97%B2%E8%A1%A8%E6%B3%95.png)
- 当请求分配磁盘空间时，系统依次扫描空闲表的内容，直到找到一个合适空闲区域位置。当用户撤销一个文件时，系统回收文件空间，此时也需要扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。
- 这个方式对于少量的空闲区域来说有比较好的效果，如果存储空间中有大量的小空闲区，那么空闲表就会变得很大，效率就很低。

#### 空闲链表法

- 也可以使用链表的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样可以很方便的找到空闲块并管理
- ![空闲链表法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A9%BA%E9%97%B2%E5%9D%97%E9%93%BE%E8%A1%A8.png)
- 当创建文件需要一块或几块时，就从链头中依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上
- 这种技术只要在主存中保存一个指针，令他指向第一个空闲块。但是不能做到随机访问，工作效率低，每次增加或者移动空闲块时都要做很多的I/O操作，同时数据块的指针消耗了一定的存储空间
- 空闲表法和空闲链表法都不适用于大型文件系统。会使得空闲表或空闲链表过大

#### 位图法

- 位图是使用二进制的一位来表示一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应

- 当值为0是，表示空闲，当值为1，表示已分配

- ```
  1111110011111110001110110111111100111 ...
  ```

- Linux文件系统就采用位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于inode空闲块的管理。因为inode也是存储在磁盘

### 文件系统的结构

- 用户在创建一个新文件时，Linux内核会通过inode的位图找到空闲可用的inode，并进行分配。要存储数据时，会通过块的位图找到空闲的块，然后分配。
- 数据块的位图是存放在磁盘里的，假设是放在一个块里，一个块4KB，每位表示一个数据块，共可以表示 `4 * 1024 * 8 = 2^15`个空闲块，由于一个数据块是4KB，那么最大的可表示空间为 `2^15 * 4 * 1024 = 2 ^ 27 B`，也就是128MB
- 也就是说，按照这个结构，采用 [一个块位图 + 一系列的块]，外加 [一个块的inode的位图 + 一些列的inode的结构]，能表示的最大空间也就128MB，这太少了。
- 在Linux文件系统，把这个结构称为一个块组，那么有N多的块组，就能表示N大的文件
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%9D%97%E7%BB%84.png)
- 最前面的是引导块，在系统启动时用于启动引导，接着后面就是一个一个的块组，块组的内容为：
  - **超级块**：包含的是文件系统的重要信息，比如inode的总个数、块总个数、每个块组的inode个数、每个块组的块个数
  - **块组描述符**：包含文件系统各个块组的状态，比如块组中空闲块和inode的数目等，每个块组都包含了文件系统中 [所有块组的组描述符信息]
  - **数据位图和inode位图**：用于表示对于的数据块或inode是空闲的，还是被使用的
  - **inode列表**：包含了块组中所有的inode，inode用于保存文件系统中各个文件和目录相关的所有元数据
  - **数据块**：包含文件的有用数据。
- 为啥每个块组都包含了重复信息？比如 **超级块和块组描述表**，这两个都是全局信息，而且非常重要
  - 如果系统崩溃破坏了超级块或块组描述符，有关文件系统和内容的所有信息都会丢失。如果有冗余的副本，这个信息就可以恢复
  - 通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，可以提高文件系统的性能
- Ext2后续版本采用了稀疏技术。做法是。超级块和块组描述表不再存储到文件系统的每个块组中，而是只写入到块组0，1和其他ID可以表示为3，5，7的幂的块组中。

### 目录的存储

- 前面都是说的普通文件的存储，对于目录来说，它如何保存呢？
- Linux的思想是一切皆文件的思想，所以目录其实也是一个文件，它也有inode，inode指向了一些块
- 和普通文件不同的是，**普通文件的块保存的是文件数据，而目录的块保存的是目录里面一项项的文件信息**
- 目录文件的块中，最简单的保存格式就是 **列表**，就是一项项的将目录下的文件信息（如文件名、文件inode、文件类型）列在表里
- 列表中每一项就代表该目录下的文件的文件名和对于的inode，通过这个inode就可以找到真正的文件
- ![目录格式哈希表](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%9B%AE%E5%BD%95%E5%93%88%E5%B8%8C%E8%A1%A8.png)
- 不过，如果一个目录有超级多的文件，想要在这个目录下找文件，就得一项项的找，效率太低了
- 所以保存目录的格式改为了哈希表，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，通过对名字进行哈希，如果能够匹配，就可以找到这个文件信息在相应的块里

### 软链接和硬链接

- 有时候我们希望给某个文件取别名，那么在Linux中就可以通过 **硬链接（Hard Link）**和 **软连接（Symbolic Link）**的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的
- 硬链接是 **多个目录项中的 索引节点 指向同一个文件**，也就是指向同一个inode，但是inode是不可能跨越文件系统的，每个文件系统都有各自的inode数据结构和列表，所以 **硬链接是不可用于跨文件系统的**。由于多个目录项都是指向同一个inode，那么 **只有删除文件的所有硬链接以及源文件时**，系统才会彻底删除该文件。
- ![硬链接](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A1%AC%E9%93%BE%E6%8E%A5-2.png)
- 而软链接相当于重新创建一个文件，这个文件有**独立的inode**，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，相当于访问到另外一个文件，所以 **软链接是可以跨文件系统的**，甚至 **目标文件被删除了，链接文件还是在的，只不过找不到指向的文件**。![软链接](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E8%BD%AF%E9%93%BE%E6%8E%A5.png)

### 文件I/O

- 文件的I/O分类特别多，常见的有：
  - 缓冲与非缓冲I/O
  - 直接与非直接I/O
  - 阻塞与非阻塞I/O VS 同步与异步I/O

#### 缓冲与非缓冲I/O

- 文件操作的标准库是可以实现数据的缓存，那么 **根据 是否利用标准库缓冲， 可以把文件I/O分为缓冲I/O和非缓冲I/O**
  - 缓冲I/O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过调用系统调用访问文件。
  - 非缓冲I/O，直接通过系统调用访问文件，不经过标准库缓冲。
- 这里的缓冲特指标准库内部实现的缓冲
- 很多程序遇到换行时才真正的输出，而换行前的内容实际上是被标准库暂时缓存了起来，这样做的目的就是为了减少系统调用的次数，系统调用是有CPU上下文切换的开销。

#### 直接与非直接I/O

- 磁盘I/O是非常慢的，所以Linux内核为了减少磁盘的I/O次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间就是 页缓存，只有当缓存满足某些条件时候，才发起磁盘I/O请求
- 那么， **根据 是否利用操作系统的缓存，可以把文件I/O分为直接I/O与非直接I/O**
  - 直接I/O，不会发生内核缓冲和用户程序之间的数据复制，而是直接经过文件系统访问磁盘
  - 非直接I/O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入磁盘
- 如果在使用文件操作类的系统调用函数时，指定了 `O_DIRECT`表示，则表示使用直接I/O

##### 如果使用了非直接I/O进行写数据操作，内核什么时候会把缓存数据写入到磁盘

- 有几种场景：
  - 在调用 `write`的最后，当发现内核缓存的数据太多时，就会把数据写到磁盘
  - 用户主动调用 `fsync`，内核缓存会刷到磁盘
  - 内存十分紧张时，无法再分配页面时，也会把内核缓存的数据刷到磁盘
  - 内核缓存的数据的缓存时间超过某个时间，也会把数据刷到磁盘上

#### 阻塞IO与非阻塞IO VS同步与异步IO

- 先看看阻塞IO，当用户程序执行 `read`，线程会被阻塞，一直到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，`read`才会返回。
- 注意，**阻塞等待的是 内核数据准备好 和 数据从内核态拷贝到用户态 这两个过程**
- ![阻塞 I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%98%BB%E5%A1%9E%20I_O.png)
- 非阻塞IO呢？非阻塞的 `read`请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，`read`调用才可以获取到结果：
- ![非阻塞 I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E9%98%BB%E5%A1%9E%20I_O%20.png)
- 注意，**最后一次read调用，获取数据的过程，是一个同步过程，需要等待。这里的同步指的是内核态的数据拷贝到用户程序的缓冲区这个过程**
- 应用程序每次都去轮询内核的IO是否准备好，其实是在浪费资源，大部分循环其实没有意义
- 所以为了解决这个傻乎乎的轮询方式，IO多路复用技术出来了，如select、poll和epoll，它们是通过IO事件分发，当内核数据准备好了，再以事件通知应用程序进行操作
- 这样子大大提高了CPU的利用率，因为当调用IO多路复用接口，如果没有事件发生，那么当前线程就会发生阻塞，这时CPU可以去切换到其他线程执行任务，等内核发现有事件到来，会去唤醒阻塞待IO多路复用接口的线程，然后用户就可以去执行后续的处理了
- 整个流出会比阻塞IO复杂，但是 **多路复用IO最大的优点就在于，用户可以在一个线程内同时处理多个Socket的IO请求**。用户可以注册多个Socket，然后不断调用IO多路复用接口读取被激活的Socket，即可以达到在同一个线程内同时处理多个IO请求的目的。而在同步阻塞模型中，必须配合多线程的方式才可以达到这个目的。
- ![I/O 多路复用](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%9F%BA%E4%BA%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%20I_O%20%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png)
- 无论是阻塞IO，非阻塞IO还是多路复用IO，实际上都是 **同步调用，因为它们在read调用时，内核将数据从内核空间拷贝到用户空间，过程都需要等待，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read调用就会在这个同步过程中等待比较长的时间。**
- 真正的 **异步IO**是 内核数据准备好 和 内核数据拷贝到用户空间 这两个过程都不需要等待
- 当发现 `aio_read`之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成
- ![异步 I/O](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%BC%82%E6%AD%A5%20I_O.png)
- 

# 计算机网络 

## TCP/IP网络模型

- 应用层：
  - 应用层是最上层，主要面对的是数据之间的一些协议，HTTP，SMTP，FTP等协议。
- 传输层：
  - 传输层有两个协议，UDP和TCP，这两个协议是为了数据的传输而产生了。
  - 他会为数据加上一个数据头和端口等信息，用于接收的解析，同时如果数据包过大，超过了TCP最大报文长度，就会进行分块。
- 网络层：
  - 网络层是真正发送数据的地方，主要的协议就是IP协议。组装好的IP报文如果超过了MTU，最大传输单位，也会再次进行分片。
  - IPv4在源头和路由器进行分片
  - IPv6只在源头进行分片，通过邻居发现请求找出整个路径最小的MTU，然后进行分片
  - IP地址被分为了网络段和主机号，网络段用于区分不同的子网，主机号用于区分子网下的设备
  - 因为传统的Class分区会造成主机号段浪费的情况，所以后续使用MASK子网掩码去更加精确的分离网络段和主机段
- 网络接口层：
  - 这是最底层的层级，这里是底层局域网通过设备MAC地址真正找到设备所在的位置。数据在这里以Frame发送，加上了帧头和帧尾。

## 当我们输入网址到网页显示会发生什么

- 首先浏览器会去解析URL
  - URL由协议，域名以及域名下的文件目录组成，通过这个形式就可以找到想要访问的主机下的资源了
  - 解析完毕就会去封装成一个HTTP请求，发送请求了。
    - 数据封装到请求体当中
- 然后会根据DNS协议找到域名真正的IP地址
  - 如果本地的DNS没有缓存，则去顶级DNS根服务器寻找，然后逐级往下
  - ![域名解析的工作流程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/6.jpg)
- 获取IP以后就可以去操作系统的**协议栈**中找对应的协议了发送了。协议栈的格式与TCP/IP网络模型相似，上层会向下层委托工作，比如上面的请求会去找到协议栈中的TCP，然后再找IP，最后找底层物理发送的MAC协议
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/7.jpg)
- 找到TCP协议以后，通过TCP协议去将我们的HTTP数据包封装，加上TCP的头信息，这个头信息包含了：
  - 源端口号和目标端口号，通过端口号可以找到应用
  - 序号：因为数据包可能会被分片，分片之后就可能会造成乱序到达，所以序号用来解决乱序的问题
  - 确认号：这个是用来解决丢包问题。接收到了正确的确认号则说明数据正常到达，如果没有则需要重发
  - 状态位：TCP是有状态的，这些状态位是表示此时TCP连接的状态：`SYN`发送一个连接,`ACK`回复,`RST`重新连接,`FIN`结束连接。
  - 窗口大小：为了保证双方的发送和接收能力均一，通过滑动窗口的方式进行控制
    - 除了流量控制，还要做阻塞控制
- TCP三次握手：
  - 首先客户端先发起连接`SYN`，序号为`client_isn`
  - 然后服务端会返回一个确认号，确认接收到了客户端的连接，并且也会发送一个自己的序号。`ACK Numbern`为`client_isn + 1`，`Seq Number`为`server_isn`
  - 客户端收到确认号和服务端的序号，说明服务端的接收和发送都没问题，但是服务端不知道接收端的接收能力可以不可以，所以此时客户端还得发送一个确认号回去，告诉服务端我这边可以接收，`Ack number`为`server_isn + 1`
- 最终，我们的TCP中的报文部分就会放入数据，当然，如果数据过大，超过了MSS则要进行分片。接着就会通过IP协议走上发送的道路了。
  - MTU：一个网络包的最大长度，以太网中一般是1500字节
  - MSS：为网络包去掉IP头部和TCP头部的数据大小
  - IP协议中有源地址IP和目标地址IP，源地址IP就是客户端的IP，目标地址IP我们通过DNS可以找到，然后就将TCP封装到了IP数据包中的Payload了。
  
- IP头部生成了，但是底层我们还要通过MAC地址才能找到真正的主机，所以得加上一个MAC头部
  - 类似的，这里也有发送方MAC地址和接收方MAC地址，当然，接收方MAC地址可能需要先通过ARP协议获取到，然后才能封装。
  - ARP协议操作很简单，直接广播一条信息到子网下，对应的目标主机进行返回它的MAC地址即可。
- 现在终于准备出发了，首先得去网卡中，将数字信息转换成电信号，通过网线进行发送。
  - 网卡需要网卡驱动程序控制，程序获取到数网络包后，将其复制到网卡的缓存区，然后给网络包开头加上起始帧和包头，末尾加上校验序列
- 数据包会首先发送到交换机上，交换机内部维护了一个MAC地址表，可以找到设备MAC地址和交换机端口的映射，如果找不到就要将网络包转发到所有端口上。
- 然后就走到了路由器了，会在这里被转发到下一个路由器，通过路由表查询转发的目标，然后通过相应的路由端口转发过去。
  - 这里路由器会先检查纠错码，如果没问题的话，看看目标MAC地址是不是给路由器的，是的话就可以丢弃MAC头部了，因为发送给外网的请求统一都是走路由器的，所以MAC地址到路由器就可以丢弃了。
  - 路由器根据IP地址，从路由表查询到转发的目标，找到以后，判断一下网关列是否是个IP地址
    - 如果是的话，说明还要继续转发到这个IP地址，还没有到达终点
    - 如果为空的话，IP头部接收方的IP地址就是要转发的目标地址，说明已经到达终点了。
  - 一样，还需要做一个ARP MAC地址的获取，然后就由交换机到到下一个路由器，层层转发过后就到达了目的地了。
- 最终，服务器就接收到了这个请求，然后将数据包中所有信息进行验证，解析，转发到相应的端口号进程，然后进程进行响应的封装，发送回发送方。发送方接收到以后，也进行验证，解析，转发到进程。这样一个完整的请求响应就完成啦！

## Linux接收网络包的流程

- 当网卡接收到数据以后，通过DMA技术将数据写入到指定内存，`Ring Buffer`，一个环形缓冲区，然后告诉操作系统数据已经到了
- 怎么告诉呢?
  - 一种方式就是直接触发中断，然后CPU就会来处理，但是弊端是如果网络包特别多，那么CPU得频繁的进行中断然后处理网络包，其他任务就会被耽搁了
  - Linux 2.6后引入了`NAPL`机制，混合了中断和轮询的方式接收网络包。核心概念就是不采用中断的方式读取数据，而是先中断唤醒数据接收的服务程序，然后`poll`的方法来轮询数据。
- 当数据包到达的时候，通过DMA写入指定内存地址，然后网卡向CPU发起硬件中断，当CPU收到硬件中断请求之后，就会根据中断表，去调用注册的中断处理函数。
- 这个函数会做以下事情：
  - 先暂时屏蔽中断，告诉网卡收到数据包就直接写入内存，不要通知CPU
  - 接着发起软中断，然后恢复刚刚的屏蔽的中断
- 软中断怎么处理数据呢？
  - 内核中有一个线程`ksoftirqd`接收到软中断以后，就来轮询处理数据，先从`Ring Buffer`获取一个数据帧，然后交给协议栈逐层处理
  - 先进入网络接口层，检查报文的合法性。
  - 然后找出协议类型，看看是IPv4还是IPv6，丢掉帧头和帧尾，然后交给网络层
  - 网络层中，会提取IP包，看看这个网络包是要发出去还是接收，接受的话就看看协议类型是TCP还是UDP，丢弃IP头，交给传输层
  - 传输层取出TCP头或UDP头，根据`源端口号，源IP，目标端口号，目标IP`作为标识，找到对应的Socket，然后将数据放到Socket的接收缓冲区中
  - 最后应用程序就可以调用Socket接口，将Socket缓冲区的数据拷贝到应用程缓冲区，然后就可以唤醒用户线程了。

## Linux发送网络包的流程

- 和接收是反过来的。
- 首先应用程序调用Socket接口发送数据，这是系统调用，所以会从用户态转换到内核态，内核会去申请一个sk_buff内存，将数据拷贝到这个内存，然后加入到发送缓冲区。
- 然后协议栈从Socket发送缓冲区取出sk_buff，按照TCP/IP协议栈从上至下逐层处理。
- 如果使用的是TCP协议，则会去拷贝一个sk_buff副本，因为TCP协议支持重传，而sk_buff再发送完成以后会被释放掉，所以要保留一个副本，等到接收到ACK以后再去释放。
- 接着就去开始填充各个的头部信息，TCP头，IP头，MAC头，帧头。
  - 这个sk_buff结构体可以表示各个层级的数据包，因为其实各个层级的数据包都是一个，我们只是在接收的时候剥离它的头部，在发送的时候添加头部，所以使用一个结构体就可以做到了，如果使用多个结构体，那么在层级进行交互的时候就要频繁的复制拷贝数据，大大降低效率
  - 在填充头部信息的时候，通过减少sk_buff的data指针来添加头部
  - 在剥离头部信息的时候，通过增加sk_buff的data值来剥离头部
  - ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/sk_buff.jpg)
  - 头部信息封装好之后，就会触发软中断告诉网卡驱动程序，这里有数据需要发送，驱动程序就会去队列中读取sk_buff，将sk_buff挂到`Ring Buffer`，接着将sk_buff映射到网卡可访问的内存DMA区域，触发真正的发送。

## HTTP

### HTTP常见状态码

- ![ 五大类 HTTP 状态码 ](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png)
- `1xx`表示提示信息
- `2xx`表示请求成功，常用的有
  - `200 OK`成功状态码，如果不是`HEAD`请求，服务器的响应头会携带body数据。
  - `204 Not Content`，与 200 不同的地方就是服务器的响应头不会携带body数据
  - `206 Partial Content`，表示响应的body数据不是资源的全部，用于断点续传或分块下载
- `3xx`表示重定向信息，通常是资源位置发生了改变，客户端可能需要使用新的URL重新获取数据
  - `301 Moved Permanently`：表示永久重定向，请求资源已经不在了，需要用新的URL来访问
  - `302 Found`：临时重定向，请求资源还在，暂时需要使用另一个URL来访问。
  - 301 和 302在响应头中有一个`Location`字段，告诉浏览器自动跳转到这个新的URL
  - `304 Not Modified`：缓存用字段，表示资源未被修改，客户端可以使用缓存资源。
- `4XX`表示客户端发送的报文有错误
  - `400 Bad Request`：客户端发送的请求数据有问题
  - `403 Forbidden`：服务器禁止访问资源
  - `404 Not found`：服务器没有找到资源，说明资源不存在或者请求路径有问题
- `5XX`表示服务器内部出现错误：
  - `500 Internal Server Error`：服务器内部出现了错误
  - `501 Not Implemented`：表示客户端请求的功能还没实现
  - `502 Bad GateWay`：网关返回的错误码，表示服务器工作正常，但是访问后端服务器发生了错误
  - `503 Service Unavailable`：表示服务器正忙，暂时没空响应客户端。

### Http常用字段

- **Host**：
  - 发送请求的时候指定域名
- **Content-Length**：
  - 服务器返回数据的时候，会有一个`Content-Length`字段，表示回应数据的长度
  - 这个是为了解决TCP粘包/半包问题，HTTP通过设置回车符，作为Header的边界，用`Content-Length`作为body边界
- **Connection**：
  - 为了实现长连接机制的字段。
  - HTTP/1.1版本默认是长连接，老版本的HTTP需要开启长连接
  - `Connection: Keep-Alive`
- **Content-Type**:
  - 服务器回应的时候，告诉客户端此次数据是什么格式
  - 比如：`Content-Type: text/html; Charset=utf-8`，说明返回的是一个网页，编码为UTF-8
  - 客户端可以使用`Accept`表示自己接收什么数据，比如`Accept: */*`表示接收所有格式
- **Content-Encoding**：
  - 表示使用什么压缩格式，服务器返回的数据使用了什么压缩格式
  - 比如:`Content-Encoding: gzip`表示使用了`gzip`。
  - 客户端通过`Accept-Encoding`来指定，比如`Accept-Encoding: gzip, deflate`

### GET和POST

- GET表示从服务器获取某个资源，可以是静态的文本，页面，图片视频。GET的请求参数是写在URL中的，浏览器对URL长度有限制
- POST表示根据请求payload对指定资源做出处理，POST携带的数据写在报文的body中

### GET和POST都是幂等的吗

- HTTP中的安全表示：
  - 不会对服务器的数据进行修改
- HTTP中的幂等表示：
  - 不管请求多少次，结果都是一样的
- 从语义上来看，GET请求就是安全和幂等的，因为GET请求不会修改服务器的数据，它是只读操作
- POST请求就不是安全和幂等的，因为它需要对服务器进行数据修改，多次提交可能会创建多个资源
- 但是这只是从语义上分析，我们也可以使用GET去修改资源，POST去请求资源
- 但是如果我们的安全是指数据安全，那么HTTP中的数据都不是安全的，因为是明文的形式进行传输。

### HTTP的缓存技术

#### HTTP的缓存有什么实现

- 缓存的作用就是提高性能，当我们的请求响应数据是一样的，那我们就可以将这对请求响应放到本地当中，不用通过网络去请求了
- 有两种方式，强制缓存和协商缓存

#### 什么是强制缓存

- 强制缓存表示只要浏览器判断缓存还没有过期，就直接使用本地缓存，决定使用缓存是在客户端这边
- 强制缓存使用的是两个字段来实现的：
  - `Cache-Control`：这是一个相对时间
  - `Expires`：这是一个绝对时间
- 如果两个字段都有的话，`Cache-Control`的优先级高于`Expires`
- `Cache-Control`的具体实现：
  - 当浏览器第一次发起请求的时候，服务器响应的时候会在Response的头部带上一个`Cache-Control`，并设置过期时间的大小
  - 当浏览器第二次请求同样的资源的时候，会先去检查`Cache-Control`，看看是不是过期了，如果没有的话就直接使用缓存，否则重新请求
  - 服务器返回的时候，会再次更新Response的`Cache-Control`

#### 什么是协商缓存

- 我们有时候会看见`304`这个code，这是服务器告诉客户端你可以使用本地缓存
- 当资源过期以后，服务器可以通过协商，看看客户端可不可以使用本地缓存，这个过期的判断也是通过强制缓存的`Cache-Control`字段来实现的，当发现缓存过期，且发现响应头有相应的协商缓存字段，才走协商缓存
- 主要两种方式实现
  - 第一种：使用请求头`If-Modified-Since`和响应头的`Last-Modified`来实现
    - 响应头的`Last-Modified`：表示相关资源最后一次修改的时间
    - `If-Modified-Since`：当资源过期以后，发现响应头具有`Last-Modified`，则会再次发请求的时候带上`Last-Modified`时间，服务器收到请求后发现有`If-Modified-Since`则与被请求资源的最后修改时间进行对比，如果最后修改时间较大，则发送新资源，如果较小，则说明没有修改，响应`304`
  - 第二种：使用请求头的`If-None-Match`和响应头的`ETag`
    - `ETag`：唯一标识响应资源
    - `If-None-Match`：当资源过期以后，发现响应头有`ETag`，则再次向服务器发起请求时，将请求头的`If-None-Match`设置为`ETag`的值，然后服务器就去对比这个标识，如果发现标识没有改变，说明这段时间里资源没有改变，就返回`304`，否则返回新资源
- 可以看到，两种方式都是要依靠一个对比，`If-Modified-Since`和`Last-Modified`是去对比修改时间，`If-None-Match`和`ETag`则是去对比标识符
- 如果两种的字段都有呢？`ETag`优先级会比`Last-Modified`高，如果`ETag`发生变化了，就不用再看`Last-Modified`，如果没有发生变化，再去看看`Last-Modified`
- 原因？
  - 因为有些文件可能并没有修改过，但是修改时间也会改变，这就导致了没有很好的利用到缓存
  - 有些文件可能是在秒级别内修改的，`If-Modified-Since`能检查到的就是秒级，`ETag`的话就可以保证1s内的资源修改也可以检查到
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/http%E7%BC%93%E5%AD%98.png)

### HTTP的特性

- 常见的HTTP版本就三个，HTTP/1.1，HTTP/2.0, HTTP/3.0

#### HTTP/1.1 的优点有哪些？

- **简单**
  - HTTP基本的报文格式就是`header + body`，header就是`key-value`的形式，简单易懂
- **灵活和扩展**
  - HTTP协议里的各个组成都没有固定的要求，我们甚至可以自定义字段
  - 而且，HTTP协议是最高层`应用层`允许的，它的下层是可以随意变化的，HTTP/1.1和HTTP/2.0就是TCP传输协议，而到了HTTP/3.0就是UDP协议了
- 应用广泛和跨平台
  - HTTP的应用非常广泛，各种APP都是用HTTP作为应用层协议，而且本身是应用层协议，并不受限于操作系统的限制

#### HTTP/1.1的缺点

- **无状态**
  - HTTP/1.1是无状态的，服务器不会去记忆HTTP的状态，不需要额外的资源和负担
  - 但是有时候我们会有关联性的操作，比如登录，添加购物车，下车，结算，支付。如果不记录状态，我们得每次去验证身份
  - 所以要使用`Cookie`来记录状态，`Cookie`由服务端生成，记录客户端的身份，然后客户端后续请求携带Cookie
- **明文传输，不安全**
  - HTTP严重的问题就是明文传输，你的内容会裸奔在互联网

####  HTTP/1.1性能

- **长连接**
  - 早期`HTTP/1.0`就是短链接的形式，每次请求响应后都会关闭连接，然后再次开启连接，增加了开销
  - HTTP/1.1提出了长连接，一方没有主动提出断开连接，TCP就会一直保持连接
- **管道网络传输**
  - HTTP/1.1因为使用的是长连接的方式，管道(Pipeline)网络传输就有可能实现。
  - 原来的时候，一个请求发完以后，要等响应回来再发第二个请求，但是现在可以客户端可以发送多个请求，不需要等响应回来
  - 但服务端必须按照接收请求的顺序来发送相应的响应。
    - 实际上 HTTP/1.1 管道化技术不是默认开启，而且浏览器基本都没有支持。
- **对头阻塞**
  - 其实就是上面的问题，当第一个请求发送完以后，如果迟迟没有收到响应，那么第二个请求就发不过去。

#### HTTP与HTTPS

##### 区别

- HTTP信息是明文的，数据在互联网上裸奔，而HTTPS将数据进行了加密，在TCP和HTTP网络层中加上了SSL/TSL安全协议，使数据可以加密发送。
- HTTP默认端口80，HTTPS默认端口443

##### HTTPS解决的问题

- HTTP主要会出现的问题：
  - 窃听：链路上可以获取通信内容
  - 篡改：可以植入垃圾广告
  - 冒充：冒充恶意网站
- HTTPS加入了`SSL/TLS`协议，很好的解决了以上的风险
  - 加密信息：数据无法被窃取
  - 校验：无法篡改通信内容
  - 身份认证：网站是经过认证的网站
- HTTPS如何做到的呢：
  - 混合加密：实现信息的机密性
  - 摘要算法：保证数据的完整性
  - 数字证书：服务器公钥放入到数字证书，解决了冒充的风险。

##### 混合加密

- 混合加密指的是对称加密和非对称加密相结合的方式
  - 通信建立前采用非对称加密交换会话密钥
  - 通信过程中使用对称加密的会话密钥加密明数据
- 因为非对称加密的速度较慢，如果全程采用非对称加密的话效率太低
- 而如果全程使用对称加密的话，因为钥匙只有一把，必须得通过网络传输将密钥给到服务器，那这个过程中有可能被窃据密钥
- 所以先使用非对称加密，把我们对称加密需要的密钥安全的交换以后，再使用对称加密加密我们的数据，这样子就效率也高，也安全
- ![混合加密](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/20-%E6%B7%B7%E5%90%88%E5%8A%A0%E5%AF%86.png)
- 先简单来说，在建立请求的时候，服务器将非对称加密的公钥给客户端，客户端利用这个公钥加密后续的对称加密密钥，发给服务器，服务器通过私钥解密得出对称加密的密钥，然后大家都可以使用对称加密密钥加密数据传递啦！

##### 摘要算法+数字签名

- 现在我们的数据是安全了，不过为了保证内容不要被篡改，要加上一个`指纹`，同内容发给对方。
- 对方收到内容以后，也去计算一下`指纹`，然后对指纹做比较，如果指纹相同，说明内容没有被篡改过，如果不同就说明内容篡改过了。
- 计算机中就是用摘要算法(哈希函数)来计算内容的哈希值，这个哈希值是唯一的，且无法从中推导出任何内容。
- 这样子可以保证内容不被篡改了，但是无法保证[内容+哈希值]不被中间人替换掉。因为缺少了对消息是否来自正确的服务端的证明。
- 所以这里又使用数字签名的方式，来保证消息来自正确的服务器，使用非对称加密
- 上面也提到了非对称加密
  - 可以私钥加密，公钥解密：这种方式用来保证消息不被冒充，私钥不可泄漏，所以如果公钥可以解密，说明内容肯定是私钥的持有者发送的。
  - 也可以公钥加密，私钥解密：这种方式来保证内容的安全，只有私钥拥有者才可以解密数据。
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.png)

##### 数字证书

- ok，现在我们可以确保数据是安全的了，通过混合加密
- 也可确保消息是可靠的了
- 但是还有一个问题，没有身份验证。如果公钥是伪造的公钥呢？
- 如果一对公钥私钥都是伪造的，那就又出现问题了，所以我们需要第三方机构了保证公钥是正规的。服务器会将自己的信息+公钥+数字签名，由第三方机构打包成一个数字证书，然后这个数字证书发送给客户端，客户端通过数字证书中的公钥去解密数字签名。
- 原理就是由一个正规机构CA，来颁发数字证书，只要数字证书可信，那么公钥就可信。
- ![数子证书工作流程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

##### 整个HTTPS的流程

- 首先复习一下上面：
  - 混合加密：
    - 使用非对称加密加密对称加密的密钥，使用对称加密加密信息
  - 摘要算法+数字签名：
    - 保证数据不被篡改，由服务器私钥加密哈希值，客户端获取服务器公钥后解密哈希值然后和自己的算的对比
  - 数字证书：
    - 为了保证公钥不被篡改，使用第三方机构颁发的数字证书，保证公钥是验证过的可靠的，第三方通过私钥来加密服务器的公钥，客户端浏览器已经有CA的公钥了，所以可以解密数字证书中服务器的公钥，然后使用这个公钥去加密对称加密的密钥，发给服务端，服务端通过自己的私钥去解密
- 所以，我们的流程就是：
  - 服务器发送证书给客户端，客户端通过内置的CA公钥解密证书，拿到服务器的公钥，然后使用公钥加密对称加密密钥，发送给服务端，服务端使用自己的私钥解密对称加密密钥，后续就通过这个密钥来进行通信了
- ![HTTPS 连接建立过程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/23-HTTPS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)
- `ClientHello`：
  - 客户端向服务器发送加密请求，`ClientHello`请求，这一步向服务器发送
    - 客户端支持的TLS版本
    - 客户端随机数，这个是用来生成密钥的
    - 客户端支持的密码套件列表，支持什么加密算法
- `ServerHello`：
  - 服务端收到请求以后，向客户端发送响应，也就是`ServerHello`，内容如下：
    - 确认的TLS版本，如果客户端都不支持，直接关闭加密通信
    - 服务端的随机数，用来生成密钥
    - 确认的密码套件，确认好一个加密算法
    - 服务器的数字证书
- `客户端回应`：
  - 客户端收到回应以后，先去操作系统或者浏览器的CA公钥，确认服务器的数字证书是否真实，没问题的话就拿出服务器的公钥，然后用它加密一个报文，内容如下
    - 一个随机数`premaster key`，这个随机数会被服务器公钥加密好
    - 加密算法改变通知，表示后续都将使用会话密钥加密通信
    - 握手结束通知，表示握手阶段结束，这里会将之前的内容做个摘要，由服务器校验。
- 此时，服务器和客户端都有了三个随机数，分别是：客户端随机数，服务器随机数以及`Premaster Key`随机数，由这个随机数，和双方选好的加密算法，生成一个密钥
- `服务器最后回应`：
  - 服务器收到第三个随机数以后，算出会话密钥
  - 然后向客户端回应最后消息：
    - 加密算法改变通知，表示后续都是用会话密钥加密通信
    - 服务器握手结束通知，然后也去生成摘要，告诉客户端来校验
- 最后，双方都可以使用加密好的信息来通信啦，此时使用普通的HTTP协议即可，只不过消息是经过加密的。

##### 客户端校验数字证书

- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png)
- CA将持有者的公钥，用途，颁发者，有效时间等信息打包，然后对信息进行hash计算，得到哈希值，由CA的私钥进行加密这个哈希值，做了签名
- 客户端拿到证书以后，计算Hash，得到一个哈希值，然后由CA的公钥解密签名，比较两个哈希值，如果相同，表示可信赖，如果不同，认为证书不可信赖。
- 这个验证过程中，有一个证书信任链的过程，因为向CA申请的证书一般不是根证书签发的，而是中间证书签发的，下面是百度的例子：
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/baidu%E8%AF%81%E4%B9%A6.png)
- 那客户端首先受到百度的证书以后，发现签发者不是根证书，所以一开始不能直接通过本的根证书公钥去验证，要去找百度证书的签发者`GlobalSign Organization Validation CA - SHA256 - G2`，向CA去请求这个中间证书。
- 请求到以后，发现这个中间证书是由`GlobalSign Root CA`颁发的，而这个上面没有签发机构了，说明`GlobalSign Root CA`就是根证书，软件就会去检查这个证书是否预载了，如果有，就可以拿到根证书的公钥去验证`GlobalSign Organization Validation CA - SHA256 - G2`，通过的话，说明可信赖
- 并且会拿到中间证书的公钥，最后使用这个公钥去验证百度的证书，通过就说明可信赖。
- 为什么要搞这么多链条呢？因为要对根证书进行严格隔离，如果根证书都有问题，那么整条信任链都会有问题。

##### HTTPS一定安全吗(字节面试)

- 场景是，有一个中间基站，他去和客户端建立HTTPS连接，也和服务端建立HTTPS连接，最后，客户端发送的请求由加基站转发给服务端，服务端的响应由假基站转发给客户端。
- 流程就是：
  - 加基站和客户端建立好了连接，也和服务端建立好了连接，客户端发送的请求是给假基站的，加基站解密以后，将数据使用服务端的加密发给服务端
  - 服务端响应以后，假基站进行解密，然后使用客户端的加密，发给客户端
- 这个问题可以产生，但是因为有证书的存在，所以客户端在和假基站建立连接的时候，假基站会伪造证书给客户端，浏览器会警告客户这个证书有问题，如果客户执意要访问的话，才会出现以上问题。
- 同样，如果电脑中毒，导入了假基站的根证书，那么后续所有这个证书下的证书都会被安全验证了，那就出问题了。甚至浏览器都不会弹出警告。
- 当然，因为一般使用的是单认证，服务端是不会去验证客户端的身份，但是可以使用双向验证，使得中间基站无机可乘。

##### RSA算法

- RSA算法就是我们上面提到的过程，服务器有公钥和私钥，然后客户端利用服务器的公钥，发送一个随机数给服务器，服务器使用私钥来解密，最后两边获得同一个对称加密的密钥
- 这个算法的问题在于，当服务器的私钥泄漏以后，原来的所有信息都会被解密了。不具有前向保密

##### DH算法

- DH算法是利用了离散对数的性质，具体公式为

  - $$
    g^i(mod \ p)=B
    $$

  - g是公开的一个数字，i是私钥，B是公钥

  - 这个公式在于，当知道私钥i时，容易得出公钥B值，而只知道公钥B，无法反向推出i值。特别是p是一个大质数的情况下

- 此时，客户端和服务器都可以生成它们的公私钥，然后将公钥交换，比如

  - 客户端：

    
    $$
    g^a (mod \ p) = A
    $$

  - 服务端：
    $$
    g^b(mod \ p)=B
    $$

  - 此时，交换各自的公钥AB，然后再次进行双方计算
    $$
    B^a(mod \ p) = K
    $$

    $$
    A^b(mod \ p) = K
    $$

  - 这样子就计算出来了一个相同的对称密钥，后续使用这个密钥进行加密数据即可。

- DH算法有两种实现：

  - static DH和DHE（DH Ephemeral）

- static DH在于服务端的私钥不变，客户端的私钥随机，但这个可能会被黑客破译出服务端的私钥导致原来的数据全部被破解

- 所以使用DHE，每次客户端和服务器的私钥随机生成，这样子就算真的破译出了一次，其他的通信安全性也不会受到影响

##### ECDHE算法

- DHE算法要大量的计算，所以现在 都采用ECDHE
- ECDHE是利用了椭圆曲线的特性来计算。它不使用传统DH的模幂运算，而是利用了椭圆的点加运算，将基点G和随机私钥相乘，得到一个公钥，这个公钥是椭圆上的离散对数形式，所以由私钥 --> 公钥简单，而公钥 -->私钥很难
- 拿到以后，还是利用椭圆的点加，将对方的公钥与自己的私钥进行相乘，两边获取的结果是一样的，这样就得到了对称加密密钥

##### RSA和ECDHE对比

- 我们知道在RSA中，要使用CA中包含的服务器公钥来加密随机数，但是在ECDHE中，其实证书的作用就是验证服务器的身份了，而不使用服务器这个公钥来进行加密数据
- ECDHE中主要使用双方的随机公私钥来进行交换对称加密密钥。

#### HTTP/1.1 HTTP/2 HTTP/3

#### 演变

##### HTTP/1.1相比HTTP/1.0提高了什么性能

- 改进：

  - 默认使用长连接了，减少短链接的性能消耗

  - 支持管道网络传输，第一个请求出以后，不必等他响应回来，就可以发送第二个请求

- 缺点：
  - 请求/响应头部没有压缩，所以信息越多延迟越大，只能压缩`body`部分
  - 冗长的首部
  - 服务器只能按照请求的顺序来响应，如果一个请求响应太慢，就会导致客户端一直请求不到数据，也就是对头阻塞。
  - 没有请求优先级控制
  - 请求只能从客户端开始，服务器只能进行被动响应

##### HTTP/2的优化

- HTTP/2是基于HTTPS的，所以是安全的协议
- 性能上的优势：
  - 头部压缩
  - 二进制格式
  - 并发传输
  - 服务器主动推送资源。
- **头部压缩**
  - 使用一个`HPACK`算法，客户端和服务端维护了一张头部信息表，所有字段都会存入这个表，生成一个索引号，以后就只发送索引号作为头部即可，压缩了头部信息。
- **二进制格式**
  - 不使用HTTP/1.1中的纯文本形式了，使用二进制的形式，头信息和数据体都是二进制的，统一称为帧：头部信息帧，数据帧
  - 比如状态码200，HTTP/1.1因为是纯文本形式，所以要占3个字节，而HTTP/2中二进制只需要1个字节。
- **并发传输**
  - HTTP/1.1默认关闭了管道传输，所以请求/响应是一个事务，只有这一个事务处理完以后才能接着发送下一个请求，这就会造成对头阻塞
  - HTTP/2中引入了Stream的概念，多个Stream复用一条TCP连接
  - HTTP/2的最小单位为一个Frame，也就是帧，他的头帧和数据帧可以分开发送，会有一个SreamID，那么服务端并发的响应不同的Stream也没关系，客户端会根据StreamID进行拼接。
  - ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/http2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.jpeg)
- **服务器推送**
  - 客户端和服务器都可以建立Stream，但是StreamID有区别，客户端建立的ID必须是奇数，服务器建立的ID必须是偶数
  - 服务端推送的好处：
    - 假设现在使用HTTP/1.1，那么当客户端去请求一个HTML页面的时候，可能还要再去请求一个CSS文件，这里就会有两个请求
    - 而HTTP/2，服务端会在客户端请求HTML的时候，再主动推送一个CSS过去，就可以少一次请求。
- **HTTP/2的缺陷**
  - 没有完全解决对头阻塞的问题，虽然HTTP协议上的对头阻塞，发送方接收方都解决了，使用Stream，但是TCP这一层的阻塞还是没有解决
  - 我们知道，数据在TCP传输的时候可能会被切分，此时如果受到的不完整数据，那么数据只能放入内核缓冲等待完整的数据到达，HTTP/2才能去内核中拿数据
  - ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http3/tcp%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.gif)
  - 我们可以看到，Packet3的数据没有收到，由于TCP数据不连续，所以接收方的应用程无法从内核读数据，就算后续的t4，t5，t6收到了，t3也得重传，应用层才可以读取到这个数据。
- 所以，一旦发生了丢包，TCP就会触发重传机制，这样一个TCP连接中的所有HTTP请求都需要等待这个丢掉的包重传才行。也就是后续的Stream也会被影响

##### HTTP/3的优化

- 既然我们说HTTP/1.1和HTTP/2都有对头阻塞，那么HTTP/3就来解决这个问题，先复习一下
  - HTTP/1.1对头阻塞：
    - HTTP/1.1虽然可以使用管道传输的方式，将发送方的对头阻塞问题解决，但是服务器还是得按照顺序来响应请求，如果某个请求处理太久，就会影响到后续的处理
  - HTTP/2对头阻塞：
    - 主要是在TCP底层的对头阻塞，因为TCP协议在某个数据包还没到的时候，这一组的数据包都不能被应用层所处理。
- HTTP/3直接把HTTP下层协议修改为UDP
- UDP是不可靠传输，所以HTTP/3使用了基于UDP的`QUIC`协议，实现类似TCP的可靠传输
- `QUIC`的特点
  - 无对头阻塞
  - 更快的建立连接
  - 连接迁移
- **无对头阻塞**
  - QUIC有类似HTTP/2 Stream的多路复用概念，也是一条连接可以传输多个Stream，一个Stream就可以认为是一个HTTP请求。而QUIC自己有一套机制，可以保证丢包时，只影响那个丢包的Stream，不会影响到其他的Stream。
- **更快的建立连接**
  - 在HTTP/1(或者说HTTPS)和HTTP/2中，TCP和TLS是分层的，也就说说TCP建立连接以后，还得TLS交换密钥，TCP握手，TLS握手。
  - 但是HTTP/3虽然也需要QUIC协议握手，而TLS不与QUIC分层，QUIC内部包含了TLS，所以在QUIC握手的时候会携带TLS的记录。QUIC使用的TLS/1.3，可以做到1RTT就完成连接，而HTTP/2需要大概3个RTT(使用TSL1.2的时候)来完成连接。
  - ![TCP HTTPS（TLS/1.3） 和 QUIC HTTPS ](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/28-HTTP3%E4%BA%A4%E4%BA%92%E6%AC%A1%E6%95%B0.png)
  - 甚至在第二次连接的时候，QUIC握手信息可以和数据包一起发送，直接打到了0RTT的效果。
- **连接迁移**
  - TCP传输协议需要四元组来确定一个TCP连接：源IP，源端口，目标IP，目标端口
  - 所以，当用户从4g切换到WIFI的时候，由于源IP的改变，就需要断开连接，然后重新建立连接。建立连接就要经历TCP三次握手以及TLS1.2四次握手，所以用户会感觉卡顿一下
    - 而QUIC并不使用四元组的方式来绑定连接，使用的是**连接ID**来标记通信的断点。即使IP地址发生变化了，只要保存了连接ID，TLS密钥等上下文信息，就可以无缝的复用原连接，不需要重连。

##### TLS1.2与1.3

- TLS1.2是需要四次握手的，客户端发送随机数等信息，服务器响应随机数等信息，客户端发送`premaster key`以及告诉服务端后续将采用加密，服务端需要回应后续将采用加密。这样就是2RTT
- 而TSL1.3是三次握手。

### HTTP/1.1 优化

- 三种手段：
  - 尽量避免HTTP请求发送
  - 减少请求次数
  - 减少响应大小

#### 如何避免HTTP请求发送

- 使用缓存技术
- 强制缓存：
  - `Expire`：绝对时间
  - `Cache-Control`：相对时间
- 当请求/响应是一样的时候，我们可以将这对请求/响应存储在本地，然后通过`Cache-Control`字段设置过期时间的大小，当发现缓存没有过期的时候，就直接从缓存拿，当过期了，再去给服务器发请求
- 协商缓存：
  - 当发现缓存过期了，两种字段来协商
    - `If-Modified-Since`和`Last-Modified`
      - 服务器返回的时候，带上`Last-Modified`，当客户端发现缓存过期，并且响应有`Last-Modified`的字段的时候，就带上`If-Modified-Since`字段和`Last-Modified`的值发给服务端，服务端根据这个时间看看这个条目的数据有没有更新，如果发现没有更新，返回`304`给客户端告诉它可以安全的去缓存取
    - `If-Not-Match`和`ETag`
      - 服务器返回的时候，带上一个唯一的`ETag`标识符标识资源，当客户端发现有`ETag`字段并且缓存过期了，就带上`If-Not-Match`字段和`ETag`的值发给服务端，服务端通过检查这个唯一标识有没有修改过，没有修改说明资源没有更改，返回`304`给客户端告诉它可以安全的从缓存拿
  - 如果两组字段都有，`ETag`优先级更高，因为`ETag`的粒度更细，可以解决秒级别的更新问题

#### 如何减少HTTP请求次数

- 三个方面入手：
  - 减少重定向次数
  - 合并请求
  - 延迟发送请求
- **减少重定向**
  - 当资源发生位置变更的时候，客户端可能不知道，这时候服务端就得发送`302`请求和`Location`字段告诉客户端现在的资源位置在哪，客户端拿到以后再去重新发送一个新的请求。
  - 可以发现，如果重定向次数太多，每次请求都会变成两次请求，这样子效率就低了
  - 当我们有代理服务器的时候，可以通过代理服务器进行减少请求次数，比如，代理服务器不将`302`发到客户端，而是自己处理以后重定向到新的资源目录，直接将资源给到客户端
  - 进一步来说，如果代理服务器可以处理重定向请求，那么它甚至不需要再去问源服务器拿重定向地址，而是直接去重定向后的地址拿取资源给客户端。
  - ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%87%8D%E5%AE%9A%E5%90%912.png)
  - **减少HTTP响应数据的大小**
    - 可以对数据进行压缩，主要两种压缩
      - 无损压缩：
        - 需要资源压缩过后，可以完全恢复成原来的模样，如何压缩呢
        - 其实和Redis中的AOF文件重写有点类似，首先就是去除很多没必要的换行符和空格
        - 然后对原始资源建立统计模型，将常见的一些数据用较短的二进制表示，不常见的用较长的二进制表示
      - 有损压缩：
        - 将一些次要的数据丢弃，比如图片和视频，可以牺牲一些质量来换取减少资源量
        - 图片的压缩现在基本都是WebP格式
        - 而视频和音频的话，一般来说连续帧之间的变化比较小，可以取一个静态的关键帧，然后使用增量数据表示后续帧，这样减少数据
        - 比如一些视频，看书的视频，一般只有人物的手在变化，周围环境变化不大，那么环境帧就可以取一个关键的帧。

### HTTPS优化

- HTTPS主要两点优化：
  - 握手流程
  - 加密报文传输
- 其中，加密传输这个阶段，各个CPU厂商都在硬件进行优化了，所以性能其实已经很高了
- 握手阶段的话，最长是2RTT，其中的一些性能损耗在于：
  - 比如ECDHE密钥协商算法，两边都要使用椭圆曲线生成公私钥
  - 客户端需要去验证证书，这就涉及到验证链
  - 双方计算`premaster-key`
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls%E6%80%A7%E8%83%BD%E6%8D%9F%E8%80%97.png)
- **硬件升级**
  - 因为是要计算，所以可以升级CPU，特别是支持`AES-NI`特性的CPU，这款CPU在指令级别优化了AES算法
  - 如果支持的话，可以使用AES算法进行对称加密密钥生成，否则可以使用ChaCha20进行生成，
- **软件优化**
  - 比如升级Linux内核，升级OpenSSL
- **协议优化**
  - 密钥交换算法优化：
    - 正常RSA密钥交换的话需要2RTT，4次握手：
      - 客户端发送随机数，服务端返回随机数以及证书
      - 客户端验证证书，加密`premaster-key`，服务端返回确认
    - 而使用ECDHE支持抢跑`False Start`，也就是客户端在TLS协议第三次握手以后，可以直接发送加密应用数据给服务端，这样子就减少了一次RTT
  - TLS升级：
    - 在TLS 1.2的时候，一般都是4次握手，先互相Hello，然后交换公钥
      - 比如ECDHE，客户端先Hello，服务端生成椭圆曲线，以及公私密钥，将公钥给客户端，这里是1RTT
      - 然后客户端生成公私密钥，用服务端的公钥生成对称加密密钥，将公钥给服务端，服务端生成对称加密密钥，返回确认，才能通信。这里是1RTT
    - 在TLS1.3的时候，可以直接减少为1RTT
      - 客户端直接带上支持的椭圆曲线，以及各个曲线的公钥给服务端
      - 服务端选择一个参数，然后返回消息，带上服务端的公钥。此时双方都有生成对称加密密钥的参数了，后续可以直接通信。
    - ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls1.2and1.3.png)
    - 并且，TSL1.3支持的密码套件，废除了RSA和朴素DH，只支持ECDHE。对称加密的签名算法也只支持最安全的
    - 这是因为，假设有人伪造客户端进行密码套件降级的话，那就不安全了。
- **证书优化**
  - 也是两个方向：
    - 证书传输
    - 证书验证
  - **证书传输**
    - 选择ECDSA椭圆曲线证书，这种证书比RSA证书短很多
  - **证书验证**
    - 证书验证的时候，客户端需要走证书链进行逐级验证，还得使用CA的公钥破解证书，用签名算法验证证书，证书有时候会过期，吊销，所以客户端还可能去CA下载CRL或者OCSP来确保证书有效
    - CRL是证书吊销列表，由CA更新，列表内容是被撤销信任的证书序号，如果服务器的证书在此列表，说明以及失效了，不在才是有效
      - 两个问题：
        - 因为是由CA更新的，所以存在时效性问题，有可能证书刚被吊销，而CRL还没有更新，那么客户端还是会去信任的
        - 如果吊销证书很多，CRL会很多数据，下载速度很慢。
    - OCSP是在线证书状态协议，工作方式是向CA发起查询，让CA返回证书状态
      - 不用下载CRL，可以实时查询每张证书的有效性
      - 但是需要向CA查询，所以CA服务器如果网络状态差，那么查询还是很慢
    - OCSP Stapling
      - 服务器来定期的向CA周期新查询证书状态，获得一个带有时间戳和签名的结果，然后缓存它
      - 客户端请求的时候，服务器会将这个结果发给客户端。因为有签名，服务端没办法篡改(CA使用了摘要算法，服务端一改那摘要算法一看就有问题了。)，客户端就可以知道证书是否吊销了。
- **会话复用**
  - TLS握手的目的就是生成一个对称加密的密钥，那如果我们把首次的TLS密钥缓存起来，下次建立连接的时候直接使用这个TLS就可以了，这就是会话复用
  - 有两种：
    - Session ID
    - Session Ticket
  - **Session ID**
    - 工作原理很简单，双方首次TLS握手以后，将Session ID作为key，密钥作为Value，存储在双方的内存中。
    - 当客户端再次连接的时候，Hello消息里直接带上Session ID，那么服务器就可以去内存中找，找得到就直接使用这个密钥恢复状态，其他就可以跳过了。这样1RTT就可以完成复用。为了安全，这个密钥的缓存会定期清除
    - 两个问题：
      - 服务器得保存很多客户端的密钥，那么内存压力会比较大
      - 现在大多是多服务器负载均衡来运作的，客户端再次连接的时候不一定是上次的服务器，所以还是要走TLS握手
  - **Session Ticket**
    - 服务器不缓存客户端的密钥，由客户端缓存，类似Cookie
    - 首次连接后，服务端会加密这个通信密钥作为Ticket给客户端
    - 下次连接的时候，客户端返回这个Ticket给服务器，服务器通过自己的私有解密方法把Ticket解密以后就可以拿到密钥了，然后恢复会话。
  - 两种都有不具备前向安全性，一旦会话密钥的密钥被破解，就会泄漏前面的信息了
  - 并且，两种都有可能被重放攻击。比如客户端向服务器发送Session ID或者Session Key，但是被中间者截胡了(Session Id和Session Key不会被二次加密，如果客户端二次加密Session ID或者Session Key，那就得再次进行TLS握手给服务器公钥来解密，那这速度就又慢下来了)，中间者就可以使用这个Session Ticket发给服务端，服务端发现可以解密，说明身份验证通过了，即使中间者无法使用其中的密钥去进行别的通信，但是它可以多次重放例如POST请求修改资源，客户端对此是不知道的。
  - TLS1.2中使用Session ID或是Session Ticket的时间是1RTT，双方得确认好接下来使用加密通话了
  - TLS1.3中客户端可以直接将HTTP请求和Session Ticket发过去，就可以减少为0RTT，不过还是会有重放攻击。

### HTTP/2的优化

- 上面提到了HTTP/1.1的一些优化手段，但是它自身的一些缺点却无法避免，比如头部字段过于冗长，比如不支持服务器推送机制，比如对头阻塞问题。所以使用HTTP/2进行优化

#### HTTP/2兼容HTTP/1.1

- 为了使更新HTTP/2在使用上更加平滑，HTTP/2并没有引入新的URL协议名，仍然采用http://表示明文，https://表示加密
- 且底层通信协议依然选择TCP，只在应用层进行修改。而应用层的语义层不进行更改，也就是说使用的时候还是一样的，只不过语法层进行改动

#### 头部压缩

- HTTP/1.1协议中，虽然可以指明压缩方式`Content-Encoding`来压缩Body字段，但是对于本身的头部字段并未做处理，使用的ASCII编码，可读性好，不过效率太低，占有字节过多。
- HTTP/2使用`HPACK`算法进行头部压缩，主要为：
  - 静态字典
  - 动态字典
  - Huffman编码
- 客户端和服务器都会建立以及维护字典，使用索引号来表示重复的字符串，再使用Huffman编码来压缩数据

#### 静态表编码

- HTTP/2为高频的头部字符串建立了静态表，这个表是写在HTTP/2协议中的，不会变化，有61个值

- ![img](https://cdn.xiaolincoding.com//picgo/image-20240105142818571.png)

- 可以看到，有些头部的Value值是空的，因为有些头部后面的Value并不是固定的，后续会采用Huffman编码发送过去。

- ```
  +---+---+---+---+---+---+
  | 0	| 1	|	Index(6+)	|
  +---+---+---+---+---+---+
  | H	| 	Length(7+)		|
  +---+---+---+---+---+---+
  |	Value String		|
  +---+---+---+---+---+---+
  ```

- 如果头部字段在静态表内，且Value是变化的，则前两位是01，后6为表示对应的Index。

- 中间是Value的长度，如果使用Huffman编码，则首位为1，后7为表示长度

- 最后是Value值，通过Huffman编码。Huffman编码是将高频出现的信息用较短的编码表示，从而减少字符串的长度

- 我们知道在Ascii编码中，所有字符都是1个字节，而Huffman编码则不一样，例如：

  - ![img](https://cdn.xiaolincoding.com//picgo/image-20240105142917193.png)

#### 动态表编码

- 静态表只包含61个常见的头部字符串，不在这个范围内的头部就需要使用动态表了，它的Index从62开始，然后随时更新
- 其实就是缓存的概念，可以将一些自定义常用的头部编码到动态表中，甚至，如果Value值也不变的话，将Value值也可以编码到动态表中，后续的请求连Value都可以不带，只带Index值。
- 动态表是客户端和服务端一起维护的，所以Index值是可以正确的找到头部和Value的
- 当然，也可以像静态表中的动态Value，使用动态表中的头部Index，再携带上Huffman编码的Value值

#### 二进制帧

- 我们上面说到了，HTTP/1.1使用的是纯字符串来传输头部信息和Value，HTTP/2将数据报文分为了两类帧，HEADERS头部帧和DATA消息帧。HEADERS其实就是使用静态编码和动态编码实现的。

- 比如状态码`200`这个编码，在HTTP/1.1中是纯字符串，也就是3个字节

- 而HTTP/2中，静态表中的状态码`200`对应的是index 8，因为它是key和value确定的编码，首位为1，后续为`1000`，总共字节为1，首位和index之间0填充：

  - ```
      0	  1	  2	  3	  4	  5	  6	  7
    +---+---+---+---+---+---+---+---+
    | 1 |		Index(7+)			+
    +---+---+---+---+---+---+---+---+
    ```

  - 对应的就是`10001000`，比HTTP/1.1少了2个字节。

- 需要注意，我说的HEADERS头部帧和一下的帧头不是一个东西，头部帧也是帧，只不过头部帧中的payload是头部信息。

- 每个帧的结构为：

  - ![image-20240105143208962](https://cdn.xiaolincoding.com//picgo/image-20240105143208962.png)
  - 帧头一共9个字节，前三位表示帧的长度
  - 后一位表示帧的类型，一共10种类型，分为数据帧和控制帧：

    - ![image-20240105143150947](https://cdn.xiaolincoding.com//picgo/image-20240105143150947.png)
  - 帧类型后一位表示标识位，可以保存8个标志位
  
    - **END_HEADERS** 表示头数据结束标志，相当于 HTTP/1 里头后的空行（“\r\n”）；
    - **END_Stream** 表示单方向数据发送结束，后续不会再有数据帧。
    - **PRIORITY** 表示流的优先级；
  - 最后4个字节是标识符，不过前1位不使用，只是用31位，所以最大是0 - 2^31 - 1范围。它是表示Frame属于哪个Stream，接收方就可以通过这个标识符来找到乱序中相同Stream ID的帧拼接信息
  - 最后就是帧中的数据，使用`HPACK`算法压缩HTTP头部和包体。
  

#### 并发传输

- HTTP/1.1还有一个问题就是对头阻塞（虽说可以开启管道传输解决客户端的对头阻塞，但是服务器依然存在对头阻塞）。HTTP/2通过Stream流来实现多路复用，也就是多个Stream共用一个TCP连接，达到并发的效果。
- 具体如何实现的呢，先看看HTTP/2中的三个概念，Stream, Message, Frame
- ![image-20240105143224839](https://cdn.xiaolincoding.com//picgo/image-20240105143224839.png)
- 可以看到：
  - 一个TCP中有多个Stream，一个Stream里有多个Message，一个Message里有多个Frame
  - 同一个HTTP请求是在一个Stream中的，HTTP请求可以由多个Frame组成，一个Frame可以由多个报文组成
- HTTP/2中，不同Stream的帧是可以乱序发送的，所以每个帧都要带上一个Stream ID作为标识。同一个Stream内部的帧就必须是有序的了。
- 双方都可以建立Stream，客户端建立的Stream必须是奇数，服务器建立的必须是偶数，所以服务器可以推送消息给客户端。
- 同一个连接的Stream ID不可以复用，只能顺序递增，当Stream耗尽以后需要发送控制帧`GOAWAY`来关闭TCP连接。
- HTTP/2通过Stream实现并发，HTTP/2实现并发的时候，100个stream只需要一个TCP连接，而HTTP/1.1则需要100个TCP连接。
  - 因为HTTP/1.1单个TCP会有对头阻塞，所以如果发两个请求得等，实现并发的话就得建立多个TCP连接
  - HTTP/2就没有这个问题，同一个TCP连接可以并发多个请求。

#### 服务器推送

- 从上面的Stream流我们可以看到，服务器和客户端都可以建立Stream连接，所以服务器可以推送资源给客户端。
- 比如在HTTP/1.1中，客户端请求一个HTML页面，这个HTML需要一些CSS渲染，所以客户端还得请求一个CSS来渲染，就需要2RTT
- HTTP/2中，当客户端请求一个HTML页面，服务器可以直接推送CSS给客户端，这就是1RTT
- 怎么实现？
  - 服务器的Stream ID是偶数，当客户端来了一个请求以后，服务器可以发送`PUSH_PROMISE`帧传输HTTP头部，然后通过`Promised Stream ID`告诉客户端接下来包体是在哪个偶数号的Stream ID，这一步是在Stream ID = 1这个Stream操作的
  - 最后，服务器发送一个Stream ID = 2的帧过去，里面包含了一个CSS文件，客户端知道这个ID是CSS，就可以拿来渲染了。

### WebSocket

- 有时候我们点击进入一个网络游戏里，会发现怪物都在自己移动，那底层肯定是服务器不断地发送数据到客户端进行渲染，但这是怎么做的呢？

#### 使用HTTP不断轮询

- 问题就在于，用户不做操作的时候，网页怎么能收到消息
- 使用HTTP的话，可以在网络前端代码中不断发HTTP请求到服务器，服务器受到请求后给客户端响应
- 这是一种**伪**服务器推送，他并不是服务器发消息到客户端，而是客户端自己偷偷发请求，最常见的就是扫码登录
- 当二维码页面出现的时候，其实前端并不知道客户端有没有扫，于是就不断地向后端轮询，问有没有人扫这个码，大概以1到2秒去轮询，可以保证用户在扫码后1到2秒得到反馈。
- 问题：
  - 当使用F12看，会发现满屏的HTTP请求
  - 最坏情况下，用户需要等慢2s中，才刚好触发下一个HTTP请求
  - 比如淘宝页面：
    - ![image-20240207122002548](C:\Users\62488\AppData\Roaming\Typora\typora-user-images\image-20240207122002548.png)
  - 不断轮询有没有人扫码

#### 长轮询

- 一般HTTP请求发送之后，会给服务器留时间进行相应，规定时间没返回，就认为超时，立马发下一次请求

- 那我们可以设定一个长时间的轮询，超时时间设置比如30s，当30s内有用户扫码，服务器立马返回给客户端

- 这样子就减少了HTTP请求的个数了。这种技术就是服务器推送技术。

  - 底层可以这么设计

  - ```Java
    //客户端请求过来以后，服务器生成一个CompletedFuture，然后调用get
    //当QR被扫了，服务器感知到以后，调用CompletedFuture的success。
    ```

- 但这个只适合简单场景，对于游戏场景，会有大量的服务器推送

- 我们就得使用WebSocket了

#### 啥是WebSocket

- TCP是全双工的，也就是双方都可以主动发送数据
- 但是HTTP/1.1是半双工，因为设计之初考虑的是网页看文本之类的场景，没有考虑到游戏啊这些大量服务器需要主动推送的场景，为了这个的支持，使用了另一个基于TCP协议的新协议，这个就是WebSocket
- WebSocket和Socket无关哈

#### 如何建立WebSocket连接

- 一开始建立TCP三次握手的时候，统一基于HTTP协议进行一次通信

  - 如果是普通的HTTP请求，那么后续就使用HTTP

  - 如果想建立WebSocket连接，就在HTTP头上带上一些特殊的头

    - ```
      Connection: Upgrade
      Upgrade: WebSocket
      Sec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\r\n
      ```

  - `Connection: Upgrade`表示浏览器想升级协议，升级成WebSocket`Upgrade: WebSocket`，同时带上一个随机生成的base64码(Sec-WebSocket-Key)发给服务器

  - 如果服务器支持，就会走WebSocket握手，根据客户端生成的base64，用公开的一个算法变成另一个字符串，放到HTTP响应`Sec-WebSocket-Accept`里，并且带上101状态码

    - ```
      HTTP/1.1 101 Switching Protocols\r\n
      Sec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\r\n
      Upgrade: WebSocket\r\n
      Connection: Upgrade\r\n
      ```

  - 101指得是协议转换。然后客户端也会将base64码经过一个公开算法进行转换，如果和服务器得相同，那么验证通过。这里的Base64作用我认为是服务器可以来理解WebSocket协议，并且正确的响应一个握手请求，防止的是连接错误的建立。

## TCP

### TCP三次握手和四次挥手

#### TCP头部格式

- ![TCP 头格式](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png)
- **序列号**：解决包乱序的问题，建立连接时的随机数为初始值，每发送一次数据就+1
- **确认应答号**：下一次期望收到数据的序列号，发送端收到确认应答之后可以认为前面的序号都正常接收，解决丢包问题
- **控制位**：
  - ACK：为1时表示：确认应答字段有效，除了最初的SYN包之外这个为都设置为1
  - RST：为1表示TCP连接出现了异常，需要断开连接
  - SYN：为1表示希望建立连接，序列号字段进行序列号初始值的设定
  - FIN：为1，表示希望断开连接。通信结束以后双方主机就可以互相交换FIN为1的TCP段

#### TCP是是什么？

- TCP是面向连接、可靠的、基于字节流的传输层协议
  - 面向连接：一对一的连接
  - 可靠的：TCP可以保证一个报文一定能到达接收端
  - 字节流：TCP协议中的用户消息可能会被操作系统分组，接收方需要知道消息边界来解决粘包问题，TCP报文也是有序的，前一个报文没有收到的时候，后续的TCP报文就算收到也不可以丢给应用层处理

#### TCP连接连接的是什么？

- 为了保证消息可靠，TCP需要通过连接来确认一些信息：
  - Socket：IP和端口号
  - 序列号：解决乱序问题
  - 窗口大小：做流量控制

#### 如何唯一确认一个TCP连接

- 通过四元组：源地址，源端口号，目标地址，目标端口号
- 其中，源地址和目标地址由IP协议来维护，在IP头部信息当中，源端口号和目标端口号在TCP头部当中

#### 一个主机的最大连接数是多少？

- 主机是监听的，所以有多少个客户端和多少个端口就可以计算最大的连接数：

  - ```
    最大TCP连接数=客户端IP数×客户端端口数
    ```

- 在IPv4地址中，客户端IP数最多为2^32次方，端口号最多为2^16次方，理论上最多是2^48次方

- 但是这基本是不可能，原因：

  - 文件描述符限制：每个TCP连接都是一个文件，如果描述符占满了，会发生`Too many open files`。Linux对此做了三个限制
    - 系统级：当前系统可打开的最大数量
    - 用户级：指定用户可打开的最大数量
    - 进程级：单个进程可打开的最大数量
  - 内存限制：TCP连接会消耗内存，操作系统内存是有限的。

#### TCP和UDP的区别

- UDP是利用IP提供无连接的通信服务，头部很简单，因为不需要维护复杂的可靠连接
  - ![UDP 头部格式](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230439961.png)
- 包长度：UDP首部的长度和数据长度之和
- 检验和：用来提供可靠的UDP首部和数据，防止网络传输过程中数据受损
- TCP和UDP的区别如下：
  - 连接：
    - TCP是面向连接的传输协议，通信之前要建立连接
    - UDP不需要连接，即刻传输数据
  - 服务对象：
    - TCP是一对一的两点服务，一条连接只有两个端点
    - UDP支持一对一，一对多和多对多的通信
  - 可靠性：
    - TCP是可靠的连接，数据可以无差错，不丢失，不重复，按序到达
    - UDP和IP一样，是尽最大可能交付数据，不过可以QUIC协议是可靠的，它是基于UDP实现的
  - 阻塞控制、流量控制
    - TCP有阻塞和流量控制，保证数据传输的安全性
    - UDP不管网络状况，直接发送
  - 首部开销：
    - TCP的首部开销比较大，因为要维护可靠连接，所以有很多字段需要设置
    - UDP首部只有8个字节，固定不变
  - 传输方式：
    - TCP是基于流传输，没有边界，但是可以保证顺序和可靠性。
    - UDP是一个包一个包的发送，有边界，但可能会丢包和乱序。
  - 分片不同：
    - TCP数据大小如果大于MSS大小，就会在传输层先进行分片，目标主机收到以后也会在传输层进行组装。如果丢失一个分片，则只需要重传这个分片
    - UDP数据大小如果大于MTU大小，会在IP层进行分片，目标主机收到以后，会在IP层组装数据，然后再传给传输层。
- TCP和UDP的应用场景：
  - TCP是面向连接的，可靠的，用于：
    - FTP文件传输
    - HTTP/HTTPS
  - UDP是面向无连接的，可以随时发送数据，处理也很简单，高效，用于：
    - 包总量较少的通信，DNS等
    - 视频，音频等多媒体通信，不需要数据完全精确可靠
    - 广播通信
- 为什么UDP头部没有首部长度字段，而TCP有？
  - 因为TCP有一个可变长选项字段，所以要记录一下首部长度
- 为什么UDP头部有包长度字段，而TCP没有
  - TCP数据长度，可以使用IP总长度-TCP首部长度-IP首部长度计算，所以没必要多一个字段来维护
  - 但是UDP也可以使用这个公式呀？
    - 原因在于：
      - 为了网络设备硬件涉及和处理方便，首部长度需要是4字节的整数倍，多一个UDP的包长度字段可以补全UDP为4字节的头部为4的整数倍
      - 如今UDP是基于IP协议，但是早期可能不是基于IP协议的，所以这个公式早期不能使用，也就是早期来说网络层协议可能不提供自身报文长度或者首部长度，所以UDP得自己维护一下

#### TCP和UDP端口？

- 可以使用同一个端口，因为TCP和UDP在内核中是完全独立的软件模块。后续会详细讲

#### TCP连接建立

##### TCP三次握手！

- TCP是面向连接的，所以使用的时候得经历三次握手来建立连接
- 首先客户端和服务端都处于`CLOSE`状态，然后服务器去监听某个端口，处于`LISTEN`状态
- 第一次握手：
  - 客户端会去随机一个序列号`client_isn`，将这个序列号放置在TCP首部的`序号`字段上，同时把`SYN`状态位设置为1，表示这是一个`SYN`报文，接着就把第一个SYN报文发送给服务端，表示发起连接。这次握手不携带数据，客户端此时处于`SYN_SENT`状态
- 第二次握手：
  - 当服务端收到客户端的SYN报文之后，服务端会去随机一个序列号`server_isn`，将这个序列号设置为TCP的`序号`字段，然后把TCP首部的`确认应答号`填入`client_isn + 1`，接着把`SYN`和`ACK`状态位设置位1，最后将这个报文发送给客户端。这个报文也不携带数据，此时服务端处于`SYN_RCVD`状态
- 第三次握手：
  - 客户端收到服务端返回的报文之后，还会响应最后一个报文，这个报文将TCP的`ACK`状态位设置为1，然后将`server_isn + 1`设置到`确认应答号`字段中，最后将报文返回给服务端，这个报文同时可以携带数据，之后客户端处于`ESTABLISHED`状态
- 服务端收到这个报文以后，也处于`ESTABLISHED`状态。
- 第三次握手是可以携带数据的，前两次是不可以的：
  - 第一次握手的时候，客户端并不知道服务器能不能收到，所以不能携带数据
  - 第二次握手的时候，服务端并不知道客户端能不能收到，所以也不能携带数据
  - 第三次握手的时候，客户端此时已经确认了服务端的接收发送没问题，所以可以携带数据了
- 使用`netstat -napt`查看TCP连接状态

##### 为啥是三次握手，不是两次和四次？

- 简单的回答就是：
  - 为了双方都能确认对方的接收和发送功能没问题
- 这是片面的，主要原因有三个：
  - 三次握手可以阻止重复历史连接的初始化
  - 三次握手可以同步双方的初始序列号
  - 三次握手可以避免资源浪费

###### 避免历史连接

- 三次握手的首要原因就是防止旧的重复连接初始化造成混乱
- 有一个场景：
  - 客户端先发送了`SYN`，`SEQ = 90`的报文，但是客户端宕机了，而且这个SYN还阻塞了，服务器现在没收到，接着客户端重启以后，又向服务器建立连接，发送了`SYN`，`SEQ = 100`报文（这并不是重传，可以看到SEQ并不一样）
  - 此时，旧的SYN到达了服务器，服务器会去返回一个ACK为91的报文，客户端收到以后，发现和预期的101不一样，会返回`RST`报文，认为连接有问题，需要释放连接
  - 服务器收到以后就会去释放连接
  - 后续最新的SYN到达服务器的时候，就可以完成三次握手了。
- 那假设，服务器还没收到客户端的`RST`报文，此时接收到了新的`SYN`，怎么办？
  - 当服务器第一次收到`SYN`的时候，会返回ACK=91的报文给客户端
  - 然后服务器又收到了一个`SYN`，此时服务器会去返回一个`Challenge ACK`，也就是刚刚的ACK=91这个报文给客户端，所以两次其实发送的都是旧的ACK=91给客户端，那么客户端就回复RST，也就是此时连接无法建立了。
- 可以看到，三次握手阻止了一个历史连接尝试建立，那如果是两次握手呢？
  - 两次握手的情况下，服务端没有中间状态来给客户端阻止历史连接，导致服务端可能会去建立一个历史连接
  - 两次握手：
    - 服务端收到SYN以后立马ESTABLISHED建立连接，但是客户端此时并不是ESTABLISHED状态，如果此时服务端返回一个ACK=91的报文给客户端，客户端认为这是一个历史连接，就会去返回RST断开连接
    - 但此时服务端已经建立好连接了，然后收到RST又会去中断这个连接，那这个连接其实什么都没有做，白白浪费了资源。
- 小问题：客户端三次握手之后，可以发送数据了，但是此时服务端还是处于`SYN_RCVD`状态，那如果这个ACK丢掉了怎么办？客户端数据会浪费吗？
  - 并不会，就算ACK丢掉了，但是后续的数据包中的确认应答字段其实还是包含了ACK的值，也就是说，数据报文中的ACK状态为是一直开启的，所以服务器收到数据以后，会发现客户端成功响应了之前的第二次握手，也就会成功建立连接。 

###### 同步双方的初始序列号

- TCP协议的双方，都需要维护一个序列号，这个序列号是提供可靠连接的其中一环：
  - 接收方可以去除重复数据
  - 接收方可以根据数据包的序列号按序接收
  - 可以表示发送出去的数据包，哪些已经被对方收到了（通过ACK报文中的序列号知道）
- 当客户端发送携带初始序列号的`SYN`报文，服务端需要返回一个`ACK`报文，表示SYN已经被成功接收了，那么当服务端发送初始序列号`SYN`报文时，客户端也要返回一个`ACK`，这样一来一回，双方都可以可靠的同步初始序列号
- 当然，服务端返回ACK的时候，同时也可以发送`SYN`，所以不需要四次握手，三次握手就足够了。
- 而二次握手，服务发送`SYN`后，并不知道这个`SYN`是否被成功接收，那么就没办法保证初始化序列号都被确认接收了。

###### 避免资源浪费

- 假设此时我们使用二次握手，然后客户端发送的`SYN`在网络阻塞，客户端没有收到`ACK`，那么就会重传这个`SYN`，那么由于我们是两次握手，服务器收到一个`SYN`就会去建立连接，此时阻塞的`SYN`到达以后，服务器就又会开启连接，那么就造成了资源浪费。

###### 总结

- 两次握手：会有历史连接建立的问题，会造成资源浪费，也会造成无法同步可靠的双方序列号
- 四次握手：理论上三次握手就可以建立可靠连接了，没必要使用四次握手。

##### 为什么每次建立TCP连接，初始化的序列号都要求不一样呢

- 原因：
  - 防止历史报文被下一个相同的四元组连接接收
  - 方式黑客伪造的相同序列号TCP被接收

###### 防止历史报文被下一个相同的四元组连接接收

- 问题：
  - 比如，客户端首先和服务器建立好了连接，从`SYN SEQ=0`开始建立，那么客户端在发送数据的时候，SEQ=1
  - 此时，服务器宕机了，比如重启了，那么以前的连接会消失，所以收到这个SEQ=1的数据包会返回一个RST，断开连接
  - 客户端尝试再次建立连接，还是从SEQ=0开始建立，那么客户端发送数据的时候还是SEQ=1，那么这个SEQ=1的数据是在服务器的接收窗口内的，旧数据也是SEQ=1，旧数据也会在服务器的接收窗口内，所以当旧数据来到的时候，服务器会正常接收，就会造成了数据错乱了。
- 如果每次建立连接的序列号都不一样，就不会出现这个问题了
  - 第一次连接的SEQ=100，那么发送数据的SEQ=101
  - 此时重启，客户端尝试连接，此时SEQ=500，发送数据的SEQ=501，假设服务器接收窗口大小是100，那么只有501-601这个范围才会被接受，所以旧数据的SEQ=101就不会被接收了
- 不过呢，因为序列号有回绕问题，所以还得通过时间戳的机制来判断历史报文。（序列号不能无限增大吧，总共也就32位，满了就得回绕了）。
- 所以呢，是大概率可以解决这个问题的，不过还是得引入其他机制来完全保证不要接收到错误的数据

##### 初始序列号ISN如何生成

- 很简单，有一个计时器和一个哈希算法来计算
- `ISN = M + F(localhost, localport, remotehost, remoteport)。`
- M是一个时钟，每4微秒+1
- F是一个哈希算法，根据四元组，源端口，源地址，目标端口，目标地址生成的随机数，当然使用一个MD5算法比较好，不要被外界推出来。

##### 为什么TCP还要进行分片？

- MTU：一个网络包的最大长度，一般为1500字节
- MSS：除去IP头和TCP头，一个TCP数据包的最大长度
- 那如果我整个数据包给到IP进行分片，有什么问题？
  - IP并没有超时重传机制，由TCP来负责重传。当IP进行分片以后，其中一个分片丢失了，那么接收的IP层可能会无法拼凑成一个完成的TCP报文(可能分片将TCP头和数据分开了，此时头或者数据某个部分丢失了)。接收方的IP层无法给数据报文给到TCP层，接收方也就不会返回ACK，但是发送方迟迟没收到ACK，就得进行重传，而这个重传会将整个TCP报文重传（它不知道具体哪个部分没掉了）
- 所以呢，为了不让IP来进行分片，我们最好是保证每个网络包不要超过MTU，那么也就是数据+IP头和TCP头不要大过MTU，那么也就是数据不要大过MSS
- MSS由双方协商好，然后TCP在发先数据打过了MSS时，就会先进行分片，那它所形成的IP包就肯定不会超过MTU，自然也就不需要IP层来进行分片了
- 所以主要目的就是不要让IP层来进行分片，因为这样子会导致数据包整体全部重传。由TCP来进行分片，就算一个分片丢失了，也可以只重发这个分片，以MSS为单位。

##### 握手丢失问题

###### 第一次握手丢失？

- TCP建立连接的时候，客户端会去先发送一个SYN包请求建立，然后进入到`SYN_SETN`状态。
- 如果客户端迟迟未受到第二次握手传回来的`SYN-ACK`报文，就会触发超时重传机制，重传一条`SYN`报文， 且`SYN`的值一致
- 重传几次呢？
  - Linux系统下，可以在`/proc/sys/net/ipv4/tcp_syn_retries`文件中修改，默认值一般是5此
- 第一次重传是1s之后，然后是2s，然后是4s，然后是8s，然后是16s，每次都是上一次的2倍
- 第五次重传之后，如果等待32秒(这个等待时间也是上一次的2倍)以后还是没收到`SYN-ACK`报文，那么就不再发送SYN，断开连接。

###### 第二次握手丢失？

- 第二次握手既`SYN-ACK`，也就是服务端的响应，服务端会进入到`SYN_RCVD`状态。
- 第二次握手有两个目的：
  - 第二次握手的ACK，是第一次握手的确认报文
  - 第二次握手的SYN，是服务端发起建立连接的报文
- 第二次握手如果丢失了，那么客户端也就没收到ACK，而服务端没收到它自己的SYN的ACK，所以两方都会开始重传。
- 客户端重传`SYN`，服务端重传`SYN-ACK`
- SYN-ACK报文重传次数由内核决定。`/proc/sys/net/ipv4/tcp_synack_retries`，默认值也是5

###### 第三次握手丢失

- 客户端收到`SYN-ACK`以后，就会返回一个`ACK`报文给到服务器，也就是第三次握手，此时客户端进入了`ESTABLISHED`状态。
- 当第三次握手丢失以后，服务端会迟迟收不到`ACK`，那就会触发超时重传机制。
- 收到不到ACK报文的那方才会去重传。

###### 总结：

- 第一次握手丢失，由客户端重传，因为它收不到ACK
- 第二次握手丢失，客户端和服务端都会重传，客户端没收到SYN的ACK，服务器也没收到SYN的ACK
- 第三次握手丢失，由服务端重传，因为它收不到ACK

##### 什么是SYN攻击？如何避免

- 讲到SYN攻击前，先看看Linux内核是怎么进行三次握手的
- 当TCP三次握手的时候，内核会去维护两个队列：
  - 半连接队列，SYN队列
  - 全连接队列，accept队列
- 正常流程如何工作呢？
  - 当服务器接收到客户端的SYN请求后，会创建一个半连接对象，放入SYN队列当中
  - 然后发送SYN-ACK给客户端，等待回应ACK
  - 当收到ACK以后，会从SYN队列取出一个半连接对象，然后创建一个新的连接对象放入Accept队列当中
  - 最后，应用通过调用`accept()`方法，从Accept队列中取出对象
- 不管是SYN队列还是Accept队列，都是有大小上限的，当队列满了之后，默认是丢弃报文。
- SYN攻击？
  - SYN攻击是攻击者通过伪造不同的IP地址的SYN报文，发送给服务端。当服务端接收到SYN报文以后，会去发送SYN-ACK报文，同时创建一个对象放入半连接队列。但是攻击者并不会去响应SYN-ACK报文，服务端收不到响应就不会移除半连接队列中的对象（当然重传次数满了还是会移除）。久而久之，半连接队列就会溢出，无法正常提供服务。
- 怎么避免呢？
  - 调大netdev_max_backlog
  - 增大TCP半连接队列
  - 开启tcp_syncookies
  - 减少SYN-ACK的重传次数

###### 调大netdev_max_backlog

- 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列来保存这些数据包。可以适当的调大这个参数，控制队列的最大值：
  - `net.core.netdev_max_backlog = 10000`


###### 增大TCP半连接队列

- 原因就是因为半连接队列满了，所以可以尝试增大半连接队列
- 具体如何增大后续将

###### 开启net.ipv4.tcp_syncookies

- 这个syncookies功能开启以后，就可以不使用SYN半连接队列，也可以成功建立连接，相当于绕过了半连接队列
- 当SYN队列满了之后，后续服务器接收到SYN包，不会将其丢弃，而是根据算法计算出一个`cookies`
- 这个`cookie`值会放入第二次握手报文的序列号中，服务端回第二次握手给客户端
- 当收到客户端的应答之后，服务器会去检查这个ACK的合法性，如果合法，那么就将连接对象放入Accept队列中
- 最后程序通过调用`accept()`接口，从全连接队列里拿到这个连接
- `net.ipv4.tcp_syncookies`有三个值：
  - 0：表示关闭
  - 1：表示仅当TCP半连接队列满了之后再启用他
  - 2：表示无条件开启
- 对于我们这个场景，设置为1即可

###### 减少SYN-ACK的重传次数

- 当第二次握手发送之后，服务器如果没有收到ACK的话，会进行重传。在重传没有达到上限的时候，是不会丢弃连接的。所以我们可以减少重传的次数，让重传快点完成，这样子就可以更快的从半连接队列中抛弃那些没有ACK的连接，也就是处于`SYN_RECV`状态的连接
- 由`tcp_stnack_retries`决定，默认是5次，我们可以去减少到两次。

#### TCP连接断开

##### TCP四次挥手过程

- 客户端打算断开来连接了，会发送一个TCP首部`FIN`标志位为1的报文，也就是`FIN`报文，之后客户端进入`FIN_WAIT_1`状态
- 服务器收到以后，会去发送响应报文`ACK`，此时，服务器进入`CLOSE_WAIT`状态
- 客户端收到这个`ACK`以后，会进入到`FIN_WAIT_2`状态。
- 当服务器处理完数据以后，也会向客户端发送`FIN`报文，此时服务器进入`LAST_ACK`状态
- 客户端收到`FIN`以后，会去响应`ACK`，之后进入到`TIME_WAIT`状态
- 服务器收到`ACK`以后，就会进入到`CLOSE`状态，至此服务器关闭连接
- 客户端等待`2MSL`一段时间，自动进入到`CLOSE`状态，至此客户端关闭连接。
- 主动关闭连接的那方，才会有`TIME_WAIT`状态。

##### 为什么要四次挥手

- 关闭连接的时候，客户端向服务器发送`FIN`，此时只表示客户端不再发送数据了，但还可以接收数据
- 服务端收到`FIN`，先去响应一个`ACK`，而服务端此时可能还有数据要处理和发送，等服务端处理完以后，才会去发送`FIN`告诉客户端我同意现在关闭连接。

##### 第一次挥手丢失，会发生什么？

- 第一次挥手是客户端调用close函数，向服务器发送FIN报文，试图关闭连接，此时客户端进入到`FIN_WAIT_1`状态
- 当第一次挥手丢失之后，客户端迟迟没有收到ACK报文，那么就会进行重传，由`tcp_orphan_retries`参数去控制
- 当重传次数超过上限之后，就不再发送FIN报文，会再去等待一个时间（和握手的时候一样，上一次等待时间的2倍）。如果还是未能收到ACK，那么就直接进入`CLOSE`状态。

##### 第二次挥手丢失，会发生什么？

- 第二次挥手是服务器收到了FIN报文之后，响应一个ACK给客户端，如果这个ACK丢失了，那么一样，客户端迟迟没有收到ACK，就会触发超时重传机制，和上面一样，达到上限之后，客户端直接进入`CLOSE`状态
- 这里提一下，当客户端正常收到ACK以后，会进入`FIN_WAIT_2`，如果是调用close函数关闭，那么由于无法接收和发送数据，`FIN_WAIT2`状态不可以持续太久，由`tcp_fin_timeout`来控制持续时长，默认是60s
- 所以调用close()关闭的连接，如果60秒还没有收到FIN报文，那么客户端就会直接关闭连接
- 但如果是使用`shutdown`函数进行的关闭连接，指定了只关闭发送方向，而接收方向没有关闭，那么关闭方还是可以接收数据的，这就意味着如果一直没有收到第三次挥手，那么就会一直处于`FIN_WAIT2`状态。也就是死等下去。`tcp_fin_timeout`对shutdown函数是不起效的。

##### 第三次挥手丢失，会发生什么？

- 当服务器收到了客户端的FIN报文后，内核会自动回复ACK，并且处于`CLOSE_WAIT`状态，等待应用进程调用close函数
- 当服务器处于`CLOSE_WAIT`，并且调用了close函数，那么内核就会去发送`FIN`报文，进入到`LAST_ACK`状态。如果这个报文丢失了，那么服务端由于没有收到ACK，就会触发超时重传，也是由`tcp_orphan_retries`参数去控制
- 客户端如果是通过close函数关闭连接的，那么等待60s没有收到服务器的FIN报文，就会关闭连接了

##### 第四次挥手丢失会发生什么？

- 第四次挥手，也就是客户端收到了服务器的FIN报文，响应一个ACK回去，处于`TIME_WAIT`状态，会去等待`2MSL`才关闭连接
- 如果第四挥手丢失，那么服务器也是依然没有收到ACK，那么会触发超时重传。
- 当重传的FIN报文来到客户端时，客户端会再次返回ACK，并且重置`2MSL`的定时器时间。

##### 为什么要在TIME_WAIT状态下要等待2MSL

- MSL是报文最长生存时间，是任何报文在网络上存在的最长时间，超过这个时间的报文就会被抛弃。
- Linux设置MSL为30s中，而TIME_WAIT状态是等待2MSL，因为客户端的ACK如果没有到达服务端，服务端会重发一个FIN，这一来一回的时间正好是2MSL。
- 那为什么不多等一会呢？假设此时，第四次挥手ACK丢失了，服务器重传的FIN也丢失了，那么服务器会再次重传FIN，如果只等2MSL，第二次重传不就收不到了嘛？
  - 正常来说，连续两次丢包的概率实在是太小了，假设我们的网络是1%的丢包率，连续两次既万分之1，概率实在太小，所以直接忽略比较好。

##### 为什么要设置一个TIME_WAIT状态

- **主动发起断开连接的一方，才会有TIME_WAIT状态**
- 主要有两个原因：
  - 防止历史连接被后续相同四元组的连接错误的接收
  - 保证被动关闭连接的一方可以正确的关闭

###### 防止历史连接被后续相同四元组的连接错误的接收

- 还是和我们的序号有关系，序号在TCP中是标识数据包顺序的重要部分，它是32位的无符号数，那么到达4G之后会去循环到0
- 序号不会无限递增，而是会发生绕回初始值的情况，所以无法根据序号来判断一个数据是新的还是老的
- 假设TIME_WAIT状态太短了？
  - ![TIME-WAIT 时间过短，收到旧连接的数据报文](https://cdn.xiaolincoding.com//mysql/other/6385cc99500b01ba2ef288c27523c1e7-20230309230608128.png)
- 那么前面延迟的数据就可能在新连接之后才到达，这样子如果数据包在接收方的窗口内，就会被接收了，这样的问题很大，数据会发生错乱。
- 如果等待2MSL，也就是有TIME_WAIT状态，那么可以让两个方向的数据包都被丢弃了，让延迟数据包在网络中自然消亡，这样子新的连接中肯定是最新的数据

###### 保证被动关闭连接的以防可以正确的关闭

- 想象一下，如果没有TIME_WAIT状态，那么客户端在发送ACK也就是第四次挥手之后直接关闭了，假设这个ACK丢失了，那么服务端得重发FIN，此时由于客户端已经关闭，那么就会返回一个RST错误，这可不是一个优雅的关闭，终止方式
- 所以为了防止这种情况，客户端就得等够时间，让服务端正确的接收到ACK。包括上面说了，等待2MSL也是防止ACK丢失了，服务端可以重发一个FIN，客户端可以正常地再次接收到这个FIN报文。

##### TIME_WAIT过多会有什么危害？

- 主要就是两种：
  - 占用系统资源：比如文件描述符，内存资源，CPU资源、线程资源等
  - 占用端口资源：端口资源是有限地，一般开启地端口为：`32768 ~ 61000`
- 客户端和服务器的TIME_WAIT过多，造成影响不太相同：
  - 客户端：
    - 如果客户端的TIME_WAIT较多，把端口号全部占满了，那么就没办法和`目的地IP + 目的地端口`的服务器再次建立连接了，不过被使用的端口可以和另外的服务器建立连接，这是因为底层内核是通过四元组的方式来定位连接的，不会因为客户端端口一样造成连接冲突
  - 服务端：
    - 服务端没有接口限制的问题，因为服务端只监听一个端口，客户端从四面八方来，所以理论上可以建立很多连接。不过还是会消耗资源。

##### 如何优化TIME_WAIT

- 通过修改内核参数来跨越`TIME_WAIT`状态
- 不过这样子不好，前面已经分析过`TIME_WAIT`的作用了，TIME_WAIT是有助于我们的，最好不要试图避免这个状态

##### 服务器出现大量TIME_WAIT状态原因有什么？

- TIME_WAIT状态只会出现在主动关闭的那一方，所以如果出现大量TIME_WAIT，也就是服务器是主动关闭连接的一方，什么时候服务器会去主动关闭连接？
  - HTTP没有使用长连接
  - HTTP长连接超时
  - HTTP长连接的请求数量达到上限

###### HTTP没有使用长连接

- HTTP的长连接机制由`Connection: Keep-Alive`来开启，HTTP1.0默认是关闭的，开启的话要在头部加上`Connection: Keep-Alive`。
- 从HTTP/1.1开始，默认就是长连接了，如果要关闭的话。就加上`Connection: close`信息，也就是如果客户端和服务端任何一方的HTTP header有`Connection: close`，就无法使用长连接机制
- 关闭长连接以后，一个完成的请求，响应结束后连接就会关闭，这种方式就是短链接
- 那是客户端来关闭还是服务端来关闭呢？一般实现来说都是不管谁禁用了HTTP Keep-Alive，都是由服务端来关闭连接的
- 客户端禁用：
  - 客户端的HTTP请求 header中有`Connection: close`的信息，服务端发送完HTTP 响应之后，就会关闭连接
  - 因为服务器是在HTTP请求-响应周期的末端，如果客户端定义了Connection: close，那么关闭的时机就只在服务端。
- 服务端禁用：
  - 也是由服务端来关闭。由服务端主动关闭的话，只需要调用一次close方法即可，但是如果由客户端来关闭，那么服务器在响应之后还得把socket放入readable队列，下次事件来之后调用read方法才知道连接关闭了。这样子就得调用两次系统函数。
- 所以当如果服务端出现大量的TIME_WAIT状态，可以排查一下是不是客户端和服务端有没开启HTTP Keep-Alive。因为如果有人没开启，就会导致服务端去主动关闭连接。

###### HTTP长连接超时

- 连接不可能一直占用，比如有客户端在完成一次请求响应后，一直不发送新的数据，那么这个连接会被关闭。web服务软件会去设置这个时间。
- 比如在nginx中，设置了keepalive_timeout参数为60s，那么当客户端完成一个HTTP请求后，nginx会启动一个定时器，如果60s内都没有发送新请求，那么nginx就会触发回调函数来关闭连接，那么服务器这边就会出现TIME_WAIT状态。
- 所以如果大量客户端在建立TCP长连接后，都不去发送数据（或是网络问题，导致客户端数据一直传不到服务端），那么服务端就去关闭连接，出现大量的TIME_WAIT状态。

###### HTTP长连接的请求数量达到上限

- Web服务端会有一个参数，记录一条HTTP长连接能处理的最大请求数量。当请求超过这个限制以后，就会去主动关闭连接
- nginx中的keepalive_requests这个参数，就是记录这个HTTP长连接已经接收并处理的客户端请求数量。如果达到这个参数设置的最大值，nginx就会主动关闭长连接。于是服务端就会出现TIME_WAIT状态的连接
- keepalive_requests参数的默认值是100，每个HTTP长连接最多跑100次请求。如果QPS不高的话，100是可以用的
- 但是QPS比较高的场景，如果还是100，就会导致连接频繁的关闭，那么服务端就会出现大量TIME_WAIT请求。

##### 服务器出现大量CLOSE_WAIT状态原因

- CLOSE_WAIT是被动关闭方有的状态，如果被动关闭方没有去调用close函数关闭连接，那么无法从CLOSE_WAIT状态变成LAST_ACK状态
- 所以如果服务端出现大量的CLOSE_WAIT状态，说明服务端的程序没有去调用close函数关闭连接
- 那如果是close函数没有调用，说明代码方面出现了问题。需要对代码进行排查
- 我们先来分析一个普通的 TCP 服务端的流程：
  1. 创建服务端 socket，bind 绑定端口、listen 监听端口
  2. 将服务端 socket 注册到 epoll
  3. epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket
  4. 将已连接的 socket 注册到 epoll
  5. epoll_wait 等待事件发生
  6. 对方连接关闭时，我方调用 close
- 几个可能出现的地方：
  - 第二步：服务器没有注册socket到epoll，那么也就无法去感知到连接时间，自然无法调用close
  - 第三步：新连接到的时候没有去调用accept方法获取socket，导致客户端断开的时候服务器无法对这些socket进行close调用，可能是accept之前的函数出异常了
  - 第四步：没有将socket注册到epoll上，导致后续收到FIN报文，服务器感知不到
    - 可能是注册到epoll之前出现了异常
  - 第六步：当客户端关闭连接之后，服务端没有去执行close函数，可能是由于漏处理，或者close函数之前发生死锁等问题卡住了。
- 主要分析就是为什么服务端没有调用close

##### 如果建立了连接，但是客户端出现故障？

- 如果客户端出现宕机等状况，此时如果服务器不去探测客户端的状态的话，那就永远不知道发生什么了，将一直处于ESTABLISH状态，占用系统资源

- 为了避免，TCP有一个保活机制：

  - 定义一个时间段，当这个时间段没有任何来连接相关的活动，TCP保活机制就会作用，每个一个时间间隔就会发送一个探测报文，如果连续几个报文都没有得到响应，认为连接死亡，内核将错误上报给应用

- ```sh
  net.ipv4.tcp_keepalive_time=7200 #保活时间 2小时内没有任何连接相关的活动，就会启动保活机制
  net.ipv4.tcp_keepalive_intvl=75  #探测次数 每次检测间隔75秒
  net.ipv4.tcp_keepalive_probes=9  #时间间隔 检测9次未响应，就中断连接
  ```

- 应用程序如果想使用保活机制的话，要通过socket接口设置`SO_KEEPALIVE`选项，如果没有设置就不会起效

- 如果开启了TCP保活，需要考虑：

  - 对端程序是正常工作的，当TCP保活探测报文给到对端，对端是可以正常响应，这样子TCP保活时间会被重置，等待下一次的TCP保活时间到来
  - 对端主机宕机并重启，当TCP保活发送到对端后，对端可以响应，不过是一个RST报文，这样子可以马上发现TCP连接已经被重置了
  - 对端主机宕机（不是进程崩溃，进程崩溃会在系统回收进程资源的时候，发送FIN报文，而宕机是没办法感知的），或者由于对端其他的原因导致探测报文不可达。连续几次没收到响应的话，TCP会报告该TCP连接已死亡

- 当然，这个时间太长了，我们可以自己实现心跳检测

- 比如上面讲的长连接超时，nginx中的`keepalive_timeout`设置的就是60s。60s内没有任何新请求发送，就会关闭该连接

##### 如果建立了连接，但是服务端的进程崩溃了？

- TCP的连接信息是由内核去维护的，所以就算进程崩溃以后，内核可以去发送FIN报文，后续的挥手过程也是在内核种完成，不用进程的参与，所以还是可以正常地和客户端完成TCP四次挥手的

## TCP重传、滑动窗口、流量控制、阻塞控制

### 重传机制

- 为什么TCP可靠，方式之一就是序列号的确认应答，当数据发送了但是没收到应答，就认为数据包丢失了，需要重传机制解决

#### 超时重传

- 当发送数据的时候，设定一个计时器，当超过指定时间没收到`ACK`，就重发数据
- 两种情况：
  - 数据包丢失
  - 确认应答丢失

##### 超时时间应该设置为多少呢？

- 一个数据包的往返是1RTT，超时重传时间是以RTO(Retransmission Timeout)来表示
- RTO不能太长，也不能太短：
  - 太长会导致重发太慢，丢包很久才重传，效率低
  - 太短的话会导致可能并没有丢包，但是就重发了，增加了网络拥堵。比如RTO比RTT还短，那人家本身一个来回要一个RTT，还没到一个RTT就重传，就不合理了
- 所以，RTO要略大于RTT的值
- RTO的值是一个动态变化的值，因为RTT的值是变化的，这是因为网络是变化的。
- 估计RTO的值需要采样：
  - RTT的时间，进行加权平均，算出一个平滑RTT的值
  - RTT的波动范围，防止某个RTT波动大，但是没有检测出来
- 如果超时重传后，再次超时了，那么间隔时间是上一次的2倍，也就是超时间隔加倍策略。因为连续两次的超时说明网络环境很差，不宜频繁发发送

#### 快速重传

- 快速重传不以时间为却动，而是以数据为驱动
- ![快速重传机制](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/10.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 发送方发送了1，2，3，4，5份数据
  - 第一份Seq1到达，于是ACK返回2
  - Seq2丢失了，Seq3到达了，于是还是返回2
  - Seq4和Seq5都到达了，ACK还是返回2，因为Seq2还是没有收到
  - 发送端返回了三个ACK = 2的确认，知道了Seq2还没有收到，就会在定时器过期之前，重传Seq2
  - 最后收到了Seq2，因为3，4，5都收到了，所以返回ACK 6
- 快速重传解决了超时时间的问题，但是还有一个问题：就是重传的时候是传一个，还是所有呢？
- 比如发送方发送了6个数据，但是Seq2 和 Seq3都丢失了，那么接收到了Seq4，Seq5，Seq6都是回复ACK 2给对方，但是发送方不知道这个连续的ACK 2是因为接收到哪个报文而回复的（因为2丢了以后，2后续的数据再丢失也是返回ACK 2，此时不管是3丢了还是4丢了等，都是返回同样次数的ACK，所以发送方就懵逼了），是重传Seq2呢，还是重传Seq2以后的所有报文呢？
- 如果只重传Seq2，那么效率很低，因为对于Seq3来说，还得3个连续的ACK 3才能再触发Seq3的重传
- 如果重传Seq2后续的所有报文，虽然可以重传丢失的Seq2和Seq3，但是剩余的报文已经接受过了，所以浪费资源

#### SACK方法

- 为了解决快速重传的问题，就有了SACK方法，选择性确认
- 这种方式需要在TCP头部`选项`字段加`SACK`这个东西，它可以将已收到的数据的信息发送给发送方，这样子发送方就知道哪些数据已经收到了，哪些还没有，所以就可以只重传丢失的数据
- ![选择性确认](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/11.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 可以发现，通过SACK信息，发现只有200-299的数据丢失，所以只重传这个数据即可
- 开启`SACK`需要双方都支持，通过`net.ipv4.tcp_sack`

#### Duplicate SACK

- `D-SACK`主要是告诉发送方有哪些数据重复接收了
- ![ACK 丢包](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/12.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 比如这里的ACK丢包了，通过SACK=3000-3500可以告诉发送方，这一段数据是重复发送的，那么发送方就知道了不是因为它没发送到，而是ACK丢失了
- ![网络延时](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/13.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 比如这里，一开始数据延迟了，接收方会通过告诉已经收到的包，通过ACK告诉哪里到哪里还没有收到，发送方就会去重传这个区间的数据。
- 延迟的数据后面到达了，那么接收方会收到重复的数据，此时就可以通过SACK=1000-1500表示这个数据重复发送了，那么发送方就知道了原来第一次并不是丢包了，而是网络延迟导致我方重传。
- 所以`D-SACK`的作用就是让发送方知道：
  - 是发出的包丢了，还是ACK丢了
  - 是网络延迟了嘛

### 滑动窗口

- 如果每一次请求，都要等待一个响应，才能再发下一个请求，那么效率太低了，所以TCP引入了窗口概念
- 窗口的大小就是指**无需等待确认应答，可以继续发送数据的最大值**
- 窗口实际上就是一个缓冲区，当发送方主机收到确认应答返回之前，必须在缓冲区保存已发送的数，如果收到了应答，就可以清除已发送的数据。
- 这样，就算某个ACK丢了，可以通过下一次的ACK进行确认。![用滑动窗口方式并行处理](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/15.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- ACK600就算丢失，发送方也不会去重发这个数据，因为下一次应答已经到达700了，说明700之前的数据都收到了。这个模式叫做累计确认或累计应答

#### 窗口大小由哪一方决定

- TCP中有一个字段是`window`，也就是窗口的大小
- 这个字段是接收方告诉发送方自己还有多少缓冲区可以接收数据，于是发送端就根据这个接收端的处理能力来发送数据，不会导致接收方处理不过来
- 所以，窗口大小是由接收方的窗口大小来决定的
- 如果发送方的数据超过接收方的窗口大小，接收方就无法正常接收到数据

#### 发送方的滑动窗口

- ![SND.WND、SND.UN、SND.NXT](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/19.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

#### 接收方的滑动窗口

- ![接收窗口](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg)

- 接收方的窗口大小和发送方的窗口大小并不是完全相等的，而是约等于。因为滑动窗口的值是在变的，当接收方处理的速度很快，那么接收窗口很快就会空缺出来，会通过TCP报文中的`Windows`字段告诉发送方，那这里就会有延迟，所以是约等于的关系

### 流量控制

- 发送方不能一股脑的将数据全部发给接收方，要考虑到接收方的处理能力
- 流量控制就是通过管理窗口的大小，来平衡发送方发送的速率，让他发的数据一直是接收方可以处理的能力范围内
- 简单来说，就是发送方发送数据以后，窗口大小会减少，直到收到接收方返回的ACK，才能将窗口移动，这样子，发送方能够发送的数据都是窗口内的数据，而窗口大小又是由接收方决定的，所以窗口内的数据都是接收方有能力处理的。
- ![流量控制](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/21.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

#### 操作系统缓冲区和滑动窗口的关系

- 前面的例子是假定了发送窗口和接收窗口都不会改变的情况下，但是实际上，发送窗口和接收窗口所存放的字节数，都是在操作系统的缓冲区中的，而操作系统的缓冲区会被操作系统调整
- 如果应用读取缓冲区内容不及时，也会对缓冲区造成影响

##### 操作系统咋影响的？

- 考虑一个情况，应用程序没有及时读取缓冲，发送窗口和接收窗口的变化
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/22.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 第二个例子
- 当服务端资源很紧张的时候，操作系统可能会直接减少缓冲区的大小，此时应用程序又无法及时读取数据，就会出现严重的情况
- ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/23.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 这种情况的出现主要是同时减少缓存以及收缩窗口，所以为了避免这个情况出现，TCP不允许同时减少缓存又收缩窗口，而是采用先收缩窗口，过段时间再减少缓存，避免丢包情况。

#### 窗口关闭

- 前面可以看到，有窗口大小为0的情况，这个情况出现以后就会阻止发送方给接收方传递信息，直到窗口变为非0为止，这个就是窗口关闭

##### 窗口关闭的潜在危险

- 接收方通告窗口大小是通过ACK来通告的
- 那当窗口关闭后，接收方处理一段时间数据后打算向发送方通过窗口非0的ACK报文，如果丢失了，那就麻烦了。![窗口关闭潜在的危险](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/24.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 如果不采取措施的话，那就死锁了

##### TCP如何解决窗口关闭潜在的死锁现象呢？

- TCP为每个连接设有一个持续定时器，只要TCP连接一方收到对方的零窗口同时，就启动持续计时器
- 如果超时了，那么就会发送窗口探测报文，对方在确认这个探测报文时，给出自己现在的接收窗口大小![窗口探测](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/25.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

#### 糊涂窗口综合征

- 如果接收方太忙了，来不及取走窗口中的数据，那么就会导致发送方的窗口越来越小。
- 到最后呢，接收方腾出几个字节就告诉发送方现在窗口大小，那么发送方就会义无反顾的发送几个字节过去，这就是糊涂窗口综合征
- 因为TCP + IP有40个字节，如果就为了发送那几个字节的数据搭上这么大的开销，太不经济了
- 比如一下的例子![糊涂窗口综合症](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/26.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 可以发现，窗口越来越小，发送的数据也越来越少了
- 所以，糊涂窗口综合征会发生在接收方和发送方
  - 接收方可以通告一个小窗口
  - 发送方可以发送一个小数据
- 所以解决糊涂窗口综合征，就要同时解决以上两个问题
  - 让接收方不要通告小窗口
  - 要发送方不要发送小数据

##### 如何让接收方不通告小窗口

- 当窗口大小小于 min(MSS, 缓冲空间 / 2)，也就是小于MSS与1/2缓冲大小中的最小值时，就直接通告窗口为0，阻止发送方发数据过来
- 当接收方处理好一些数据以后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用的时候，就把窗口打开，让发送方发数据过来。

##### 怎么避免发送方发小数据呢？

- 使用Nagle算法，这个算法的思路是延时处理，只有满足下面条件的任意一个，才可以发送数据

  - 1：等到窗口大小 >= MSS 并且数据大小 >= MSS
  - 2：收到之前发送数据的ACK回包。

- 只要上述条件不满足，那么发送方就会一直囤积数据

- 伪代码：

  - ```java
    if 有数据要发送 {
        if 可用窗口大小 >= MSS and 可发送的数据 >= MSS {
        	立刻发送MSS大小的数据
        } else {
            if 有未确认的数据 {
                将数据放入缓存等待接收ACK
            } else {
                立刻发送数据
            }
        }
    }
    ```

- 接收方也要满足 不通告小窗口，因为如果不满足，即使开启了Nagle算法，对端的ACK回复很快，就达到了Nagle算法的第二个条件，就不会拼接太多数据包，依然会有小数据传输

- Nagle算法默认开启，不过有时候我们确实有小数据包传输的需求，比如telnet和ssh这种，需要关闭Nagle算法

- 可以这是TCP_NODELAY选项关闭算法

### 拥塞控制

#### 为什么要有拥塞控制

- 流量控制是避免发送方数据填满了接收方的缓存，但是并不知道网络中发生了什么
- 计算机网络处在一个共享的环境，所以可能因为其他主机使得网络拥堵
- 如果网络出现拥堵的时候，继续发送大量数据包，就可能导致数据包延迟，丢失等问题。TCP就会去重传数据包，但是重传又会导致网络负担更重，于是又会有延迟和丢包。情况就陷入了恶性循环
- 为了避免这种事情发生，TCP会自我牺牲，降低发送的数据量。
- 于是就有了拥塞控制，为的是避免发送方数据填满了整个网络
- 使用拥塞窗口来调节这个量

##### 什么是拥塞窗口，和发送窗口有什么关系？

- 拥塞窗口 `cwnd`是发送方维护的一个状态变量，根据网络中的拥塞程度去变化
- 前面说的是发送窗口 `swnd`和接收窗口`rwnd`是约等于的关系，那么现在加入了拥塞窗口的概念时，发送窗口的值为`swnd = min(cwnd, rwnd)`，也就是拥塞窗口和接收窗口的最小值
- 拥塞窗口`cwnd`的变化规则：
  - 只要网络中没有出现拥塞，`cwnd`就会增大
  - 如果网络中出现了拥塞，`cwnd`就减少

##### 如何知道网络中是否有拥塞呢？

- 只要发送方没有在规定时间内收到ACK应答报文，也就是发生了超时重传，就认为网络出问题了

##### 拥塞控制有什么算法？

- 主要四种算法：
  - 慢启动
  - 拥塞避免
  - 拥塞发生
  - 快速恢复

#### 慢启动

- TCP刚建立连接的时候，会有一个慢启动的过程，也就是一点点的提高发送数据包的数量，要是一上来就发大量的数据，就相当于给网络添堵了
- 慢启动算法很简单：当发送方每收到一个ACK，拥塞窗口cwnd大小就 + 1
- 假定拥塞窗口`cwnd`和发送窗口`swnd`相等：
  - 连接建立完成，一开始初始化`cwnd = 1`，表示可以传一个`MSS`大小的数据
  - 收到一个ACK后，cwnd + 1，于是可以发送2个
  - 又收到了2个ACK，cwnd + 2，现在一次可以发送4个
  - 又收到了4个ACK，cwnd + 4，现在一次可以发送8个了
- ![慢启动算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/27.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

##### 慢启动什么时候到头呢？

- 有一个慢启动门限`ssthresh(slow start threshold)`状态变量
  - 当`cwnd < ssthresh`，使用慢启动算法
  - `cwnd >= ssthresh`，使用阻塞避免算法

#### 拥塞避免算法

- 当`cwnd`超过了`ssthresh`之后，就会进入拥塞避免算法，一般来说`ssthresh`的大小是`65535`字节
- 进入拥塞避免算法后的规则：每收到一个ACK时，cwnd就会增加1/cwnd
- 比如现在`ssthresh`是8
  - 当8个ACK来到之后，每个确认增加1/8，8个ACK确认cwnd一共增加1，于是这一次就可以发送9个`MSS`大小的数据，其实就是变成了线性增加
- ![拥塞避免](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/28.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)
- 还是在增长阶段的，只不过增长的步调放缓了。
- 就这么一直增长的话，网络慢慢就会进入到拥塞状况了，就会出现丢包现象，此时就要对丢包的数据进行重传
- 当触发了重传，其实就进入到了拥塞发送算法

#### 拥塞发生

- 当网络出现拥塞，重传机制主要是两种
  - 超时重传
  - 快速重传

##### 发生超时重传的拥塞发生算法

- 当发生了超时重传，则会使用拥塞发生算法
- `ssthresh`的值和`cwnd`的值会发生变化
  - `ssthresh`设为`cwnd/2`
  - `cwnd`重置为1（其实是恢复到初始值，这里假定为1）

##### 如何查看系统的cwnd初始值

- 可以使用ss -nli查看每一个TCP连接的cwnd初始化值，Linux下初始值为10，也就是10个MSS

![拥塞发送 —— 超时重传](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/29.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

- 
